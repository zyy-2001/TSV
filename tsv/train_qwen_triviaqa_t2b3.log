Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   1%|          | 115/17944 [00:00<00:15, 1129.55 examples/s]Map:   1%|▏         | 244/17944 [00:00<00:14, 1216.34 examples/s]Map:   2%|▏         | 373/17944 [00:00<00:14, 1246.11 examples/s]Map:   3%|▎         | 502/17944 [00:00<00:13, 1260.05 examples/s]Map:   4%|▎         | 631/17944 [00:00<00:13, 1267.88 examples/s]Map:   5%|▍         | 818/17944 [00:00<00:13, 1254.49 examples/s]Map:   5%|▌         | 948/17944 [00:00<00:13, 1265.13 examples/s]Map:   6%|▌         | 1078/17944 [00:00<00:13, 1273.30 examples/s]Map:   7%|▋         | 1209/17944 [00:00<00:13, 1280.46 examples/s]Map:   7%|▋         | 1339/17944 [00:01<00:12, 1283.46 examples/s]Map:   8%|▊         | 1470/17944 [00:01<00:12, 1287.17 examples/s]Map:   9%|▉         | 1600/17944 [00:01<00:12, 1289.20 examples/s]Map:  10%|▉         | 1730/17944 [00:01<00:12, 1290.93 examples/s]Map:  10%|█         | 1860/17944 [00:01<00:12, 1289.49 examples/s]Map:  11%|█         | 1990/17944 [00:01<00:12, 1289.47 examples/s]Map:  12%|█▏        | 2119/17944 [00:01<00:12, 1286.07 examples/s]Map:  13%|█▎        | 2249/17944 [00:01<00:12, 1288.47 examples/s]Map:  13%|█▎        | 2379/17944 [00:01<00:12, 1289.91 examples/s]Map:  14%|█▍        | 2509/17944 [00:01<00:11, 1290.46 examples/s]Map:  15%|█▍        | 2640/17944 [00:02<00:11, 1291.41 examples/s]Map:  15%|█▌        | 2770/17944 [00:02<00:11, 1291.93 examples/s]Map:  17%|█▋        | 2961/17944 [00:02<00:11, 1281.70 examples/s]Map:  18%|█▊        | 3148/17944 [00:02<00:11, 1266.86 examples/s]Map:  19%|█▊        | 3338/17944 [00:02<00:11, 1263.22 examples/s]Map:  20%|█▉        | 3527/17944 [00:02<00:11, 1260.34 examples/s]Map:  20%|██        | 3655/17944 [00:02<00:11, 1262.51 examples/s]Map:  21%|██        | 3785/17944 [00:02<00:11, 1269.34 examples/s]Map:  22%|██▏       | 3915/17944 [00:03<00:11, 1274.42 examples/s]Map:  23%|██▎       | 4045/17944 [00:03<00:10, 1277.47 examples/s]Map:  24%|██▎       | 4237/17944 [00:03<00:10, 1274.99 examples/s]Map:  24%|██▍       | 4367/17944 [00:03<00:10, 1278.20 examples/s]Map:  25%|██▌       | 4497/17944 [00:03<00:10, 1280.96 examples/s]Map:  26%|██▌       | 4690/17944 [00:03<00:10, 1281.39 examples/s]Map:  27%|██▋       | 4820/17944 [00:03<00:10, 1282.81 examples/s]Map:  28%|██▊       | 4949/17944 [00:03<00:10, 1282.06 examples/s]Map:  28%|██▊       | 5079/17944 [00:03<00:10, 1283.52 examples/s]Map:  29%|██▉       | 5259/17944 [00:04<00:10, 1250.47 examples/s]Map:  30%|███       | 5389/17944 [00:04<00:09, 1260.40 examples/s]Map:  31%|███       | 5519/17944 [00:04<00:09, 1269.27 examples/s]Map:  31%|███▏      | 5649/17944 [00:04<00:09, 1274.50 examples/s]Map:  32%|███▏      | 5779/17944 [00:04<00:09, 1278.48 examples/s]Map:  33%|███▎      | 5908/17944 [00:04<00:09, 1278.15 examples/s]Map:  34%|███▍      | 6091/17944 [00:04<00:09, 1253.01 examples/s]Map:  35%|███▍      | 6222/17944 [00:04<00:09, 1265.54 examples/s]Map:  35%|███▌      | 6353/17944 [00:04<00:09, 1274.72 examples/s]Map:  36%|███▋      | 6543/17944 [00:05<00:08, 1269.99 examples/s]Map:  37%|███▋      | 6673/17944 [00:05<00:08, 1274.96 examples/s]Map:  38%|███▊      | 6803/17944 [00:05<00:08, 1279.40 examples/s]Map:  39%|███▊      | 6934/17944 [00:05<00:08, 1284.39 examples/s]Map:  39%|███▉      | 7064/17944 [00:05<00:08, 1286.36 examples/s]Map:  40%|████      | 7194/17944 [00:05<00:08, 1288.04 examples/s]Map:  41%|████      | 7324/17944 [00:05<00:08, 1289.82 examples/s]Map:  42%|████▏     | 7515/17944 [00:05<00:08, 1279.76 examples/s]Map:  43%|████▎     | 7644/17944 [00:05<00:08, 1280.76 examples/s]Map:  43%|████▎     | 7774/17944 [00:06<00:07, 1284.33 examples/s]Map:  44%|████▍     | 7904/17944 [00:06<00:07, 1286.77 examples/s]Map:  45%|████▍     | 8034/17944 [00:06<00:07, 1289.67 examples/s]Map:  45%|████▌     | 8164/17944 [00:06<00:07, 1290.74 examples/s]Map:  46%|████▌     | 8294/17944 [00:06<00:07, 1290.76 examples/s]Map:  47%|████▋     | 8424/17944 [00:06<00:07, 1291.61 examples/s]Map:  48%|████▊     | 8612/17944 [00:06<00:07, 1273.18 examples/s]Map:  49%|████▊     | 8741/17944 [00:06<00:07, 1277.39 examples/s]Map:  49%|████▉     | 8870/17944 [00:06<00:07, 1276.99 examples/s]Map:  50%|█████     | 8999/17944 [00:07<00:06, 1278.08 examples/s]Map:  51%|█████     | 9129/17944 [00:07<00:06, 1280.46 examples/s]Map:  52%|█████▏    | 9259/17944 [00:07<00:06, 1281.70 examples/s]Map:  53%|█████▎    | 9449/17944 [00:07<00:06, 1272.42 examples/s]Map:  53%|█████▎    | 9579/17944 [00:07<00:06, 1275.47 examples/s]Map:  54%|█████▍    | 9708/17944 [00:07<00:06, 1277.35 examples/s]Map:  55%|█████▍    | 9838/17944 [00:07<00:06, 1278.97 examples/s]Map:  57%|█████▋    | 10210/17944 [00:07<00:03, 1973.30 examples/s]Map:  68%|██████▊   | 12129/17944 [00:07<00:00, 6961.72 examples/s]Map:  79%|███████▉  | 14133/17944 [00:08<00:00, 10788.96 examples/s]Map:  90%|████████▉ | 16079/17944 [00:08<00:00, 13343.49 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2135.04 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  2%|▏         | 154/9960 [00:00<00:06, 1533.58it/s]  3%|▎         | 316/9960 [00:00<00:06, 1582.04it/s]  5%|▍         | 485/9960 [00:00<00:05, 1629.83it/s]  7%|▋         | 653/9960 [00:00<00:05, 1647.74it/s]  8%|▊         | 820/9960 [00:00<00:05, 1654.36it/s] 10%|▉         | 989/9960 [00:00<00:05, 1664.70it/s] 12%|█▏        | 1156/9960 [00:00<00:05, 1650.73it/s] 13%|█▎        | 1328/9960 [00:00<00:05, 1669.93it/s] 15%|█▌        | 1497/9960 [00:00<00:05, 1676.14it/s] 17%|█▋        | 1666/9960 [00:01<00:04, 1679.46it/s] 18%|█▊        | 1834/9960 [00:01<00:04, 1679.17it/s] 20%|██        | 2007/9960 [00:01<00:04, 1692.17it/s] 22%|██▏       | 2180/9960 [00:01<00:04, 1702.99it/s] 24%|██▎       | 2351/9960 [00:01<00:04, 1696.34it/s] 25%|██▌       | 2521/9960 [00:01<00:04, 1689.59it/s] 27%|██▋       | 2690/9960 [00:01<00:04, 1686.94it/s] 29%|██▊       | 2859/9960 [00:01<00:04, 1682.10it/s] 30%|███       | 3028/9960 [00:01<00:04, 1677.05it/s] 32%|███▏      | 3196/9960 [00:01<00:04, 1674.44it/s] 34%|███▍      | 3366/9960 [00:02<00:03, 1679.39it/s] 35%|███▌      | 3534/9960 [00:02<00:03, 1673.05it/s] 37%|███▋      | 3702/9960 [00:02<00:03, 1639.31it/s] 39%|███▉      | 3867/9960 [00:02<00:03, 1633.62it/s] 40%|████      | 4031/9960 [00:02<00:03, 1617.23it/s] 42%|████▏     | 4193/9960 [00:02<00:03, 1615.20it/s] 44%|████▎     | 4356/9960 [00:02<00:03, 1618.31it/s] 45%|████▌     | 4520/9960 [00:02<00:03, 1623.83it/s] 47%|████▋     | 4684/9960 [00:02<00:03, 1626.80it/s] 49%|████▉     | 4856/9960 [00:02<00:03, 1654.23it/s] 51%|█████     | 5032/9960 [00:03<00:02, 1684.53it/s] 52%|█████▏    | 5202/9960 [00:03<00:02, 1688.15it/s] 54%|█████▍    | 5372/9960 [00:03<00:02, 1690.28it/s] 56%|█████▌    | 5545/9960 [00:03<00:02, 1699.71it/s] 57%|█████▋    | 5717/9960 [00:03<00:02, 1703.68it/s] 59%|█████▉    | 5889/9960 [00:03<00:02, 1705.68it/s] 61%|██████    | 6062/9960 [00:03<00:02, 1710.22it/s] 63%|██████▎   | 6234/9960 [00:03<00:02, 1691.87it/s] 64%|██████▍   | 6405/9960 [00:03<00:02, 1694.28it/s] 66%|██████▌   | 6575/9960 [00:03<00:01, 1695.00it/s] 68%|██████▊   | 6747/9960 [00:04<00:01, 1698.91it/s] 69%|██████▉   | 6917/9960 [00:04<00:01, 1698.86it/s] 71%|███████   | 7089/9960 [00:04<00:01, 1703.18it/s] 73%|███████▎  | 7260/9960 [00:04<00:01, 1704.33it/s] 75%|███████▍  | 7431/9960 [00:04<00:01, 1701.86it/s] 76%|███████▋  | 7602/9960 [00:04<00:01, 1663.56it/s] 78%|███████▊  | 7771/9960 [00:04<00:01, 1668.51it/s] 80%|███████▉  | 7940/9960 [00:04<00:01, 1672.79it/s] 81%|████████▏ | 8110/9960 [00:04<00:01, 1679.73it/s] 83%|████████▎ | 8280/9960 [00:04<00:00, 1685.15it/s] 85%|████████▍ | 8449/9960 [00:05<00:00, 1676.15it/s] 87%|████████▋ | 8618/9960 [00:05<00:00, 1679.90it/s] 88%|████████▊ | 8787/9960 [00:05<00:00, 1662.05it/s] 90%|████████▉ | 8962/9960 [00:05<00:00, 1685.67it/s] 92%|█████████▏| 9137/9960 [00:05<00:00, 1702.49it/s] 93%|█████████▎| 9311/9960 [00:05<00:00, 1712.86it/s] 95%|█████████▌| 9488/9960 [00:05<00:00, 1728.08it/s] 97%|█████████▋| 9661/9960 [00:05<00:00, 1709.85it/s] 99%|█████████▊| 9833/9960 [00:05<00:00, 1683.60it/s]100%|██████████| 9960/9960 [00:05<00:00, 1675.70it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]                                                                 epoch_loss: 0.713432788848877
Epoch [1/20], Loss: 0.7134
Best test AUROC: 0.5432, at epoch: 0
Epoch [1/20],Test AUROC: 0.5432
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.6867635250091553
Epoch [2/20], Loss: 0.6868
Best test AUROC: 0.6298, at epoch: 1
Epoch [2/20],Test AUROC: 0.6298
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6692449450492859
Epoch [3/20], Loss: 0.6692
Best test AUROC: 0.6814, at epoch: 2
Epoch [3/20],Test AUROC: 0.6814
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6528533697128296
Epoch [4/20], Loss: 0.6529
Best test AUROC: 0.7136, at epoch: 3
Epoch [4/20],Test AUROC: 0.7136
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6366641521453857
Epoch [5/20], Loss: 0.6367
Best test AUROC: 0.7365, at epoch: 4
Epoch [5/20],Test AUROC: 0.7365
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6189807653427124
Epoch [6/20], Loss: 0.6190
Best test AUROC: 0.7531, at epoch: 5
Epoch [6/20],Test AUROC: 0.7531
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                 epoch_loss: 0.60040682554245
Epoch [7/20], Loss: 0.6004
Best test AUROC: 0.7636, at epoch: 6
Epoch [7/20],Test AUROC: 0.7636
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                 epoch_loss: 0.580348014831543
Epoch [8/20], Loss: 0.5803
Best test AUROC: 0.7686, at epoch: 7
Epoch [8/20],Test AUROC: 0.7686
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.5611743330955505
Epoch [9/20], Loss: 0.5612
Best test AUROC: 0.7712, at epoch: 8
Epoch [9/20],Test AUROC: 0.7712
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.5413799285888672
Epoch [10/20], Loss: 0.5414
Best test AUROC: 0.7749, at epoch: 9
Epoch [10/20],Test AUROC: 0.7749
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.519528329372406
Epoch [11/20], Loss: 0.5195
Best test AUROC: 0.7779, at epoch: 10
Epoch [11/20],Test AUROC: 0.7779
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.49455100297927856
Epoch [12/20], Loss: 0.4946
Best test AUROC: 0.7796, at epoch: 11
Epoch [12/20],Test AUROC: 0.7796
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.4681552052497864
Epoch [13/20], Loss: 0.4682
Best test AUROC: 0.7810, at epoch: 12
Epoch [13/20],Test AUROC: 0.7810
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.441533625125885
Epoch [14/20], Loss: 0.4415
Best test AUROC: 0.7813, at epoch: 13
Epoch [14/20],Test AUROC: 0.7813
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.41387704014778137
Epoch [15/20], Loss: 0.4139
Epoch [15/20],Test AUROC: 0.7796
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.3843817710876465
Epoch [16/20], Loss: 0.3844
Epoch [16/20],Test AUROC: 0.7782
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.35265570878982544
Epoch [17/20], Loss: 0.3527
Epoch [17/20],Test AUROC: 0.7773
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.3220868408679962
Epoch [18/20], Loss: 0.3221
Epoch [18/20],Test AUROC: 0.7784
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.293613076210022
Epoch [19/20], Loss: 0.2936
Epoch [19/20],Test AUROC: 0.7773
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.2714197039604187
Epoch [20/20], Loss: 0.2714
Best test AUROC: 0.7842, at epoch: 19
Epoch [20/20],Test AUROC: 0.7842
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.08it/s]  2%|▏         | 2/115 [00:01<00:57,  1.95it/s]  3%|▎         | 3/115 [00:01<00:48,  2.30it/s]  3%|▎         | 4/115 [00:01<00:52,  2.11it/s]  4%|▍         | 5/115 [00:02<00:53,  2.06it/s]  5%|▌         | 6/115 [00:02<00:49,  2.18it/s]  6%|▌         | 7/115 [00:03<00:46,  2.34it/s]  7%|▋         | 8/115 [00:03<00:45,  2.35it/s]  8%|▊         | 9/115 [00:04<00:47,  2.22it/s]  9%|▊         | 10/115 [00:04<00:49,  2.10it/s] 10%|▉         | 11/115 [00:04<00:44,  2.32it/s] 10%|█         | 12/115 [00:05<00:48,  2.11it/s] 11%|█▏        | 13/115 [00:06<00:48,  2.08it/s] 12%|█▏        | 14/115 [00:06<00:49,  2.04it/s] 13%|█▎        | 15/115 [00:06<00:44,  2.25it/s] 14%|█▍        | 16/115 [00:07<00:48,  2.04it/s] 15%|█▍        | 17/115 [00:08<00:50,  1.95it/s] 16%|█▌        | 18/115 [00:08<00:51,  1.87it/s] 17%|█▋        | 19/115 [00:08<00:45,  2.11it/s] 17%|█▋        | 20/115 [00:09<00:43,  2.17it/s] 18%|█▊        | 21/115 [00:09<00:45,  2.07it/s] 19%|█▉        | 22/115 [00:10<00:45,  2.04it/s] 20%|██        | 23/115 [00:10<00:40,  2.26it/s] 21%|██        | 24/115 [00:11<00:39,  2.32it/s] 22%|██▏       | 25/115 [00:11<00:36,  2.48it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.62it/s] 23%|██▎       | 27/115 [00:12<00:37,  2.34it/s] 24%|██▍       | 28/115 [00:12<00:40,  2.15it/s] 25%|██▌       | 29/115 [00:13<00:44,  1.92it/s] 26%|██▌       | 30/115 [00:14<00:44,  1.90it/s] 27%|██▋       | 31/115 [00:14<00:40,  2.07it/s] 28%|██▊       | 32/115 [00:14<00:40,  2.05it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.92it/s] 30%|██▉       | 34/115 [00:16<00:40,  1.98it/s] 30%|███       | 35/115 [00:16<00:39,  2.04it/s] 31%|███▏      | 36/115 [00:17<00:40,  1.97it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.91it/s] 33%|███▎      | 38/115 [00:18<00:39,  1.95it/s] 34%|███▍      | 39/115 [00:18<00:36,  2.09it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.16it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.96it/s] 37%|███▋      | 42/115 [00:20<00:36,  1.98it/s] 37%|███▋      | 43/115 [00:20<00:42,  1.71it/s] 38%|███▊      | 44/115 [00:21<00:46,  1.52it/s] 39%|███▉      | 45/115 [00:22<00:44,  1.59it/s] 40%|████      | 46/115 [00:22<00:42,  1.61it/s] 41%|████      | 47/115 [00:23<00:39,  1.71it/s] 42%|████▏     | 48/115 [00:24<00:53,  1.26it/s] 43%|████▎     | 49/115 [00:25<00:49,  1.33it/s] 43%|████▎     | 50/115 [00:25<00:45,  1.44it/s] 44%|████▍     | 51/115 [00:26<00:40,  1.56it/s] 45%|████▌     | 52/115 [00:26<00:40,  1.55it/s] 46%|████▌     | 53/115 [00:27<00:39,  1.56it/s] 47%|████▋     | 54/115 [00:28<00:37,  1.62it/s] 48%|████▊     | 55/115 [00:28<00:31,  1.90it/s] 49%|████▊     | 56/115 [00:28<00:29,  2.01it/s] 50%|████▉     | 57/115 [00:29<00:25,  2.29it/s] 50%|█████     | 58/115 [00:29<00:23,  2.42it/s] 51%|█████▏    | 59/115 [00:29<00:21,  2.63it/s] 52%|█████▏    | 60/115 [00:30<00:23,  2.35it/s] 53%|█████▎    | 61/115 [00:30<00:23,  2.30it/s] 54%|█████▍    | 62/115 [00:31<00:24,  2.16it/s] 55%|█████▍    | 63/115 [00:32<00:26,  1.95it/s] 56%|█████▌    | 64/115 [00:32<00:25,  2.00it/s] 57%|█████▋    | 65/115 [00:32<00:24,  2.07it/s] 57%|█████▋    | 66/115 [00:33<00:24,  1.99it/s] 58%|█████▊    | 67/115 [00:33<00:22,  2.17it/s] 59%|█████▉    | 68/115 [00:34<00:20,  2.26it/s] 60%|██████    | 69/115 [00:34<00:21,  2.18it/s] 61%|██████    | 70/115 [00:35<00:21,  2.11it/s] 62%|██████▏   | 71/115 [00:35<00:20,  2.14it/s] 63%|██████▎   | 72/115 [00:36<00:20,  2.09it/s] 63%|██████▎   | 73/115 [00:36<00:18,  2.25it/s] 64%|██████▍   | 74/115 [00:36<00:17,  2.34it/s] 65%|██████▌   | 75/115 [00:37<00:17,  2.30it/s] 66%|██████▌   | 76/115 [00:37<00:18,  2.13it/s] 67%|██████▋   | 77/115 [00:38<00:18,  2.03it/s] 68%|██████▊   | 78/115 [00:38<00:16,  2.18it/s] 69%|██████▊   | 79/115 [00:39<00:17,  2.08it/s] 70%|██████▉   | 80/115 [00:39<00:15,  2.23it/s] 70%|███████   | 81/115 [00:40<00:14,  2.29it/s] 71%|███████▏  | 82/115 [00:40<00:14,  2.30it/s] 72%|███████▏  | 83/115 [00:41<00:13,  2.38it/s] 73%|███████▎  | 84/115 [00:41<00:13,  2.23it/s] 74%|███████▍  | 85/115 [00:42<00:13,  2.19it/s] 75%|███████▍  | 86/115 [00:42<00:14,  2.07it/s] 76%|███████▌  | 87/115 [00:43<00:15,  1.85it/s] 77%|███████▋  | 88/115 [00:43<00:14,  1.90it/s] 77%|███████▋  | 89/115 [00:46<00:29,  1.14s/it] 78%|███████▊  | 90/115 [00:46<00:23,  1.08it/s] 79%|███████▉  | 91/115 [00:47<00:20,  1.16it/s] 80%|████████  | 92/115 [00:48<00:18,  1.26it/s] 81%|████████  | 93/115 [00:48<00:15,  1.39it/s] 82%|████████▏ | 94/115 [00:49<00:13,  1.56it/s] 83%|████████▎ | 95/115 [00:49<00:11,  1.69it/s] 83%|████████▎ | 96/115 [00:50<00:11,  1.66it/s] 84%|████████▍ | 97/115 [00:50<00:10,  1.76it/s] 85%|████████▌ | 98/115 [00:51<00:08,  1.95it/s] 86%|████████▌ | 99/115 [00:51<00:07,  2.06it/s] 87%|████████▋ | 100/115 [00:51<00:06,  2.23it/s] 88%|████████▊ | 101/115 [00:52<00:06,  2.17it/s] 89%|████████▊ | 102/115 [00:52<00:06,  2.12it/s] 90%|████████▉ | 103/115 [00:53<00:05,  2.33it/s] 90%|█████████ | 104/115 [00:53<00:04,  2.26it/s] 91%|█████████▏| 105/115 [00:53<00:03,  2.57it/s] 92%|█████████▏| 106/115 [00:54<00:03,  2.38it/s] 93%|█████████▎| 107/115 [00:54<00:03,  2.45it/s] 94%|█████████▍| 108/115 [00:55<00:02,  2.64it/s] 95%|█████████▍| 109/115 [00:55<00:02,  2.77it/s] 96%|█████████▌| 110/115 [00:56<00:02,  1.87it/s] 97%|█████████▋| 111/115 [00:57<00:02,  1.65it/s] 97%|█████████▋| 112/115 [00:58<00:02,  1.21it/s] 98%|█████████▊| 113/115 [00:58<00:01,  1.42it/s] 99%|█████████▉| 114/115 [00:59<00:00,  1.59it/s]100%|██████████| 115/115 [00:59<00:00,  1.94it/s]
tsv_main1.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main1.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                 epoch_loss: 0.3544951279958089
Epoch [1/20], Loss: 0.3545
Best test AUROC: 0.7963, at epoch: 20
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                 epoch_loss: 0.2458292841911316
Epoch [2/20], Loss: 0.2458
Best test AUROC: 0.8044, at epoch: 21
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                 epoch_loss: 0.19708472987016043
Epoch [3/20], Loss: 0.1971
Best test AUROC: 0.8119, at epoch: 22
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.15770725905895233
Epoch [4/20], Loss: 0.1577
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.13001498331626257
Epoch [5/20], Loss: 0.1300
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.10351881633202235
Epoch [6/20], Loss: 0.1035
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.08302931984265645
Epoch [7/20], Loss: 0.0830
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.06590259075164795
Epoch [8/20], Loss: 0.0659
Best test AUROC: 0.8121, at epoch: 27
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                 epoch_loss: 0.052712077274918556
Epoch [9/20], Loss: 0.0527
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.04221360571682453
Epoch [10/20], Loss: 0.0422
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.03413042612373829
Epoch [11/20], Loss: 0.0341
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                  epoch_loss: 0.02740259033938249
Epoch [12/20], Loss: 0.0274
Best test AUROC: 0.8134, at epoch: 31
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.02199687249958515
Epoch [13/20], Loss: 0.0220
Best test AUROC: 0.8145, at epoch: 32
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.29it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]                                                                  epoch_loss: 0.017664811263481777
Epoch [14/20], Loss: 0.0177
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.014258775860071182
Epoch [15/20], Loss: 0.0143
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.011618037552883228
Epoch [16/20], Loss: 0.0116
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.009504568763077259
Epoch [17/20], Loss: 0.0095
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.007819693690786758
Epoch [18/20], Loss: 0.0078
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.0064737543774147826
Epoch [19/20], Loss: 0.0065
Best test AUROC: 0.8146, at epoch: 38
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]                                                                  epoch_loss: 0.005385546324153741
Epoch [20/20], Loss: 0.0054
best_test_auroc: 0.8146331368880027
