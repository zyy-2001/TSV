Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.87s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.92s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.59s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 13%|█▎        | 104/817 [00:00<00:00, 1032.84it/s] 31%|███       | 253/817 [00:00<00:00, 1297.25it/s] 47%|████▋     | 383/817 [00:00<00:00, 1274.85it/s] 65%|██████▌   | 533/817 [00:00<00:00, 1361.89it/s] 85%|████████▌ | 696/817 [00:00<00:00, 1455.65it/s]100%|██████████| 817/817 [00:00<00:00, 1409.03it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]                                                                 epoch_loss: 0.6991661787033081
Epoch [1/20], Loss: 0.6992
Best test AUROC: 0.5635, at epoch: 0
Epoch [1/20],Test AUROC: 0.5635
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]                                                                 epoch_loss: 0.7004290819168091
Epoch [2/20], Loss: 0.7004
Epoch [2/20],Test AUROC: 0.5467
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                 epoch_loss: 0.6296881437301636
Epoch [3/20], Loss: 0.6297
Best test AUROC: 0.7437, at epoch: 2
Epoch [3/20],Test AUROC: 0.7437
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                 epoch_loss: 0.5004989504814148
Epoch [4/20], Loss: 0.5005
Best test AUROC: 0.7914, at epoch: 3
Epoch [4/20],Test AUROC: 0.7914
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.4080272316932678
Epoch [5/20], Loss: 0.4080
Best test AUROC: 0.8225, at epoch: 4
Epoch [5/20],Test AUROC: 0.8225
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.32816874980926514
Epoch [6/20], Loss: 0.3282
Best test AUROC: 0.8340, at epoch: 5
Epoch [6/20],Test AUROC: 0.8340
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]                                                                 epoch_loss: 0.2606867849826813
Epoch [7/20], Loss: 0.2607
Best test AUROC: 0.8386, at epoch: 6
Epoch [7/20],Test AUROC: 0.8386
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                 epoch_loss: 0.20509620010852814
Epoch [8/20], Loss: 0.2051
Best test AUROC: 0.8396, at epoch: 7
Epoch [8/20],Test AUROC: 0.8396
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                 epoch_loss: 0.1612640619277954
Epoch [9/20], Loss: 0.1613
Best test AUROC: 0.8406, at epoch: 8
Epoch [9/20],Test AUROC: 0.8406
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]                                                                  epoch_loss: 0.12671974301338196
Epoch [10/20], Loss: 0.1267
Epoch [10/20],Test AUROC: 0.8392
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.0965380072593689
Epoch [11/20], Loss: 0.0965
Epoch [11/20],Test AUROC: 0.8381
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.06938457489013672
Epoch [12/20], Loss: 0.0694
Epoch [12/20],Test AUROC: 0.8369
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.047246694564819336
Epoch [13/20], Loss: 0.0472
Epoch [13/20],Test AUROC: 0.8377
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.030986875295639038
Epoch [14/20], Loss: 0.0310
Epoch [14/20],Test AUROC: 0.8357
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.01984952948987484
Epoch [15/20], Loss: 0.0198
Epoch [15/20],Test AUROC: 0.8358
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.012385906651616096
Epoch [16/20], Loss: 0.0124
Epoch [16/20],Test AUROC: 0.8357
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.007479646243155003
Epoch [17/20], Loss: 0.0075
Epoch [17/20],Test AUROC: 0.8354
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.004422792233526707
Epoch [18/20], Loss: 0.0044
Epoch [18/20],Test AUROC: 0.8355
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.0026294179260730743
Epoch [19/20], Loss: 0.0026
Epoch [19/20],Test AUROC: 0.8346
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.0016039498150348663
Epoch [20/20], Loss: 0.0016
Epoch [20/20],Test AUROC: 0.8345
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.08it/s] 50%|█████     | 2/4 [00:01<00:01,  1.02it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]100%|██████████| 4/4 [00:03<00:00,  1.04it/s]100%|██████████| 4/4 [00:03<00:00,  1.04it/s]
tsv_main3.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main3.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                 epoch_loss: 0.0005904914811253548
Epoch [1/20], Loss: 0.0006
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                 epoch_loss: 0.00045365015976130965
Epoch [2/20], Loss: 0.0005
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 3/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                 epoch_loss: 0.000350317545235157
Epoch [3/20], Loss: 0.0004
Epoch 4/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 4/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                 epoch_loss: 0.00027199860196560623
Epoch [4/20], Loss: 0.0003
Epoch 5/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 5/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                 epoch_loss: 0.00021228149998933076
Epoch [5/20], Loss: 0.0002
Epoch 6/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 6/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                 epoch_loss: 0.00016660783439874648
Epoch [6/20], Loss: 0.0002
Epoch 7/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 7/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                 epoch_loss: 0.00013158724177628756
Epoch [7/20], Loss: 0.0001
Epoch 8/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 8/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                 epoch_loss: 0.00010443776263855398
Epoch [8/20], Loss: 0.0001
Epoch 9/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it]Epoch 9/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                 epoch_loss: 8.343137451447547e-05
Epoch [9/20], Loss: 0.0001
Epoch 10/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 10/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 6.698697397951036e-05
Epoch [10/20], Loss: 0.0001
Epoch 11/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 11/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 5.413051694631576e-05
Epoch [11/20], Loss: 0.0001
Epoch 12/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 12/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 4.400918842293322e-05
Epoch [12/20], Loss: 0.0000
Epoch 13/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it]Epoch 13/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                  epoch_loss: 3.5990914329886434e-05
Epoch [13/20], Loss: 0.0000
Epoch 14/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 14/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 2.962663711514324e-05
Epoch [14/20], Loss: 0.0000
Epoch 15/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 15/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 2.4513524112990127e-05
Epoch [15/20], Loss: 0.0000
Epoch 16/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 16/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                  epoch_loss: 2.040527906501666e-05
Epoch [16/20], Loss: 0.0000
Epoch 17/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 17/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 1.7085779836634175e-05
Epoch [17/20], Loss: 0.0000
Epoch 18/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 18/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 1.4392198499990627e-05
Epoch [18/20], Loss: 0.0000
Epoch 19/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.34s/it]Epoch 19/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.26it/s]                                                                  epoch_loss: 1.2193388465675526e-05
Epoch [19/20], Loss: 0.0000
Epoch 20/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it]Epoch 20/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]                                                                  epoch_loss: 1.0393965567345731e-05
Epoch [20/20], Loss: 0.0000
best_test_auroc: 0.8405806451612904
