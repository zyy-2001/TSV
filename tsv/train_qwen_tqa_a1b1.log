Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 17%|█▋        | 138/817 [00:00<00:00, 1374.91it/s] 38%|███▊      | 308/817 [00:00<00:00, 1564.87it/s] 58%|█████▊    | 476/817 [00:00<00:00, 1614.77it/s] 78%|███████▊  | 639/817 [00:00<00:00, 1616.88it/s] 99%|█████████▉| 808/817 [00:00<00:00, 1643.08it/s]100%|██████████| 817/817 [00:00<00:00, 1612.65it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]                                                                 epoch_loss: 0.6144369840621948
Epoch [1/20], Loss: 0.6144
Best test AUROC: 0.6005, at epoch: 0
Epoch [1/20],Test AUROC: 0.6005
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]                                                                 epoch_loss: 0.5514991283416748
Epoch [2/20], Loss: 0.5515
Best test AUROC: 0.7557, at epoch: 1
Epoch [2/20],Test AUROC: 0.7557
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]                                                                 epoch_loss: 0.4466997981071472
Epoch [3/20], Loss: 0.4467
Best test AUROC: 0.8198, at epoch: 2
Epoch [3/20],Test AUROC: 0.8198
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]                                                                 epoch_loss: 0.3520755469799042
Epoch [4/20], Loss: 0.3521
Best test AUROC: 0.8374, at epoch: 3
Epoch [4/20],Test AUROC: 0.8374
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                 epoch_loss: 0.25459951162338257
Epoch [5/20], Loss: 0.2546
Best test AUROC: 0.8468, at epoch: 4
Epoch [5/20],Test AUROC: 0.8468
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]                                                                 epoch_loss: 0.1757173240184784
Epoch [6/20], Loss: 0.1757
Best test AUROC: 0.8490, at epoch: 5
Epoch [6/20],Test AUROC: 0.8490
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]                                                                 epoch_loss: 0.11370152235031128
Epoch [7/20], Loss: 0.1137
Epoch [7/20],Test AUROC: 0.8463
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                 epoch_loss: 0.07182000577449799
Epoch [8/20], Loss: 0.0718
Epoch [8/20],Test AUROC: 0.8436
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]                                                                 epoch_loss: 0.04428355395793915
Epoch [9/20], Loss: 0.0443
Epoch [9/20],Test AUROC: 0.8431
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.02689426951110363
Epoch [10/20], Loss: 0.0269
Epoch [10/20],Test AUROC: 0.8414
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.016616009175777435
Epoch [11/20], Loss: 0.0166
Epoch [11/20],Test AUROC: 0.8413
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]                                                                  epoch_loss: 0.010615350678563118
Epoch [12/20], Loss: 0.0106
Epoch [12/20],Test AUROC: 0.8413
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.007016611285507679
Epoch [13/20], Loss: 0.0070
Epoch [13/20],Test AUROC: 0.8419
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]                                                                  epoch_loss: 0.004790154285728931
Epoch [14/20], Loss: 0.0048
Epoch [14/20],Test AUROC: 0.8410
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.0033703327644616365
Epoch [15/20], Loss: 0.0034
Epoch [15/20],Test AUROC: 0.8409
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.002431637840345502
Epoch [16/20], Loss: 0.0024
Epoch [16/20],Test AUROC: 0.8405
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]                                                                  epoch_loss: 0.0017984427977353334
Epoch [17/20], Loss: 0.0018
Epoch [17/20],Test AUROC: 0.8398
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]                                                                  epoch_loss: 0.0013561114901676774
Epoch [18/20], Loss: 0.0014
Epoch [18/20],Test AUROC: 0.8406
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]                                                                  epoch_loss: 0.0010402742773294449
Epoch [19/20], Loss: 0.0010
Epoch [19/20],Test AUROC: 0.8405
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]                                                                  epoch_loss: 0.0008114699739962816
Epoch [20/20], Loss: 0.0008
Epoch [20/20],Test AUROC: 0.8402
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.12it/s] 50%|█████     | 2/4 [00:01<00:01,  1.06it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]100%|██████████| 4/4 [00:03<00:00,  1.08it/s]100%|██████████| 4/4 [00:03<00:00,  1.08it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.0005360499955713749
Epoch [1/20], Loss: 0.0005
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.00041471857111901044
Epoch [2/20], Loss: 0.0004
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 3/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.0003223455452825874
Epoch [3/20], Loss: 0.0003
Epoch 4/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 4/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.0002517572371289134
Epoch [4/20], Loss: 0.0003
Epoch 5/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 5/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.00019755337852984668
Epoch [5/20], Loss: 0.0002
Epoch 6/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 6/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.00015572094125673174
Epoch [6/20], Loss: 0.0002
Epoch 7/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 7/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 0.00012335809005890042
Epoch [7/20], Loss: 0.0001
Epoch 8/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 8/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 9.826101886574179e-05
Epoch [8/20], Loss: 0.0001
Epoch 9/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 9/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                 epoch_loss: 7.86287768278271e-05
Epoch [9/20], Loss: 0.0001
Epoch 10/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 10/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 6.319984968286007e-05
Epoch [10/20], Loss: 0.0001
Epoch 11/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.06s/it]Epoch 11/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 5.1076876843580976e-05
Epoch [11/20], Loss: 0.0001
Epoch 12/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 12/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 4.146581050008535e-05
Epoch [12/20], Loss: 0.0000
Epoch 13/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.06s/it]Epoch 13/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 3.3839032403193416e-05
Epoch [13/20], Loss: 0.0000
Epoch 14/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 14/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 2.7750926528824492e-05
Epoch [14/20], Loss: 0.0000
Epoch 15/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 15/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 2.2872874251333996e-05
Epoch [15/20], Loss: 0.0000
Epoch 16/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 16/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 1.894780361908488e-05
Epoch [16/20], Loss: 0.0000
Epoch 17/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 17/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 1.577378607180435e-05
Epoch [17/20], Loss: 0.0000
Epoch 18/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 18/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 1.3182426482671871e-05
Epoch [18/20], Loss: 0.0000
Epoch 19/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 19/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 1.1085054211434908e-05
Epoch [19/20], Loss: 0.0000
Epoch 20/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.05s/it]Epoch 20/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.50it/s]                                                                  epoch_loss: 9.35426251089666e-06
Epoch [20/20], Loss: 0.0000
best_test_auroc: 0.8489677419354837
