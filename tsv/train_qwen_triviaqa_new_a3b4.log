Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   1%|          | 121/17944 [00:00<00:15, 1184.65 examples/s]Map:   1%|▏         | 243/17944 [00:00<00:14, 1196.19 examples/s]Map:   2%|▏         | 372/17944 [00:00<00:14, 1233.63 examples/s]Map:   3%|▎         | 501/17944 [00:00<00:13, 1252.46 examples/s]Map:   4%|▍         | 691/17944 [00:00<00:13, 1256.16 examples/s]Map:   5%|▍         | 821/17944 [00:00<00:13, 1266.55 examples/s]Map:   5%|▌         | 951/17944 [00:00<00:13, 1274.43 examples/s]Map:   6%|▌         | 1081/17944 [00:00<00:13, 1280.36 examples/s]Map:   7%|▋         | 1273/17944 [00:01<00:13, 1277.32 examples/s]Map:   8%|▊         | 1404/17944 [00:01<00:12, 1282.68 examples/s]Map:   9%|▊         | 1534/17944 [00:01<00:12, 1285.12 examples/s]Map:  10%|▉         | 1727/17944 [00:01<00:12, 1282.71 examples/s]Map:  10%|█         | 1858/17944 [00:01<00:12, 1285.89 examples/s]Map:  11%|█         | 1989/17944 [00:01<00:12, 1290.12 examples/s]Map:  12%|█▏        | 2120/17944 [00:01<00:12, 1292.75 examples/s]Map:  13%|█▎        | 2315/17944 [00:01<00:12, 1292.82 examples/s]Map:  14%|█▎        | 2447/17944 [00:01<00:11, 1296.25 examples/s]Map:  14%|█▍        | 2578/17944 [00:02<00:11, 1297.90 examples/s]Map:  15%|█▌        | 2773/17944 [00:02<00:11, 1294.42 examples/s]Map:  16%|█▌        | 2904/17944 [00:02<00:11, 1296.67 examples/s]Map:  17%|█▋        | 3036/17944 [00:02<00:11, 1298.88 examples/s]Map:  18%|█▊        | 3168/17944 [00:02<00:11, 1299.83 examples/s]Map:  19%|█▊        | 3361/17944 [00:02<00:11, 1292.68 examples/s]Map:  19%|█▉        | 3493/17944 [00:02<00:11, 1296.04 examples/s]Map:  20%|██        | 3623/17944 [00:02<00:11, 1293.73 examples/s]Map:  21%|██▏       | 3818/17944 [00:02<00:10, 1290.52 examples/s]Map:  22%|██▏       | 3949/17944 [00:03<00:10, 1293.84 examples/s]Map:  23%|██▎       | 4144/17944 [00:03<00:10, 1292.05 examples/s]Map:  24%|██▍       | 4275/17944 [00:03<00:10, 1294.47 examples/s]Map:  25%|██▍       | 4405/17944 [00:03<00:10, 1292.83 examples/s]Map:  25%|██▌       | 4535/17944 [00:03<00:10, 1292.16 examples/s]Map:  26%|██▌       | 4666/17944 [00:03<00:10, 1294.47 examples/s]Map:  27%|██▋       | 4797/17944 [00:03<00:10, 1295.39 examples/s]Map:  28%|██▊       | 4990/17944 [00:03<00:10, 1288.30 examples/s]Map:  29%|██▉       | 5183/17944 [00:04<00:09, 1284.23 examples/s]Map:  30%|██▉       | 5314/17944 [00:04<00:09, 1287.01 examples/s]Map:  30%|███       | 5445/17944 [00:04<00:09, 1290.33 examples/s]Map:  31%|███       | 5575/17944 [00:04<00:09, 1289.67 examples/s]Map:  32%|███▏      | 5706/17944 [00:04<00:09, 1292.22 examples/s]Map:  33%|███▎      | 5900/17944 [00:04<00:09, 1288.14 examples/s]Map:  34%|███▎      | 6029/17944 [00:04<00:09, 1287.43 examples/s]Map:  34%|███▍      | 6160/17944 [00:04<00:09, 1289.40 examples/s]Map:  35%|███▌      | 6292/17944 [00:04<00:08, 1294.72 examples/s]Map:  36%|███▌      | 6423/17944 [00:04<00:08, 1295.54 examples/s]Map:  37%|███▋      | 6553/17944 [00:05<00:08, 1295.82 examples/s]Map:  37%|███▋      | 6684/17944 [00:05<00:08, 1296.33 examples/s]Map:  38%|███▊      | 6814/17944 [00:05<00:08, 1294.75 examples/s]Map:  39%|███▊      | 6946/17944 [00:05<00:08, 1298.71 examples/s]Map:  39%|███▉      | 7077/17944 [00:05<00:08, 1299.16 examples/s]Map:  40%|████      | 7209/17944 [00:05<00:08, 1302.17 examples/s]Map:  41%|████▏     | 7405/17944 [00:05<00:08, 1300.88 examples/s]Map:  42%|████▏     | 7537/17944 [00:05<00:07, 1301.99 examples/s]Map:  43%|████▎     | 7669/17944 [00:05<00:07, 1303.36 examples/s]Map:  43%|████▎     | 7801/17944 [00:06<00:07, 1304.40 examples/s]Map:  44%|████▍     | 7932/17944 [00:06<00:07, 1301.72 examples/s]Map:  45%|████▍     | 8064/17944 [00:06<00:07, 1301.96 examples/s]Map:  46%|████▌     | 8254/17944 [00:06<00:07, 1284.66 examples/s]Map:  47%|████▋     | 8384/17944 [00:06<00:07, 1288.42 examples/s]Map:  48%|████▊     | 8579/17944 [00:06<00:07, 1287.63 examples/s]Map:  49%|████▉     | 8759/17944 [00:06<00:07, 1254.42 examples/s]Map:  50%|████▉     | 8890/17944 [00:06<00:07, 1265.52 examples/s]Map:  50%|█████     | 9021/17944 [00:07<00:07, 1274.28 examples/s]Map:  51%|█████     | 9150/17944 [00:07<00:06, 1275.55 examples/s]Map:  52%|█████▏    | 9336/17944 [00:07<00:06, 1257.64 examples/s]Map:  53%|█████▎    | 9468/17944 [00:07<00:06, 1270.43 examples/s]Map:  54%|█████▍    | 9659/17944 [00:07<00:06, 1269.91 examples/s]Map:  55%|█████▍    | 9789/17944 [00:07<00:06, 1275.55 examples/s]Map:  55%|█████▌    | 9919/17944 [00:07<00:06, 1280.74 examples/s]Map:  64%|██████▎   | 11427/17944 [00:07<00:01, 5063.64 examples/s]Map:  75%|███████▍  | 13383/17944 [00:07<00:00, 9142.91 examples/s]Map:  85%|████████▌ | 15256/17944 [00:08<00:00, 11891.14 examples/s]Map:  96%|█████████▌| 17177/17944 [00:08<00:00, 14016.64 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2149.30 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  2%|▏         | 155/9960 [00:00<00:06, 1543.15it/s]  3%|▎         | 314/9960 [00:00<00:06, 1569.14it/s]  5%|▍         | 483/9960 [00:00<00:05, 1619.29it/s]  7%|▋         | 651/9960 [00:00<00:05, 1641.08it/s]  8%|▊         | 816/9960 [00:00<00:05, 1628.62it/s] 10%|▉         | 984/9960 [00:00<00:05, 1645.75it/s] 12%|█▏        | 1153/9960 [00:00<00:05, 1658.64it/s] 13%|█▎        | 1325/9960 [00:00<00:05, 1677.16it/s] 15%|█▍        | 1493/9960 [00:00<00:05, 1670.32it/s] 17%|█▋        | 1662/9960 [00:01<00:04, 1673.80it/s] 18%|█▊        | 1830/9960 [00:01<00:04, 1666.73it/s] 20%|██        | 1999/9960 [00:01<00:04, 1671.95it/s] 22%|██▏       | 2172/9960 [00:01<00:04, 1689.02it/s] 24%|██▎       | 2343/9960 [00:01<00:04, 1693.99it/s] 25%|██▌       | 2513/9960 [00:01<00:04, 1691.39it/s] 27%|██▋       | 2684/9960 [00:01<00:04, 1694.60it/s] 29%|██▊       | 2854/9960 [00:01<00:04, 1672.11it/s] 30%|███       | 3022/9960 [00:01<00:04, 1665.33it/s] 32%|███▏      | 3189/9960 [00:01<00:04, 1665.75it/s] 34%|███▎      | 3360/9960 [00:02<00:03, 1676.44it/s] 35%|███▌      | 3528/9960 [00:02<00:03, 1669.83it/s] 37%|███▋      | 3696/9960 [00:02<00:03, 1660.65it/s] 39%|███▉      | 3863/9960 [00:02<00:03, 1649.31it/s] 40%|████      | 4028/9960 [00:02<00:03, 1630.27it/s] 42%|████▏     | 4192/9960 [00:02<00:03, 1623.69it/s] 44%|████▎     | 4355/9960 [00:02<00:03, 1622.53it/s] 45%|████▌     | 4518/9960 [00:02<00:03, 1609.99it/s] 47%|████▋     | 4680/9960 [00:02<00:03, 1595.27it/s] 49%|████▊     | 4851/9960 [00:02<00:03, 1628.39it/s] 50%|█████     | 5025/9960 [00:03<00:02, 1660.40it/s] 52%|█████▏    | 5197/9960 [00:03<00:02, 1676.25it/s] 54%|█████▍    | 5369/9960 [00:03<00:02, 1688.25it/s] 56%|█████▌    | 5543/9960 [00:03<00:02, 1701.95it/s] 57%|█████▋    | 5714/9960 [00:03<00:02, 1703.45it/s] 59%|█████▉    | 5885/9960 [00:03<00:02, 1696.54it/s] 61%|██████    | 6056/9960 [00:03<00:02, 1700.03it/s] 63%|██████▎   | 6227/9960 [00:03<00:02, 1700.53it/s] 64%|██████▍   | 6400/9960 [00:03<00:02, 1709.03it/s] 66%|██████▌   | 6571/9960 [00:03<00:01, 1703.91it/s] 68%|██████▊   | 6742/9960 [00:04<00:01, 1695.15it/s] 69%|██████▉   | 6915/9960 [00:04<00:01, 1705.19it/s] 71%|███████   | 7088/9960 [00:04<00:01, 1711.17it/s] 73%|███████▎  | 7260/9960 [00:04<00:01, 1712.23it/s] 75%|███████▍  | 7432/9960 [00:04<00:01, 1709.93it/s] 76%|███████▋  | 7604/9960 [00:04<00:01, 1668.79it/s] 78%|███████▊  | 7772/9960 [00:04<00:01, 1613.67it/s] 80%|███████▉  | 7940/9960 [00:04<00:01, 1631.30it/s] 81%|████████▏ | 8110/9960 [00:04<00:01, 1649.91it/s] 83%|████████▎ | 8280/9960 [00:04<00:01, 1661.97it/s] 85%|████████▍ | 8450/9960 [00:05<00:00, 1672.62it/s] 87%|████████▋ | 8618/9960 [00:05<00:00, 1655.78it/s] 88%|████████▊ | 8785/9960 [00:05<00:00, 1658.80it/s] 90%|████████▉ | 8960/9960 [00:05<00:00, 1683.37it/s] 92%|█████████▏| 9133/9960 [00:05<00:00, 1695.60it/s] 93%|█████████▎| 9309/9960 [00:05<00:00, 1712.36it/s] 95%|█████████▌| 9485/9960 [00:05<00:00, 1724.07it/s] 97%|█████████▋| 9658/9960 [00:05<00:00, 1706.84it/s] 99%|█████████▊| 9829/9960 [00:05<00:00, 1683.31it/s]100%|██████████| 9960/9960 [00:05<00:00, 1670.42it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]                                                                 epoch_loss: 0.6982091665267944
Epoch [1/20], Loss: 0.6982
Best test AUROC: 0.6924, at epoch: 0
Epoch [1/20],Test AUROC: 0.6924
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.6477978229522705
Epoch [2/20], Loss: 0.6478
Best test AUROC: 0.7937, at epoch: 1
Epoch [2/20],Test AUROC: 0.7937
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.40905526280403137
Epoch [3/20], Loss: 0.4091
Best test AUROC: 0.8044, at epoch: 2
Epoch [3/20],Test AUROC: 0.8044
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.23037883639335632
Epoch [4/20], Loss: 0.2304
Best test AUROC: 0.8081, at epoch: 3
Epoch [4/20],Test AUROC: 0.8081
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.11392541229724884
Epoch [5/20], Loss: 0.1139
Best test AUROC: 0.8093, at epoch: 4
Epoch [5/20],Test AUROC: 0.8093
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.051223307847976685
Epoch [6/20], Loss: 0.0512
Epoch [6/20],Test AUROC: 0.8093
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.02220284566283226
Epoch [7/20], Loss: 0.0222
Epoch [7/20],Test AUROC: 0.8086
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.00998205877840519
Epoch [8/20], Loss: 0.0100
Epoch [8/20],Test AUROC: 0.8073
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.004840872250497341
Epoch [9/20], Loss: 0.0048
Epoch [9/20],Test AUROC: 0.8060
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.002549968659877777
Epoch [10/20], Loss: 0.0025
Epoch [10/20],Test AUROC: 0.8048
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0014518351526930928
Epoch [11/20], Loss: 0.0015
Epoch [11/20],Test AUROC: 0.8040
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0008824551478028297
Epoch [12/20], Loss: 0.0009
Epoch [12/20],Test AUROC: 0.8033
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0005670742830261588
Epoch [13/20], Loss: 0.0006
Epoch [13/20],Test AUROC: 0.8026
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.00038177857641130686
Epoch [14/20], Loss: 0.0004
Epoch [14/20],Test AUROC: 0.8020
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.0002675428113434464
Epoch [15/20], Loss: 0.0003
Epoch [15/20],Test AUROC: 0.8016
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.00019376928685232997
Epoch [16/20], Loss: 0.0002
Epoch [16/20],Test AUROC: 0.8011
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.00014423401444219053
Epoch [17/20], Loss: 0.0001
Epoch [17/20],Test AUROC: 0.8008
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.00010993323667207733
Epoch [18/20], Loss: 0.0001
Epoch [18/20],Test AUROC: 0.8004
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 8.558903937228024e-05
Epoch [19/20], Loss: 0.0001
Epoch [19/20],Test AUROC: 0.8003
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                  epoch_loss: 6.781990668969229e-05
Epoch [20/20], Loss: 0.0001
Epoch [20/20],Test AUROC: 0.8001
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:55,  2.05it/s]  2%|▏         | 2/115 [00:01<00:58,  1.92it/s]  3%|▎         | 3/115 [00:01<00:49,  2.28it/s]  3%|▎         | 4/115 [00:01<00:53,  2.09it/s]  4%|▍         | 5/115 [00:02<00:53,  2.04it/s]  5%|▌         | 6/115 [00:02<00:50,  2.16it/s]  6%|▌         | 7/115 [00:03<00:46,  2.32it/s]  7%|▋         | 8/115 [00:03<00:46,  2.32it/s]  8%|▊         | 9/115 [00:04<00:48,  2.20it/s]  9%|▊         | 10/115 [00:04<00:50,  2.08it/s] 10%|▉         | 11/115 [00:05<00:45,  2.30it/s] 10%|█         | 12/115 [00:05<00:49,  2.09it/s] 11%|█▏        | 13/115 [00:06<00:49,  2.06it/s] 12%|█▏        | 14/115 [00:06<00:49,  2.02it/s] 13%|█▎        | 15/115 [00:06<00:44,  2.23it/s] 14%|█▍        | 16/115 [00:07<00:48,  2.02it/s] 15%|█▍        | 17/115 [00:08<00:50,  1.93it/s] 16%|█▌        | 18/115 [00:08<00:52,  1.86it/s] 17%|█▋        | 19/115 [00:09<00:45,  2.09it/s] 17%|█▋        | 20/115 [00:09<00:44,  2.15it/s] 18%|█▊        | 21/115 [00:10<00:45,  2.06it/s] 19%|█▉        | 22/115 [00:10<00:45,  2.03it/s] 20%|██        | 23/115 [00:10<00:40,  2.25it/s] 21%|██        | 24/115 [00:11<00:39,  2.30it/s] 22%|██▏       | 25/115 [00:11<00:36,  2.47it/s] 23%|██▎       | 26/115 [00:11<00:34,  2.60it/s] 23%|██▎       | 27/115 [00:12<00:37,  2.32it/s] 24%|██▍       | 28/115 [00:13<00:40,  2.14it/s] 25%|██▌       | 29/115 [00:13<00:45,  1.91it/s] 26%|██▌       | 30/115 [00:14<00:44,  1.89it/s] 27%|██▋       | 31/115 [00:14<00:40,  2.05it/s] 28%|██▊       | 32/115 [00:15<00:40,  2.04it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.91it/s] 30%|██▉       | 34/115 [00:16<00:41,  1.97it/s] 30%|███       | 35/115 [00:16<00:39,  2.03it/s] 31%|███▏      | 36/115 [00:17<00:40,  1.96it/s] 32%|███▏      | 37/115 [00:17<00:41,  1.90it/s] 33%|███▎      | 38/115 [00:18<00:39,  1.94it/s] 34%|███▍      | 39/115 [00:18<00:36,  2.08it/s] 35%|███▍      | 40/115 [00:19<00:34,  2.15it/s] 36%|███▌      | 41/115 [00:19<00:38,  1.94it/s] 37%|███▋      | 42/115 [00:20<00:37,  1.96it/s] 37%|███▋      | 43/115 [00:20<00:42,  1.70it/s] 38%|███▊      | 44/115 [00:21<00:46,  1.52it/s] 39%|███▉      | 45/115 [00:22<00:44,  1.58it/s] 40%|████      | 46/115 [00:22<00:42,  1.61it/s] 41%|████      | 47/115 [00:23<00:39,  1.71it/s] 42%|████▏     | 48/115 [00:24<00:56,  1.19it/s] 43%|████▎     | 49/115 [00:25<00:51,  1.27it/s] 43%|████▎     | 50/115 [00:26<00:46,  1.39it/s] 44%|████▍     | 51/115 [00:26<00:42,  1.52it/s] 45%|████▌     | 52/115 [00:27<00:41,  1.51it/s] 46%|████▌     | 53/115 [00:27<00:40,  1.54it/s] 47%|████▋     | 54/115 [00:28<00:38,  1.60it/s] 48%|████▊     | 55/115 [00:28<00:32,  1.87it/s] 49%|████▊     | 56/115 [00:29<00:29,  1.99it/s] 50%|████▉     | 57/115 [00:29<00:25,  2.27it/s] 50%|█████     | 58/115 [00:29<00:23,  2.40it/s] 51%|█████▏    | 59/115 [00:30<00:21,  2.61it/s] 52%|█████▏    | 60/115 [00:30<00:23,  2.33it/s] 53%|█████▎    | 61/115 [00:31<00:23,  2.28it/s] 54%|█████▍    | 62/115 [00:31<00:24,  2.15it/s] 55%|█████▍    | 63/115 [00:32<00:26,  1.94it/s] 56%|█████▌    | 64/115 [00:32<00:25,  2.00it/s] 57%|█████▋    | 65/115 [00:33<00:24,  2.06it/s] 57%|█████▋    | 66/115 [00:33<00:24,  1.98it/s] 58%|█████▊    | 67/115 [00:34<00:22,  2.16it/s] 59%|█████▉    | 68/115 [00:34<00:20,  2.25it/s] 60%|██████    | 69/115 [00:35<00:21,  2.17it/s] 61%|██████    | 70/115 [00:35<00:21,  2.11it/s] 62%|██████▏   | 71/115 [00:36<00:20,  2.13it/s] 63%|██████▎   | 72/115 [00:36<00:20,  2.08it/s] 63%|██████▎   | 73/115 [00:36<00:18,  2.24it/s] 64%|██████▍   | 74/115 [00:37<00:17,  2.33it/s] 65%|██████▌   | 75/115 [00:37<00:17,  2.30it/s] 66%|██████▌   | 76/115 [00:38<00:18,  2.13it/s] 67%|██████▋   | 77/115 [00:38<00:18,  2.03it/s] 68%|██████▊   | 78/115 [00:39<00:16,  2.18it/s] 69%|██████▊   | 79/115 [00:39<00:17,  2.08it/s] 70%|██████▉   | 80/115 [00:40<00:15,  2.23it/s] 70%|███████   | 81/115 [00:40<00:14,  2.29it/s] 71%|███████▏  | 82/115 [00:40<00:14,  2.30it/s] 72%|███████▏  | 83/115 [00:41<00:13,  2.37it/s] 73%|███████▎  | 84/115 [00:41<00:13,  2.23it/s] 74%|███████▍  | 85/115 [00:42<00:13,  2.19it/s] 75%|███████▍  | 86/115 [00:42<00:14,  2.07it/s] 76%|███████▌  | 87/115 [00:43<00:15,  1.85it/s] 77%|███████▋  | 88/115 [00:44<00:14,  1.90it/s] 77%|███████▋  | 89/115 [00:44<00:11,  2.17it/s] 78%|███████▊  | 90/115 [00:44<00:11,  2.19it/s] 79%|███████▉  | 91/115 [00:45<00:12,  1.89it/s] 80%|████████  | 92/115 [00:46<00:12,  1.78it/s] 81%|████████  | 93/115 [00:46<00:12,  1.79it/s] 82%|████████▏ | 94/115 [00:47<00:11,  1.89it/s] 83%|████████▎ | 95/115 [00:47<00:10,  1.95it/s] 83%|████████▎ | 96/115 [00:48<00:10,  1.82it/s] 84%|████████▍ | 97/115 [00:48<00:09,  1.89it/s] 85%|████████▌ | 98/115 [00:49<00:08,  2.06it/s] 86%|████████▌ | 99/115 [00:49<00:07,  2.13it/s] 87%|████████▋ | 100/115 [00:49<00:06,  2.29it/s] 88%|████████▊ | 101/115 [00:50<00:06,  2.20it/s] 89%|████████▊ | 102/115 [00:50<00:06,  2.14it/s] 90%|████████▉ | 103/115 [00:51<00:05,  2.35it/s] 90%|█████████ | 104/115 [00:51<00:04,  2.27it/s] 91%|█████████▏| 105/115 [00:52<00:03,  2.58it/s] 92%|█████████▏| 106/115 [00:52<00:03,  2.38it/s] 93%|█████████▎| 107/115 [00:52<00:03,  2.45it/s] 94%|█████████▍| 108/115 [00:53<00:02,  2.65it/s] 95%|█████████▍| 109/115 [00:53<00:02,  2.77it/s] 96%|█████████▌| 110/115 [00:54<00:02,  1.88it/s] 97%|█████████▋| 111/115 [00:55<00:02,  1.66it/s] 97%|█████████▋| 112/115 [00:56<00:02,  1.14it/s] 98%|█████████▊| 113/115 [00:57<00:01,  1.35it/s] 99%|█████████▉| 114/115 [00:57<00:00,  1.53it/s]100%|██████████| 115/115 [00:57<00:00,  1.99it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 2.8394881762020912e-05
Epoch [1/20], Loss: 0.0000
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 2.1158518696514268e-05
Epoch [2/20], Loss: 0.0000
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 1.5928973274033826e-05
Epoch [3/20], Loss: 0.0000
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 1.208685868429408e-05
Epoch [4/20], Loss: 0.0000
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 9.258684864713965e-06
Epoch [5/20], Loss: 0.0000
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 7.156343826864031e-06
Epoch [6/20], Loss: 0.0000
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 5.588595892428809e-06
Epoch [7/20], Loss: 0.0000
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 4.392764064202008e-06
Epoch [8/20], Loss: 0.0000
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 3.4887516828045286e-06
Epoch [9/20], Loss: 0.0000
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 2.7939794714863333e-06
Epoch [10/20], Loss: 0.0000
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 2.2544297735294094e-06
Epoch [11/20], Loss: 0.0000
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 1.830365022215119e-06
Epoch [12/20], Loss: 0.0000
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 1.5044004915883609e-06
Epoch [13/20], Loss: 0.0000
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 1.24424991554406e-06
Epoch [14/20], Loss: 0.0000
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 1.0350120381493373e-06
Epoch [15/20], Loss: 0.0000
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 8.642689219110858e-07
Epoch [16/20], Loss: 0.0000
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 7.407131192849192e-07
Epoch [17/20], Loss: 0.0000
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 6.183991274610889e-07
Epoch [18/20], Loss: 0.0000
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 5.41409567252534e-07
Epoch [19/20], Loss: 0.0000
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 4.5883213791360805e-07
Epoch [20/20], Loss: 0.0000
best_test_auroc: 0.80930942309324
