Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   1%|          | 117/17944 [00:00<00:15, 1140.99 examples/s]Map:   1%|▏         | 246/17944 [00:00<00:14, 1220.07 examples/s]Map:   2%|▏         | 375/17944 [00:00<00:14, 1244.84 examples/s]Map:   3%|▎         | 505/17944 [00:00<00:13, 1259.61 examples/s]Map:   4%|▍         | 679/17944 [00:00<00:14, 1212.03 examples/s]Map:   5%|▍         | 847/17944 [00:00<00:14, 1170.99 examples/s]Map:   5%|▌         | 977/17944 [00:00<00:14, 1203.75 examples/s]Map:   6%|▌         | 1108/17944 [00:00<00:13, 1229.05 examples/s]Map:   7%|▋         | 1238/17944 [00:01<00:13, 1247.83 examples/s]Map:   8%|▊         | 1369/17944 [00:01<00:13, 1262.03 examples/s]Map:   8%|▊         | 1500/17944 [00:01<00:12, 1273.52 examples/s]Map:   9%|▉         | 1630/17944 [00:01<00:12, 1280.97 examples/s]Map:  10%|█         | 1808/17944 [00:01<00:13, 1240.36 examples/s]Map:  11%|█         | 1964/17944 [00:01<00:13, 1166.04 examples/s]Map:  12%|█▏        | 2095/17944 [00:01<00:13, 1199.45 examples/s]Map:  12%|█▏        | 2226/17944 [00:01<00:12, 1226.64 examples/s]Map:  13%|█▎        | 2357/17944 [00:01<00:12, 1247.08 examples/s]Map:  14%|█▍        | 2489/17944 [00:02<00:12, 1263.46 examples/s]Map:  15%|█▍        | 2621/17944 [00:02<00:12, 1275.12 examples/s]Map:  15%|█▌        | 2751/17944 [00:02<00:11, 1281.97 examples/s]Map:  16%|█▌        | 2881/17944 [00:02<00:11, 1285.96 examples/s]Map:  17%|█▋        | 3034/17944 [00:02<00:12, 1175.54 examples/s]Map:  18%|█▊        | 3165/17944 [00:02<00:12, 1209.16 examples/s]Map:  18%|█▊        | 3296/17944 [00:02<00:11, 1234.75 examples/s]Map:  19%|█▉        | 3426/17944 [00:02<00:11, 1248.42 examples/s]Map:  20%|█▉        | 3556/17944 [00:02<00:11, 1261.76 examples/s]Map:  21%|██        | 3687/17944 [00:02<00:11, 1272.64 examples/s]Map:  21%|██▏       | 3817/17944 [00:03<00:11, 1278.15 examples/s]Map:  22%|██▏       | 3946/17944 [00:03<00:10, 1279.49 examples/s]Map:  23%|██▎       | 4106/17944 [00:03<00:11, 1191.96 examples/s]Map:  24%|██▍       | 4278/17944 [00:03<00:11, 1171.63 examples/s]Map:  25%|██▍       | 4409/17944 [00:03<00:11, 1203.85 examples/s]Map:  25%|██▌       | 4540/17944 [00:03<00:10, 1228.40 examples/s]Map:  26%|██▌       | 4669/17944 [00:03<00:10, 1244.71 examples/s]Map:  27%|██▋       | 4799/17944 [00:03<00:10, 1258.18 examples/s]Map:  27%|██▋       | 4929/17944 [00:03<00:10, 1267.42 examples/s]Map:  28%|██▊       | 5110/17944 [00:04<00:10, 1238.48 examples/s]Map:  29%|██▉       | 5260/17944 [00:04<00:11, 1150.30 examples/s]Map:  30%|███       | 5391/17944 [00:04<00:10, 1186.93 examples/s]Map:  31%|███       | 5522/17944 [00:04<00:10, 1216.07 examples/s]Map:  32%|███▏      | 5653/17944 [00:04<00:09, 1239.32 examples/s]Map:  32%|███▏      | 5784/17944 [00:04<00:09, 1256.50 examples/s]Map:  33%|███▎      | 5912/17944 [00:04<00:09, 1259.62 examples/s]Map:  34%|███▎      | 6042/17944 [00:04<00:09, 1268.22 examples/s]Map:  35%|███▍      | 6205/17944 [00:05<00:09, 1194.54 examples/s]Map:  35%|███▌      | 6335/17944 [00:05<00:09, 1222.11 examples/s]Map:  36%|███▌      | 6465/17944 [00:05<00:09, 1242.16 examples/s]Map:  37%|███▋      | 6596/17944 [00:05<00:09, 1257.80 examples/s]Map:  37%|███▋      | 6723/17944 [00:05<00:08, 1259.44 examples/s]Map:  38%|███▊      | 6853/17944 [00:05<00:08, 1269.12 examples/s]Map:  39%|███▉      | 6984/17944 [00:05<00:08, 1278.41 examples/s]Map:  40%|███▉      | 7115/17944 [00:05<00:08, 1283.42 examples/s]Map:  40%|████      | 7245/17944 [00:05<00:08, 1287.70 examples/s]Map:  41%|████▏     | 7425/17944 [00:06<00:08, 1246.94 examples/s]Map:  42%|████▏     | 7555/17944 [00:06<00:08, 1260.04 examples/s]Map:  43%|████▎     | 7682/17944 [00:06<00:08, 1261.25 examples/s]Map:  44%|████▎     | 7812/17944 [00:06<00:07, 1270.21 examples/s]Map:  44%|████▍     | 7943/17944 [00:06<00:07, 1277.50 examples/s]Map:  45%|████▍     | 8073/17944 [00:06<00:07, 1282.38 examples/s]Map:  46%|████▌     | 8204/17944 [00:06<00:07, 1286.07 examples/s]Map:  46%|████▋     | 8335/17944 [00:06<00:07, 1289.57 examples/s]Map:  47%|████▋     | 8515/17944 [00:06<00:07, 1252.68 examples/s]Map:  48%|████▊     | 8646/17944 [00:06<00:07, 1264.47 examples/s]Map:  49%|████▉     | 8774/17944 [00:07<00:07, 1266.88 examples/s]Map:  50%|████▉     | 8904/17944 [00:07<00:07, 1273.92 examples/s]Map:  50%|█████     | 9034/17944 [00:07<00:06, 1280.47 examples/s]Map:  51%|█████     | 9164/17944 [00:07<00:06, 1285.28 examples/s]Map:  52%|█████▏    | 9294/17944 [00:07<00:06, 1288.30 examples/s]Map:  53%|█████▎    | 9489/17944 [00:07<00:06, 1290.08 examples/s]Map:  54%|█████▍    | 9672/17944 [00:07<00:06, 1259.01 examples/s]Map:  55%|█████▍    | 9802/17944 [00:07<00:06, 1267.70 examples/s]Map:  55%|█████▌    | 9933/17944 [00:07<00:06, 1275.28 examples/s]Map:  65%|██████▍   | 11619/17944 [00:08<00:01, 5535.62 examples/s]Map:  76%|███████▌  | 13600/17944 [00:08<00:00, 9543.45 examples/s]Map:  87%|████████▋ | 15527/17944 [00:08<00:00, 12326.39 examples/s]Map:  97%|█████████▋| 17461/17944 [00:08<00:00, 14360.83 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2091.31 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.59s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.40s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  2%|▏         | 158/9960 [00:00<00:06, 1574.34it/s]  3%|▎         | 329/9960 [00:00<00:05, 1650.03it/s]  5%|▌         | 503/9960 [00:00<00:05, 1689.41it/s]  7%|▋         | 672/9960 [00:00<00:05, 1663.41it/s]  8%|▊         | 839/9960 [00:00<00:05, 1593.74it/s] 10%|█         | 999/9960 [00:00<00:06, 1451.56it/s] 12%|█▏        | 1167/9960 [00:00<00:05, 1517.75it/s] 13%|█▎        | 1336/9960 [00:00<00:05, 1568.20it/s] 15%|█▌        | 1502/9960 [00:00<00:05, 1595.61it/s] 17%|█▋        | 1669/9960 [00:01<00:05, 1615.16it/s] 18%|█▊        | 1839/9960 [00:01<00:04, 1637.86it/s] 20%|██        | 2009/9960 [00:01<00:04, 1654.79it/s] 22%|██▏       | 2178/9960 [00:01<00:04, 1663.27it/s] 24%|██▎       | 2345/9960 [00:01<00:04, 1663.72it/s] 25%|██▌       | 2512/9960 [00:01<00:04, 1660.37it/s] 27%|██▋       | 2679/9960 [00:01<00:04, 1661.21it/s] 29%|██▊       | 2846/9960 [00:02<00:11, 636.22it/s]  30%|███       | 3010/9960 [00:02<00:08, 776.78it/s] 32%|███▏      | 3174/9960 [00:02<00:07, 920.25it/s] 34%|███▎      | 3342/9960 [00:02<00:06, 1065.59it/s] 35%|███▌      | 3510/9960 [00:02<00:05, 1197.20it/s] 37%|███▋      | 3673/9960 [00:02<00:04, 1298.56it/s] 39%|███▊      | 3835/9960 [00:02<00:04, 1377.57it/s] 40%|████      | 3994/9960 [00:02<00:04, 1431.32it/s] 42%|████▏     | 4153/9960 [00:03<00:04, 1450.43it/s] 43%|████▎     | 4315/9960 [00:03<00:03, 1496.12it/s] 45%|████▍     | 4475/9960 [00:03<00:03, 1525.03it/s] 47%|████▋     | 4637/9960 [00:03<00:03, 1550.83it/s] 48%|████▊     | 4806/9960 [00:03<00:03, 1589.23it/s] 50%|████▉     | 4979/9960 [00:03<00:03, 1630.36it/s] 52%|█████▏    | 5151/9960 [00:03<00:02, 1654.76it/s] 53%|█████▎    | 5321/9960 [00:03<00:02, 1667.66it/s] 55%|█████▌    | 5492/9960 [00:03<00:02, 1679.04it/s] 57%|█████▋    | 5661/9960 [00:04<00:02, 1622.65it/s] 59%|█████▊    | 5830/9960 [00:04<00:02, 1639.59it/s] 60%|██████    | 6000/9960 [00:04<00:02, 1657.02it/s] 62%|██████▏   | 6167/9960 [00:04<00:02, 1648.07it/s] 64%|██████▎   | 6333/9960 [00:04<00:02, 1625.39it/s] 65%|██████▌   | 6502/9960 [00:04<00:02, 1644.25it/s] 67%|██████▋   | 6667/9960 [00:05<00:08, 405.83it/s]  69%|██████▊   | 6838/9960 [00:05<00:05, 528.35it/s] 70%|███████   | 6986/9960 [00:05<00:04, 640.94it/s] 72%|███████▏  | 7155/9960 [00:05<00:03, 792.71it/s] 74%|███████▎  | 7323/9960 [00:06<00:02, 944.74it/s] 75%|███████▌  | 7486/9960 [00:06<00:02, 1078.74it/s] 77%|███████▋  | 7647/9960 [00:06<00:01, 1194.08it/s] 78%|███████▊  | 7815/9960 [00:06<00:01, 1309.86it/s] 80%|████████  | 7982/9960 [00:06<00:01, 1400.44it/s] 82%|████████▏ | 8151/9960 [00:06<00:01, 1476.24it/s] 84%|████████▎ | 8320/9960 [00:06<00:01, 1532.79it/s] 85%|████████▌ | 8486/9960 [00:06<00:00, 1529.70it/s] 87%|████████▋ | 8653/9960 [00:06<00:00, 1568.39it/s] 89%|████████▊ | 8820/9960 [00:06<00:00, 1597.47it/s] 90%|█████████ | 8994/9960 [00:07<00:00, 1637.16it/s] 92%|█████████▏| 9166/9960 [00:07<00:00, 1659.47it/s] 94%|█████████▍| 9338/9960 [00:07<00:00, 1677.30it/s] 96%|█████████▌| 9512/9960 [00:07<00:00, 1694.63it/s] 97%|█████████▋| 9683/9960 [00:07<00:00, 1659.85it/s] 99%|█████████▉| 9850/9960 [00:07<00:00, 1643.86it/s]100%|██████████| 9960/9960 [00:07<00:00, 1299.92it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:03<00:00,  3.73s/it]                                                                 epoch_loss: 0.713432788848877
Epoch [1/20], Loss: 0.7134
Best test AUROC: 0.5628, at epoch: 0
Epoch [1/20],Test AUROC: 0.5628
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]                                                                 epoch_loss: 0.6840740442276001
Epoch [2/20], Loss: 0.6841
Best test AUROC: 0.6540, at epoch: 1
Epoch [2/20],Test AUROC: 0.6540
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]                                                                 epoch_loss: 0.6639984846115112
Epoch [3/20], Loss: 0.6640
Best test AUROC: 0.7047, at epoch: 2
Epoch [3/20],Test AUROC: 0.7047
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]                                                                 epoch_loss: 0.6452998518943787
Epoch [4/20], Loss: 0.6453
Best test AUROC: 0.7408, at epoch: 3
Epoch [4/20],Test AUROC: 0.7408
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.6253155469894409
Epoch [5/20], Loss: 0.6253
Best test AUROC: 0.7651, at epoch: 4
Epoch [5/20],Test AUROC: 0.7651
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.604288637638092
Epoch [6/20], Loss: 0.6043
Best test AUROC: 0.7821, at epoch: 5
Epoch [6/20],Test AUROC: 0.7821
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.5827575922012329
Epoch [7/20], Loss: 0.5828
Best test AUROC: 0.7922, at epoch: 6
Epoch [7/20],Test AUROC: 0.7922
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.5594518780708313
Epoch [8/20], Loss: 0.5595
Best test AUROC: 0.7967, at epoch: 7
Epoch [8/20],Test AUROC: 0.7967
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.5350915193557739
Epoch [9/20], Loss: 0.5351
Best test AUROC: 0.7994, at epoch: 8
Epoch [9/20],Test AUROC: 0.7994
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.5066835880279541
Epoch [10/20], Loss: 0.5067
Best test AUROC: 0.8016, at epoch: 9
Epoch [10/20],Test AUROC: 0.8016
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.4804062247276306
Epoch [11/20], Loss: 0.4804
Best test AUROC: 0.8093, at epoch: 10
Epoch [11/20],Test AUROC: 0.8093
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.4461725354194641
Epoch [12/20], Loss: 0.4462
Best test AUROC: 0.8148, at epoch: 11
Epoch [12/20],Test AUROC: 0.8148
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.4126725196838379
Epoch [13/20], Loss: 0.4127
Epoch [13/20],Test AUROC: 0.8111
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.3751791715621948
Epoch [14/20], Loss: 0.3752
Epoch [14/20],Test AUROC: 0.8090
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.3395828604698181
Epoch [15/20], Loss: 0.3396
Epoch [15/20],Test AUROC: 0.8066
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.30674582719802856
Epoch [16/20], Loss: 0.3067
Epoch [16/20],Test AUROC: 0.8118
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.27809208631515503
Epoch [17/20], Loss: 0.2781
Epoch [17/20],Test AUROC: 0.8053
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.2636350393295288
Epoch [18/20], Loss: 0.2636
Epoch [18/20],Test AUROC: 0.7989
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.27141717076301575
Epoch [19/20], Loss: 0.2714
Epoch [19/20],Test AUROC: 0.8073
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.25402089953422546
Epoch [20/20], Loss: 0.2540
Epoch [20/20],Test AUROC: 0.8023
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.11it/s]  2%|▏         | 2/115 [00:00<00:56,  1.98it/s]  3%|▎         | 3/115 [00:01<00:47,  2.34it/s]  3%|▎         | 4/115 [00:01<00:51,  2.15it/s]  4%|▍         | 5/115 [00:02<00:52,  2.10it/s]  5%|▌         | 6/115 [00:02<00:49,  2.22it/s]  6%|▌         | 7/115 [00:03<00:45,  2.39it/s]  7%|▋         | 8/115 [00:03<00:44,  2.39it/s]  8%|▊         | 9/115 [00:04<00:46,  2.26it/s]  9%|▊         | 10/115 [00:04<00:49,  2.14it/s] 10%|▉         | 11/115 [00:04<00:44,  2.36it/s] 10%|█         | 12/115 [00:05<00:47,  2.15it/s] 11%|█▏        | 13/115 [00:05<00:48,  2.12it/s] 12%|█▏        | 14/115 [00:06<00:48,  2.08it/s] 13%|█▎        | 15/115 [00:06<00:43,  2.29it/s] 14%|█▍        | 16/115 [00:07<00:47,  2.08it/s] 15%|█▍        | 17/115 [00:07<00:49,  1.99it/s] 16%|█▌        | 18/115 [00:08<00:50,  1.91it/s] 17%|█▋        | 19/115 [00:08<00:44,  2.15it/s] 17%|█▋        | 20/115 [00:09<00:42,  2.22it/s] 18%|█▊        | 21/115 [00:09<00:44,  2.11it/s] 19%|█▉        | 22/115 [00:10<00:44,  2.08it/s] 20%|██        | 23/115 [00:10<00:39,  2.30it/s] 21%|██        | 24/115 [00:10<00:38,  2.36it/s] 22%|██▏       | 25/115 [00:11<00:35,  2.54it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.68it/s] 23%|██▎       | 27/115 [00:12<00:36,  2.38it/s] 24%|██▍       | 28/115 [00:12<00:39,  2.20it/s] 25%|██▌       | 29/115 [00:13<00:43,  1.96it/s] 26%|██▌       | 30/115 [00:13<00:43,  1.94it/s] 27%|██▋       | 31/115 [00:14<00:39,  2.11it/s] 28%|██▊       | 32/115 [00:14<00:39,  2.09it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.95it/s] 30%|██▉       | 34/115 [00:15<00:40,  2.01it/s] 30%|███       | 35/115 [00:16<00:38,  2.07it/s] 31%|███▏      | 36/115 [00:16<00:39,  2.01it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.94it/s] 33%|███▎      | 38/115 [00:17<00:38,  1.99it/s] 34%|███▍      | 39/115 [00:18<00:35,  2.13it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.20it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.99it/s] 37%|███▋      | 42/115 [00:19<00:36,  2.01it/s] 37%|███▋      | 43/115 [00:20<00:41,  1.74it/s] 38%|███▊      | 44/115 [00:22<01:11,  1.01s/it] 39%|███▉      | 45/115 [00:23<01:01,  1.14it/s] 40%|████      | 46/115 [00:23<00:54,  1.27it/s] 41%|████      | 47/115 [00:25<01:12,  1.06s/it] 42%|████▏     | 48/115 [00:26<01:06,  1.00it/s] 43%|████▎     | 49/115 [00:26<00:58,  1.12it/s] 43%|████▎     | 50/115 [00:27<00:51,  1.27it/s] 44%|████▍     | 51/115 [00:27<00:45,  1.42it/s] 45%|████▌     | 52/115 [00:28<00:43,  1.46it/s] 46%|████▌     | 53/115 [00:29<00:41,  1.51it/s] 47%|████▋     | 54/115 [00:29<00:38,  1.59it/s] 48%|████▊     | 55/115 [00:29<00:32,  1.87it/s] 49%|████▊     | 56/115 [00:30<00:29,  2.00it/s] 50%|████▉     | 57/115 [00:30<00:25,  2.29it/s] 50%|█████     | 58/115 [00:31<00:23,  2.43it/s] 51%|█████▏    | 59/115 [00:31<00:21,  2.66it/s] 52%|█████▏    | 60/115 [00:31<00:23,  2.38it/s] 53%|█████▎    | 61/115 [00:32<00:34,  1.58it/s] 54%|█████▍    | 62/115 [00:33<00:31,  1.67it/s] 55%|█████▍    | 63/115 [00:34<00:31,  1.66it/s] 56%|█████▌    | 64/115 [00:35<00:46,  1.10it/s] 57%|█████▋    | 65/115 [00:36<00:38,  1.31it/s] 57%|█████▋    | 66/115 [00:36<00:34,  1.44it/s] 58%|█████▊    | 67/115 [00:37<00:28,  1.68it/s] 59%|█████▉    | 68/115 [00:39<00:50,  1.07s/it] 60%|██████    | 69/115 [00:39<00:41,  1.12it/s] 61%|██████    | 70/115 [00:40<00:34,  1.29it/s] 62%|██████▏   | 71/115 [00:40<00:29,  1.48it/s] 63%|██████▎   | 72/115 [00:41<00:26,  1.61it/s] 63%|██████▎   | 73/115 [00:41<00:22,  1.85it/s] 64%|██████▍   | 74/115 [00:41<00:20,  2.03it/s] 65%|██████▌   | 75/115 [00:43<00:34,  1.16it/s] 66%|██████▌   | 76/115 [00:44<00:29,  1.30it/s] 67%|██████▋   | 77/115 [00:44<00:26,  1.44it/s] 68%|██████▊   | 78/115 [00:45<00:22,  1.67it/s] 69%|██████▊   | 79/115 [00:45<00:20,  1.74it/s] 70%|██████▉   | 80/115 [00:45<00:17,  1.96it/s] 70%|███████   | 81/115 [00:47<00:24,  1.40it/s] 71%|███████▏  | 82/115 [00:47<00:20,  1.60it/s] 72%|███████▏  | 83/115 [00:47<00:17,  1.82it/s] 73%|███████▎  | 84/115 [00:48<00:16,  1.87it/s] 74%|███████▍  | 85/115 [00:50<00:30,  1.02s/it] 75%|███████▍  | 86/115 [00:51<00:25,  1.15it/s] 76%|███████▌  | 87/115 [00:51<00:22,  1.24it/s] 77%|███████▋  | 88/115 [00:53<00:31,  1.16s/it] 77%|███████▋  | 89/115 [00:54<00:23,  1.11it/s] 78%|███████▊  | 90/115 [00:54<00:19,  1.31it/s] 79%|███████▉  | 91/115 [00:55<00:17,  1.35it/s] 80%|████████  | 92/115 [00:55<00:16,  1.43it/s] 81%|████████  | 93/115 [00:56<00:14,  1.53it/s] 82%|████████▏ | 94/115 [00:57<00:17,  1.22it/s] 83%|████████▎ | 95/115 [00:57<00:14,  1.40it/s] 83%|████████▎ | 96/115 [00:58<00:12,  1.47it/s] 84%|████████▍ | 97/115 [00:59<00:11,  1.61it/s] 85%|████████▌ | 98/115 [00:59<00:09,  1.83it/s] 86%|████████▌ | 99/115 [00:59<00:08,  1.98it/s] 87%|████████▋ | 100/115 [01:00<00:06,  2.18it/s] 88%|████████▊ | 101/115 [01:01<00:08,  1.72it/s] 89%|████████▊ | 102/115 [01:01<00:07,  1.82it/s] 90%|████████▉ | 103/115 [01:01<00:05,  2.08it/s] 90%|█████████ | 104/115 [01:04<00:11,  1.04s/it] 91%|█████████▏| 105/115 [01:04<00:08,  1.25it/s] 92%|█████████▏| 106/115 [01:04<00:06,  1.42it/s] 93%|█████████▎| 107/115 [01:05<00:04,  1.65it/s] 94%|█████████▍| 108/115 [01:05<00:03,  1.94it/s] 95%|█████████▍| 109/115 [01:06<00:03,  1.88it/s] 96%|█████████▌| 110/115 [01:07<00:03,  1.51it/s] 97%|█████████▋| 111/115 [01:07<00:02,  1.45it/s] 97%|█████████▋| 112/115 [01:09<00:02,  1.14it/s] 98%|█████████▊| 113/115 [01:11<00:02,  1.22s/it] 99%|█████████▉| 114/115 [01:11<00:00,  1.01it/s]100%|██████████| 115/115 [01:11<00:00,  1.60it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:02<00:05,  2.51s/it]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:02<00:01,  1.30s/it]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]                                                                 epoch_loss: 0.19995182752609253
Epoch [1/20], Loss: 0.2000
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.17it/s]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.32it/s]                                                                 epoch_loss: 0.17564970503250757
Epoch [2/20], Loss: 0.1756
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.17it/s]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                 epoch_loss: 0.1391132945815722
Epoch [3/20], Loss: 0.1391
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                 epoch_loss: 0.10601703077554703
Epoch [4/20], Loss: 0.1060
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                 epoch_loss: 0.08407574146986008
Epoch [5/20], Loss: 0.0841
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                 epoch_loss: 0.06626091649134953
Epoch [6/20], Loss: 0.0663
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 0.05198024275402228
Epoch [7/20], Loss: 0.0520
Best test AUROC: 0.8148, at epoch: 26
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 0.04081843110422293
Epoch [8/20], Loss: 0.0408
Best test AUROC: 0.8153, at epoch: 27
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 0.03219290698568026
Epoch [9/20], Loss: 0.0322
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.026300625875592232
Epoch [10/20], Loss: 0.0263
Best test AUROC: 0.8155, at epoch: 29
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.020429732277989388
Epoch [11/20], Loss: 0.0204
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.01648637931793928
Epoch [12/20], Loss: 0.0165
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.013209163832167784
Epoch [13/20], Loss: 0.0132
Best test AUROC: 0.8160, at epoch: 32
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.010751790677507719
Epoch [14/20], Loss: 0.0108
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.59it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.00872674211859703
Epoch [15/20], Loss: 0.0087
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 0.007198053567359845
Epoch [16/20], Loss: 0.0072
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.0059477171550194425
Epoch [17/20], Loss: 0.0059
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.004924435323725144
Epoch [18/20], Loss: 0.0049
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.004133432017018397
Epoch [19/20], Loss: 0.0041
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.60it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]                                                                  epoch_loss: 0.003468088029573361
Epoch [20/20], Loss: 0.0035
best_test_auroc: 0.8160111040512557
