Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   1%|          | 121/17944 [00:00<00:15, 1161.51 examples/s]Map:   1%|▏         | 252/17944 [00:00<00:14, 1237.00 examples/s]Map:   2%|▏         | 378/17944 [00:00<00:14, 1242.82 examples/s]Map:   3%|▎         | 509/17944 [00:00<00:13, 1265.41 examples/s]Map:   4%|▎         | 641/17944 [00:00<00:13, 1281.64 examples/s]Map:   4%|▍         | 773/17944 [00:00<00:13, 1292.01 examples/s]Map:   5%|▌         | 959/17944 [00:00<00:13, 1265.87 examples/s]Map:   6%|▋         | 1150/17944 [00:00<00:13, 1264.49 examples/s]Map:   7%|▋         | 1282/17944 [00:01<00:13, 1276.45 examples/s]Map:   8%|▊         | 1415/17944 [00:01<00:12, 1287.15 examples/s]Map:   9%|▊         | 1548/17944 [00:01<00:12, 1295.33 examples/s]Map:   9%|▉         | 1680/17944 [00:01<00:12, 1301.37 examples/s]Map:  10%|█         | 1813/17944 [00:01<00:12, 1306.24 examples/s]Map:  11%|█         | 1946/17944 [00:01<00:12, 1309.05 examples/s]Map:  12%|█▏        | 2079/17944 [00:01<00:12, 1311.57 examples/s]Map:  12%|█▏        | 2211/17944 [00:01<00:11, 1312.90 examples/s]Map:  13%|█▎        | 2407/17944 [00:01<00:11, 1306.66 examples/s]Map:  14%|█▍        | 2539/17944 [00:01<00:11, 1308.74 examples/s]Map:  15%|█▍        | 2671/17944 [00:02<00:11, 1309.21 examples/s]Map:  16%|█▌        | 2803/17944 [00:02<00:11, 1311.00 examples/s]Map:  16%|█▋        | 2935/17944 [00:02<00:11, 1311.70 examples/s]Map:  17%|█▋        | 3067/17944 [00:02<00:11, 1312.39 examples/s]Map:  18%|█▊        | 3199/17944 [00:02<00:11, 1312.75 examples/s]Map:  19%|█▊        | 3331/17944 [00:02<00:11, 1313.87 examples/s]Map:  20%|█▉        | 3521/17944 [00:02<00:11, 1292.33 examples/s]Map:  20%|██        | 3651/17944 [00:02<00:11, 1292.84 examples/s]Map:  21%|██        | 3782/17944 [00:02<00:10, 1294.45 examples/s]Map:  22%|██▏       | 3914/17944 [00:03<00:10, 1299.07 examples/s]Map:  23%|██▎       | 4045/17944 [00:03<00:10, 1298.08 examples/s]Map:  23%|██▎       | 4177/17944 [00:03<00:10, 1301.26 examples/s]Map:  24%|██▍       | 4309/17944 [00:03<00:10, 1304.56 examples/s]Map:  25%|██▍       | 4441/17944 [00:03<00:10, 1306.74 examples/s]Map:  25%|██▌       | 4572/17944 [00:03<00:10, 1305.17 examples/s]Map:  26%|██▌       | 4704/17944 [00:03<00:10, 1305.64 examples/s]Map:  27%|██▋       | 4836/17944 [00:03<00:10, 1305.58 examples/s]Map:  28%|██▊       | 4968/17944 [00:03<00:09, 1305.70 examples/s]Map:  28%|██▊       | 5100/17944 [00:03<00:09, 1306.53 examples/s]Map:  29%|██▉       | 5232/17944 [00:04<00:09, 1308.19 examples/s]Map:  30%|███       | 5426/17944 [00:04<00:09, 1299.92 examples/s]Map:  31%|███▏      | 5622/17944 [00:04<00:09, 1298.23 examples/s]Map:  32%|███▏      | 5754/17944 [00:04<00:09, 1302.32 examples/s]Map:  33%|███▎      | 5885/17944 [00:04<00:09, 1301.81 examples/s]Map:  34%|███▍      | 6077/17944 [00:04<00:09, 1290.16 examples/s]Map:  35%|███▍      | 6209/17944 [00:04<00:09, 1293.59 examples/s]Map:  35%|███▌      | 6341/17944 [00:04<00:08, 1297.26 examples/s]Map:  36%|███▌      | 6473/17944 [00:04<00:08, 1300.82 examples/s]Map:  37%|███▋      | 6605/17944 [00:05<00:08, 1303.83 examples/s]Map:  38%|███▊      | 6793/17944 [00:05<00:08, 1279.66 examples/s]Map:  39%|███▊      | 6923/17944 [00:05<00:08, 1281.26 examples/s]Map:  39%|███▉      | 7055/17944 [00:05<00:08, 1288.94 examples/s]Map:  40%|████      | 7187/17944 [00:05<00:08, 1293.79 examples/s]Map:  41%|████      | 7319/17944 [00:05<00:08, 1298.80 examples/s]Map:  42%|████▏     | 7451/17944 [00:05<00:08, 1301.73 examples/s]Map:  42%|████▏     | 7582/17944 [00:05<00:07, 1302.20 examples/s]Map:  43%|████▎     | 7714/17944 [00:05<00:07, 1304.99 examples/s]Map:  44%|████▎     | 7846/17944 [00:06<00:07, 1306.91 examples/s]Map:  45%|████▍     | 8040/17944 [00:06<00:07, 1299.49 examples/s]Map:  46%|████▌     | 8172/17944 [00:06<00:07, 1302.39 examples/s]Map:  46%|████▋     | 8304/17944 [00:06<00:07, 1305.96 examples/s]Map:  47%|████▋     | 8436/17944 [00:06<00:07, 1308.24 examples/s]Map:  48%|████▊     | 8619/17944 [00:06<00:07, 1271.57 examples/s]Map:  49%|████▉     | 8751/17944 [00:06<00:07, 1281.82 examples/s]Map:  50%|████▉     | 8883/17944 [00:06<00:07, 1290.19 examples/s]Map:  50%|█████     | 9015/17944 [00:06<00:06, 1296.83 examples/s]Map:  51%|█████▏    | 9207/17944 [00:07<00:06, 1285.20 examples/s]Map:  52%|█████▏    | 9339/17944 [00:07<00:06, 1292.48 examples/s]Map:  53%|█████▎    | 9471/17944 [00:07<00:06, 1297.20 examples/s]Map:  54%|█████▎    | 9602/17944 [00:07<00:06, 1297.78 examples/s]Map:  54%|█████▍    | 9769/17944 [00:07<00:06, 1220.98 examples/s]Map:  55%|█████▌    | 9902/17944 [00:07<00:06, 1246.73 examples/s]Map:  62%|██████▏   | 11193/17944 [00:07<00:01, 4413.56 examples/s]Map:  74%|███████▎  | 13197/17944 [00:07<00:00, 8779.23 examples/s]Map:  84%|████████▍ | 15157/17944 [00:07<00:00, 11864.79 examples/s]Map:  95%|█████████▌| 17073/17944 [00:08<00:00, 13974.83 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2163.03 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  2%|▏         | 154/9960 [00:00<00:06, 1539.26it/s]  3%|▎         | 320/9960 [00:00<00:06, 1604.84it/s]  5%|▍         | 489/9960 [00:00<00:05, 1639.94it/s]  7%|▋         | 656/9960 [00:00<00:05, 1649.30it/s]  8%|▊         | 823/9960 [00:00<00:05, 1654.15it/s] 10%|▉         | 989/9960 [00:00<00:05, 1655.46it/s] 12%|█▏        | 1159/9960 [00:00<00:05, 1667.78it/s] 13%|█▎        | 1330/9960 [00:00<00:05, 1680.40it/s] 15%|█▌        | 1499/9960 [00:00<00:05, 1681.55it/s] 17%|█▋        | 1668/9960 [00:01<00:04, 1678.68it/s] 18%|█▊        | 1839/9960 [00:01<00:04, 1687.90it/s] 20%|██        | 2008/9960 [00:01<00:04, 1659.47it/s] 22%|██▏       | 2176/9960 [00:01<00:04, 1663.27it/s] 24%|██▎       | 2343/9960 [00:01<00:04, 1651.87it/s] 25%|██▌       | 2509/9960 [00:01<00:04, 1637.18it/s] 27%|██▋       | 2673/9960 [00:01<00:04, 1636.79it/s] 28%|██▊       | 2838/9960 [00:01<00:04, 1637.85it/s] 30%|███       | 3002/9960 [00:01<00:04, 1628.60it/s] 32%|███▏      | 3165/9960 [00:01<00:04, 1619.12it/s] 33%|███▎      | 3329/9960 [00:02<00:04, 1622.93it/s] 35%|███▌      | 3495/9960 [00:02<00:03, 1631.57it/s] 37%|███▋      | 3659/9960 [00:02<00:03, 1618.83it/s] 38%|███▊      | 3821/9960 [00:02<00:03, 1586.69it/s] 40%|███▉      | 3980/9960 [00:02<00:03, 1564.23it/s] 42%|████▏     | 4137/9960 [00:02<00:03, 1556.96it/s] 43%|████▎     | 4296/9960 [00:02<00:03, 1564.87it/s] 45%|████▍     | 4454/9960 [00:02<00:03, 1567.97it/s] 46%|████▋     | 4611/9960 [00:02<00:03, 1559.22it/s] 48%|████▊     | 4773/9960 [00:02<00:03, 1576.91it/s] 50%|████▉     | 4940/9960 [00:03<00:03, 1603.29it/s] 51%|█████▏    | 5108/9960 [00:03<00:02, 1625.10it/s] 53%|█████▎    | 5274/9960 [00:03<00:02, 1635.34it/s] 55%|█████▍    | 5439/9960 [00:03<00:02, 1637.33it/s] 56%|█████▋    | 5605/9960 [00:03<00:02, 1643.76it/s] 58%|█████▊    | 5770/9960 [00:03<00:02, 1624.13it/s] 60%|█████▉    | 5934/9960 [00:03<00:02, 1626.30it/s] 61%|██████    | 6097/9960 [00:03<00:02, 1625.15it/s] 63%|██████▎   | 6263/9960 [00:03<00:02, 1633.97it/s] 65%|██████▍   | 6427/9960 [00:03<00:02, 1634.32it/s] 66%|██████▌   | 6591/9960 [00:04<00:02, 1628.56it/s] 68%|██████▊   | 6756/9960 [00:04<00:01, 1632.16it/s] 69%|██████▉   | 6921/9960 [00:04<00:01, 1636.54it/s] 71%|███████   | 7085/9960 [00:04<00:01, 1633.15it/s] 73%|███████▎  | 7249/9960 [00:04<00:01, 1632.37it/s] 74%|███████▍  | 7413/9960 [00:04<00:01, 1633.66it/s] 76%|███████▌  | 7577/9960 [00:04<00:01, 1556.08it/s] 78%|███████▊  | 7742/9960 [00:04<00:01, 1581.36it/s] 79%|███████▉  | 7908/9960 [00:04<00:01, 1603.84it/s] 81%|████████  | 8077/9960 [00:04<00:01, 1627.36it/s] 83%|████████▎ | 8245/9960 [00:05<00:01, 1640.72it/s] 84%|████████▍ | 8415/9960 [00:05<00:00, 1655.81it/s] 86%|████████▌ | 8584/9960 [00:05<00:00, 1664.60it/s] 88%|████████▊ | 8752/9960 [00:05<00:00, 1668.63it/s] 90%|████████▉ | 8926/9960 [00:05<00:00, 1688.72it/s] 91%|█████████▏| 9099/9960 [00:05<00:00, 1700.55it/s] 93%|█████████▎| 9271/9960 [00:05<00:00, 1705.04it/s] 95%|█████████▍| 9445/9960 [00:05<00:00, 1714.88it/s] 97%|█████████▋| 9617/9960 [00:05<00:00, 1666.69it/s] 98%|█████████▊| 9784/9960 [00:05<00:00, 1640.67it/s]100%|█████████▉| 9949/9960 [00:06<00:00, 1638.43it/s]100%|██████████| 9960/9960 [00:06<00:00, 1633.71it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]                                                                 epoch_loss: 0.713432788848877
Epoch [1/20], Loss: 0.7134
Best test AUROC: 0.5626, at epoch: 0
Epoch [1/20],Test AUROC: 0.5626
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.68250572681427
Epoch [2/20], Loss: 0.6825
Best test AUROC: 0.6450, at epoch: 1
Epoch [2/20],Test AUROC: 0.6450
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6632612943649292
Epoch [3/20], Loss: 0.6633
Best test AUROC: 0.6822, at epoch: 2
Epoch [3/20],Test AUROC: 0.6822
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                 epoch_loss: 0.6451493501663208
Epoch [4/20], Loss: 0.6451
Best test AUROC: 0.7055, at epoch: 3
Epoch [4/20],Test AUROC: 0.7055
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                 epoch_loss: 0.6272172331809998
Epoch [5/20], Loss: 0.6272
Best test AUROC: 0.7251, at epoch: 4
Epoch [5/20],Test AUROC: 0.7251
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.6082343459129333
Epoch [6/20], Loss: 0.6082
Best test AUROC: 0.7414, at epoch: 5
Epoch [6/20],Test AUROC: 0.7414
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                 epoch_loss: 0.5887971520423889
Epoch [7/20], Loss: 0.5888
Best test AUROC: 0.7538, at epoch: 6
Epoch [7/20],Test AUROC: 0.7538
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.5700356960296631
Epoch [8/20], Loss: 0.5700
Best test AUROC: 0.7624, at epoch: 7
Epoch [8/20],Test AUROC: 0.7624
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                 epoch_loss: 0.5500437021255493
Epoch [9/20], Loss: 0.5500
Best test AUROC: 0.7680, at epoch: 8
Epoch [9/20],Test AUROC: 0.7680
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                  epoch_loss: 0.5311242341995239
Epoch [10/20], Loss: 0.5311
Best test AUROC: 0.7717, at epoch: 9
Epoch [10/20],Test AUROC: 0.7717
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.5097500085830688
Epoch [11/20], Loss: 0.5098
Best test AUROC: 0.7746, at epoch: 10
Epoch [11/20],Test AUROC: 0.7746
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.4881149232387543
Epoch [12/20], Loss: 0.4881
Best test AUROC: 0.7768, at epoch: 11
Epoch [12/20],Test AUROC: 0.7768
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.4648434519767761
Epoch [13/20], Loss: 0.4648
Best test AUROC: 0.7784, at epoch: 12
Epoch [13/20],Test AUROC: 0.7784
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.43922996520996094
Epoch [14/20], Loss: 0.4392
Best test AUROC: 0.7797, at epoch: 13
Epoch [14/20],Test AUROC: 0.7797
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.411496102809906
Epoch [15/20], Loss: 0.4115
Best test AUROC: 0.7799, at epoch: 14
Epoch [15/20],Test AUROC: 0.7799
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.3817371726036072
Epoch [16/20], Loss: 0.3817
Best test AUROC: 0.7816, at epoch: 15
Epoch [16/20],Test AUROC: 0.7816
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.35055792331695557
Epoch [17/20], Loss: 0.3506
Best test AUROC: 0.7819, at epoch: 16
Epoch [17/20],Test AUROC: 0.7819
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.32057279348373413
Epoch [18/20], Loss: 0.3206
Epoch [18/20],Test AUROC: 0.7753
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.2962748408317566
Epoch [19/20], Loss: 0.2963
Best test AUROC: 0.7845, at epoch: 18
Epoch [19/20],Test AUROC: 0.7845
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.287699818611145
Epoch [20/20], Loss: 0.2877
Epoch [20/20],Test AUROC: 0.7609
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.08it/s]  2%|▏         | 2/115 [00:01<00:58,  1.95it/s]  3%|▎         | 3/115 [00:01<00:48,  2.30it/s]  3%|▎         | 4/115 [00:01<00:52,  2.11it/s]  4%|▍         | 5/115 [00:02<00:53,  2.06it/s]  5%|▌         | 6/115 [00:02<00:49,  2.18it/s]  6%|▌         | 7/115 [00:03<00:46,  2.34it/s]  7%|▋         | 8/115 [00:03<00:45,  2.35it/s]  8%|▊         | 9/115 [00:04<00:47,  2.22it/s]  9%|▊         | 10/115 [00:04<00:50,  2.10it/s] 10%|▉         | 11/115 [00:04<00:44,  2.32it/s] 10%|█         | 12/115 [00:05<00:48,  2.10it/s] 11%|█▏        | 13/115 [00:06<00:48,  2.08it/s] 12%|█▏        | 14/115 [00:06<00:49,  2.04it/s] 13%|█▎        | 15/115 [00:06<00:44,  2.25it/s] 14%|█▍        | 16/115 [00:07<00:48,  2.04it/s] 15%|█▍        | 17/115 [00:08<00:50,  1.95it/s] 16%|█▌        | 18/115 [00:08<00:51,  1.88it/s] 17%|█▋        | 19/115 [00:08<00:45,  2.11it/s] 17%|█▋        | 20/115 [00:09<00:43,  2.17it/s] 18%|█▊        | 21/115 [00:09<00:45,  2.07it/s] 19%|█▉        | 22/115 [00:10<00:45,  2.04it/s] 20%|██        | 23/115 [00:10<00:40,  2.26it/s] 21%|██        | 24/115 [00:11<00:39,  2.32it/s] 22%|██▏       | 25/115 [00:11<00:36,  2.49it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.62it/s] 23%|██▎       | 27/115 [00:12<00:37,  2.34it/s] 24%|██▍       | 28/115 [00:12<00:40,  2.15it/s] 25%|██▌       | 29/115 [00:13<00:44,  1.92it/s] 26%|██▌       | 30/115 [00:14<00:44,  1.91it/s] 27%|██▋       | 31/115 [00:14<00:40,  2.07it/s] 28%|██▊       | 32/115 [00:14<00:40,  2.05it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.92it/s] 30%|██▉       | 34/115 [00:16<00:40,  1.98it/s] 30%|███       | 35/115 [00:16<00:39,  2.04it/s] 31%|███▏      | 36/115 [00:17<00:40,  1.97it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.91it/s] 33%|███▎      | 38/115 [00:18<00:39,  1.95it/s] 34%|███▍      | 39/115 [00:18<00:36,  2.09it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.16it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.95it/s] 37%|███▋      | 42/115 [00:20<00:36,  1.98it/s] 37%|███▋      | 43/115 [00:20<00:42,  1.71it/s] 38%|███▊      | 44/115 [00:21<00:46,  1.52it/s] 39%|███▉      | 45/115 [00:22<00:43,  1.59it/s] 40%|████      | 46/115 [00:22<00:42,  1.62it/s] 41%|████      | 47/115 [00:23<00:39,  1.72it/s] 42%|████▏     | 48/115 [00:24<00:51,  1.30it/s] 43%|████▎     | 49/115 [00:25<00:48,  1.36it/s] 43%|████▎     | 50/115 [00:25<00:44,  1.46it/s] 44%|████▍     | 51/115 [00:26<00:40,  1.58it/s] 45%|████▌     | 52/115 [00:26<00:40,  1.56it/s] 46%|████▌     | 53/115 [00:27<00:39,  1.57it/s] 47%|████▋     | 54/115 [00:28<00:37,  1.63it/s] 48%|████▊     | 55/115 [00:28<00:31,  1.90it/s] 49%|████▊     | 56/115 [00:28<00:29,  2.02it/s] 50%|████▉     | 57/115 [00:29<00:25,  2.30it/s] 50%|█████     | 58/115 [00:29<00:23,  2.43it/s] 51%|█████▏    | 59/115 [00:29<00:21,  2.64it/s] 52%|█████▏    | 60/115 [00:30<00:23,  2.35it/s] 53%|█████▎    | 61/115 [00:30<00:23,  2.30it/s] 54%|█████▍    | 62/115 [00:31<00:24,  2.15it/s] 55%|█████▍    | 63/115 [00:31<00:26,  1.95it/s] 56%|█████▌    | 64/115 [00:32<00:25,  2.00it/s] 57%|█████▋    | 65/115 [00:32<00:24,  2.07it/s] 57%|█████▋    | 66/115 [00:33<00:24,  1.99it/s] 58%|█████▊    | 67/115 [00:33<00:22,  2.17it/s] 59%|█████▉    | 68/115 [00:34<00:20,  2.26it/s] 60%|██████    | 69/115 [00:34<00:21,  2.18it/s] 61%|██████    | 70/115 [00:35<00:21,  2.12it/s] 62%|██████▏   | 71/115 [00:35<00:20,  2.14it/s] 63%|██████▎   | 72/115 [00:36<00:20,  2.09it/s] 63%|██████▎   | 73/115 [00:36<00:18,  2.25it/s] 64%|██████▍   | 74/115 [00:36<00:17,  2.34it/s] 65%|██████▌   | 75/115 [00:37<00:17,  2.30it/s] 66%|██████▌   | 76/115 [00:37<00:18,  2.13it/s] 67%|██████▋   | 77/115 [00:38<00:18,  2.04it/s] 68%|██████▊   | 78/115 [00:38<00:16,  2.18it/s] 69%|██████▊   | 79/115 [00:39<00:17,  2.08it/s] 70%|██████▉   | 80/115 [00:39<00:15,  2.24it/s] 70%|███████   | 81/115 [00:40<00:14,  2.30it/s] 71%|███████▏  | 82/115 [00:40<00:14,  2.31it/s] 72%|███████▏  | 83/115 [00:40<00:13,  2.38it/s] 73%|███████▎  | 84/115 [00:41<00:13,  2.24it/s] 74%|███████▍  | 85/115 [00:41<00:13,  2.20it/s] 75%|███████▍  | 86/115 [00:42<00:13,  2.07it/s] 76%|███████▌  | 87/115 [00:43<00:15,  1.85it/s] 77%|███████▋  | 88/115 [00:43<00:14,  1.90it/s] 77%|███████▋  | 89/115 [00:43<00:11,  2.17it/s] 78%|███████▊  | 90/115 [00:44<00:11,  2.19it/s] 79%|███████▉  | 91/115 [00:45<00:12,  1.89it/s] 80%|████████  | 92/115 [00:45<00:12,  1.78it/s] 81%|████████  | 93/115 [00:46<00:12,  1.79it/s] 82%|████████▏ | 94/115 [00:46<00:11,  1.89it/s] 83%|████████▎ | 95/115 [00:47<00:10,  1.95it/s] 83%|████████▎ | 96/115 [00:47<00:10,  1.82it/s] 84%|████████▍ | 97/115 [00:48<00:09,  1.89it/s] 85%|████████▌ | 98/115 [00:48<00:08,  2.06it/s] 86%|████████▌ | 99/115 [00:49<00:07,  2.14it/s] 87%|████████▋ | 100/115 [00:49<00:06,  2.30it/s] 88%|████████▊ | 101/115 [00:49<00:06,  2.21it/s] 89%|████████▊ | 102/115 [00:50<00:06,  2.15it/s] 90%|████████▉ | 103/115 [00:50<00:05,  2.35it/s] 90%|█████████ | 104/115 [00:51<00:04,  2.27it/s] 91%|█████████▏| 105/115 [00:51<00:03,  2.58it/s] 92%|█████████▏| 106/115 [00:52<00:03,  2.38it/s] 93%|█████████▎| 107/115 [00:52<00:03,  2.45it/s] 94%|█████████▍| 108/115 [00:52<00:02,  2.65it/s] 95%|█████████▍| 109/115 [00:53<00:02,  2.77it/s] 96%|█████████▌| 110/115 [00:53<00:02,  1.87it/s] 97%|█████████▋| 111/115 [00:54<00:02,  1.65it/s] 97%|█████████▋| 112/115 [00:56<00:02,  1.10it/s] 98%|█████████▊| 113/115 [00:56<00:01,  1.32it/s] 99%|█████████▉| 114/115 [00:57<00:00,  1.50it/s]100%|██████████| 115/115 [00:57<00:00,  2.01it/s]
tsv_main1.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main1.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                 epoch_loss: 0.392230749130249
Epoch [1/20], Loss: 0.3922
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.29014907280604046
Epoch [2/20], Loss: 0.2901
Best test AUROC: 0.7882, at epoch: 21
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.22729465862115225
Epoch [3/20], Loss: 0.2273
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.18960419545571008
Epoch [4/20], Loss: 0.1896
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                 epoch_loss: 0.15626043329636255
Epoch [5/20], Loss: 0.1563
Best test AUROC: 0.7915, at epoch: 24
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                 epoch_loss: 0.12544644872347513
Epoch [6/20], Loss: 0.1254
Best test AUROC: 0.7933, at epoch: 25
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.09925109272201856
Epoch [7/20], Loss: 0.0993
Best test AUROC: 0.7936, at epoch: 26
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.09s/it]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.07914822300275166
Epoch [8/20], Loss: 0.0791
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                 epoch_loss: 0.06377287084857623
Epoch [9/20], Loss: 0.0638
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                  epoch_loss: 0.05161858225862185
Epoch [10/20], Loss: 0.0516
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.041931728521982826
Epoch [11/20], Loss: 0.0419
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                  epoch_loss: 0.03397894153992335
Epoch [12/20], Loss: 0.0340
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.027637604003151257
Epoch [13/20], Loss: 0.0276
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.02259726511935393
Epoch [14/20], Loss: 0.0226
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.01853640501697858
Epoch [15/20], Loss: 0.0185
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.015280754305422306
Epoch [16/20], Loss: 0.0153
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                  epoch_loss: 0.012653802211085955
Epoch [17/20], Loss: 0.0127
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]                                                                  epoch_loss: 0.010521231684833765
Epoch [18/20], Loss: 0.0105
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.00877973980580767
Epoch [19/20], Loss: 0.0088
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:01<00:02,  1.08s/it]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.42it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]                                                                  epoch_loss: 0.007360775178919236
Epoch [20/20], Loss: 0.0074
best_test_auroc: 0.7935873197227096
