Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 19%|█▉        | 158/817 [00:00<00:00, 1572.03it/s] 39%|███▉      | 321/817 [00:00<00:00, 1599.82it/s] 59%|█████▉    | 481/817 [00:00<00:00, 1495.26it/s] 80%|███████▉  | 650/817 [00:00<00:00, 1566.41it/s]100%|██████████| 817/817 [00:00<00:00, 1585.73it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]                                                                 epoch_loss: 0.6743698120117188
Epoch [1/20], Loss: 0.6744
Best test AUROC: 0.5038, at epoch: 0
Epoch [1/20],Test AUROC: 0.5038
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]                                                                 epoch_loss: 0.6826239824295044
Epoch [2/20], Loss: 0.6826
Best test AUROC: 0.6074, at epoch: 1
Epoch [2/20],Test AUROC: 0.6074
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]                                                                 epoch_loss: 0.6946163177490234
Epoch [3/20], Loss: 0.6946
Best test AUROC: 0.8120, at epoch: 2
Epoch [3/20],Test AUROC: 0.8120
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                 epoch_loss: 0.5463701486587524
Epoch [4/20], Loss: 0.5464
Best test AUROC: 0.8164, at epoch: 3
Epoch [4/20],Test AUROC: 0.8164
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                 epoch_loss: 0.45492932200431824
Epoch [5/20], Loss: 0.4549
Best test AUROC: 0.8221, at epoch: 4
Epoch [5/20],Test AUROC: 0.8221
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                 epoch_loss: 0.3696615397930145
Epoch [6/20], Loss: 0.3697
Epoch [6/20],Test AUROC: 0.8208
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]                                                                 epoch_loss: 0.30300265550613403
Epoch [7/20], Loss: 0.3030
Epoch [7/20],Test AUROC: 0.8215
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]                                                                 epoch_loss: 0.24328015744686127
Epoch [8/20], Loss: 0.2433
Epoch [8/20],Test AUROC: 0.8212
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]                                                                 epoch_loss: 0.19738471508026123
Epoch [9/20], Loss: 0.1974
Epoch [9/20],Test AUROC: 0.8203
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]                                                                  epoch_loss: 0.1586167812347412
Epoch [10/20], Loss: 0.1586
Epoch [10/20],Test AUROC: 0.8205
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]                                                                  epoch_loss: 0.12793609499931335
Epoch [11/20], Loss: 0.1279
Epoch [11/20],Test AUROC: 0.8204
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.10293180495500565
Epoch [12/20], Loss: 0.1029
Epoch [12/20],Test AUROC: 0.8206
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.08070452511310577
Epoch [13/20], Loss: 0.0807
Epoch [13/20],Test AUROC: 0.8206
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.06179255619645119
Epoch [14/20], Loss: 0.0618
Epoch [14/20],Test AUROC: 0.8203
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.045569367706775665
Epoch [15/20], Loss: 0.0456
Epoch [15/20],Test AUROC: 0.8190
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.03299523890018463
Epoch [16/20], Loss: 0.0330
Epoch [16/20],Test AUROC: 0.8179
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.02411523461341858
Epoch [17/20], Loss: 0.0241
Epoch [17/20],Test AUROC: 0.8154
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]                                                                  epoch_loss: 0.017433058470487595
Epoch [18/20], Loss: 0.0174
Epoch [18/20],Test AUROC: 0.8154
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.012572526931762695
Epoch [19/20], Loss: 0.0126
Epoch [19/20],Test AUROC: 0.8136
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]                                                                  epoch_loss: 0.00899931974709034
Epoch [20/20], Loss: 0.0090
Epoch [20/20],Test AUROC: 0.8128
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.05it/s] 50%|█████     | 2/4 [00:01<00:02,  1.01s/it] 75%|███████▌  | 3/4 [00:02<00:00,  1.04it/s]100%|██████████| 4/4 [00:03<00:00,  1.01it/s]100%|██████████| 4/4 [00:03<00:00,  1.01it/s]
tsv_main3.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main3.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.07it/s]                                                                 epoch_loss: 0.002285777125507593
Epoch [1/20], Loss: 0.0023
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.001917855627834797
Epoch [2/20], Loss: 0.0019
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 3/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0016212705057114362
Epoch [3/20], Loss: 0.0016
Epoch 4/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 4/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.07it/s]                                                                 epoch_loss: 0.0013836152851581574
Epoch [4/20], Loss: 0.0014
Epoch 5/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 5/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.001190092135220766
Epoch [5/20], Loss: 0.0012
Epoch 6/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 6/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0010332837235182523
Epoch [6/20], Loss: 0.0010
Epoch 7/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 7/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0009041738696396351
Epoch [7/20], Loss: 0.0009
Epoch 8/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 8/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0007983239833265543
Epoch [8/20], Loss: 0.0008
Epoch 9/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 9/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0007106104167178273
Epoch [9/20], Loss: 0.0007
Epoch 10/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 10/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.0006375472294166684
Epoch [10/20], Loss: 0.0006
Epoch 11/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 11/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.0005769282695837318
Epoch [11/20], Loss: 0.0006
Epoch 12/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 12/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.0005255207885056734
Epoch [12/20], Loss: 0.0005
Epoch 13/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Epoch 13/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.0004826836462598294
Epoch [13/20], Loss: 0.0005
Epoch 14/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 14/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00044606566661968826
Epoch [14/20], Loss: 0.0004
Epoch 15/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 15/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00041464543319307267
Epoch [15/20], Loss: 0.0004
Epoch 16/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 16/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.000388016298529692
Epoch [16/20], Loss: 0.0004
Epoch 17/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 17/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00036499412672128526
Epoch [17/20], Loss: 0.0004
Epoch 18/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 18/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00034526450326666236
Epoch [18/20], Loss: 0.0003
Epoch 19/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 19/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00032817840692587195
Epoch [19/20], Loss: 0.0003
Epoch 20/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Epoch 20/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                  epoch_loss: 0.00031311563507188114
Epoch [20/20], Loss: 0.0003
best_test_auroc: 0.8220645161290322
