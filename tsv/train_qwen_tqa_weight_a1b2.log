Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.77s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 18%|█▊        | 143/817 [00:00<00:00, 1426.13it/s] 37%|███▋      | 306/817 [00:00<00:00, 1540.62it/s] 57%|█████▋    | 464/817 [00:00<00:00, 1557.88it/s] 76%|███████▋  | 624/817 [00:00<00:00, 1574.19it/s] 96%|█████████▌| 782/817 [00:00<00:00, 1558.47it/s]100%|██████████| 817/817 [00:00<00:00, 1552.55it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]                                                                 epoch_loss: 0.7693562507629395
Epoch [1/20], Loss: 0.7694
Best test AUROC: 0.1998, at epoch: 0
Epoch [1/20],Test AUROC: 0.1998
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                 epoch_loss: 0.7735651731491089
Epoch [2/20], Loss: 0.7736
Best test AUROC: 0.2077, at epoch: 1
Epoch [2/20],Test AUROC: 0.2077
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s]                                                                 epoch_loss: 0.7720659375190735
Epoch [3/20], Loss: 0.7721
Best test AUROC: 0.5791, at epoch: 2
Epoch [3/20],Test AUROC: 0.5791
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.5917928218841553
Epoch [4/20], Loss: 0.5918
Best test AUROC: 0.8542, at epoch: 3
Epoch [4/20],Test AUROC: 0.8542
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.5019680261611938
Epoch [5/20], Loss: 0.5020
Best test AUROC: 0.8630, at epoch: 4
Epoch [5/20],Test AUROC: 0.8630
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.42848122119903564
Epoch [6/20], Loss: 0.4285
Epoch [6/20],Test AUROC: 0.8552
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.3550644814968109
Epoch [7/20], Loss: 0.3551
Epoch [7/20],Test AUROC: 0.8454
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.27823594212532043
Epoch [8/20], Loss: 0.2782
Epoch [8/20],Test AUROC: 0.8367
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.20319688320159912
Epoch [9/20], Loss: 0.2032
Epoch [9/20],Test AUROC: 0.8185
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                  epoch_loss: 0.16672995686531067
Epoch [10/20], Loss: 0.1667
Epoch [10/20],Test AUROC: 0.8361
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                  epoch_loss: 0.10177728533744812
Epoch [11/20], Loss: 0.1018
Epoch [11/20],Test AUROC: 0.8382
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.0744425356388092
Epoch [12/20], Loss: 0.0744
Epoch [12/20],Test AUROC: 0.8397
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.053332529962062836
Epoch [13/20], Loss: 0.0533
Epoch [13/20],Test AUROC: 0.8401
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.039093416184186935
Epoch [14/20], Loss: 0.0391
Epoch [14/20],Test AUROC: 0.8400
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.028578592464327812
Epoch [15/20], Loss: 0.0286
Epoch [15/20],Test AUROC: 0.8381
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.021052246913313866
Epoch [16/20], Loss: 0.0211
Epoch [16/20],Test AUROC: 0.8373
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]                                                                  epoch_loss: 0.015705358237028122
Epoch [17/20], Loss: 0.0157
Epoch [17/20],Test AUROC: 0.8355
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.011905362829566002
Epoch [18/20], Loss: 0.0119
Epoch [18/20],Test AUROC: 0.8353
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.009176677092909813
Epoch [19/20], Loss: 0.0092
Epoch [19/20],Test AUROC: 0.8339
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                  epoch_loss: 0.007212734315544367
Epoch [20/20], Loss: 0.0072
Epoch [20/20],Test AUROC: 0.8327
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.08it/s] 50%|█████     | 2/4 [00:01<00:01,  1.02it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]100%|██████████| 4/4 [00:03<00:00,  1.04it/s]100%|██████████| 4/4 [00:03<00:00,  1.04it/s]
tsv_main3.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main3.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.003888954408466816
Epoch [1/20], Loss: 0.0039
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.003357241116464138
Epoch [2/20], Loss: 0.0034
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 3/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]                                                                 epoch_loss: 0.002907755970954895
Epoch [3/20], Loss: 0.0029
Epoch 4/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 4/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.0025256481021642685
Epoch [4/20], Loss: 0.0025
Epoch 5/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 5/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.002200019359588623
Epoch [5/20], Loss: 0.0022
Epoch 6/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 6/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.0019227089826017619
Epoch [6/20], Loss: 0.0019
Epoch 7/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 7/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.0016855931840837
Epoch [7/20], Loss: 0.0017
Epoch 8/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 8/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.0014818758703768254
Epoch [8/20], Loss: 0.0015
Epoch 9/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 9/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                 epoch_loss: 0.001307457685470581
Epoch [9/20], Loss: 0.0013
Epoch 10/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 10/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.0011570726055651903
Epoch [10/20], Loss: 0.0012
Epoch 11/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 11/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.0010265838587656616
Epoch [11/20], Loss: 0.0010
Epoch 12/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 12/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]                                                                  epoch_loss: 0.0009146171156316996
Epoch [12/20], Loss: 0.0009
Epoch 13/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 13/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.000816672039218247
Epoch [13/20], Loss: 0.0008
Epoch 14/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 14/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.0007316679693758488
Epoch [14/20], Loss: 0.0007
Epoch 15/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 15/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]                                                                  epoch_loss: 0.0006574527360498905
Epoch [15/20], Loss: 0.0007
Epoch 16/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 16/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.0005930216750130058
Epoch [16/20], Loss: 0.0006
Epoch 17/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 17/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]                                                                  epoch_loss: 0.000536361918784678
Epoch [17/20], Loss: 0.0005
Epoch 18/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 18/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.0004864019807428122
Epoch [18/20], Loss: 0.0005
Epoch 19/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Epoch 19/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.00044241221621632576
Epoch [19/20], Loss: 0.0004
Epoch 20/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.19s/it]Epoch 20/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]                                                                  epoch_loss: 0.00040374917443841696
Epoch [20/20], Loss: 0.0004
best_test_auroc: 0.8630322580645161
