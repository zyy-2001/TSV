Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 18%|█▊        | 151/817 [00:00<00:00, 1505.87it/s] 39%|███▉      | 317/817 [00:00<00:00, 1596.22it/s] 59%|█████▉    | 483/817 [00:00<00:00, 1622.60it/s] 79%|███████▉  | 649/817 [00:00<00:00, 1637.18it/s]100%|█████████▉| 816/817 [00:00<00:00, 1648.26it/s]100%|██████████| 817/817 [00:00<00:00, 1628.90it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]                                                                 epoch_loss: 0.6848214864730835
Epoch [1/20], Loss: 0.6848
Best test AUROC: 0.7019, at epoch: 0
Epoch [1/20],Test AUROC: 0.7019
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]                                                                 epoch_loss: 0.6336902379989624
Epoch [2/20], Loss: 0.6337
Best test AUROC: 0.7278, at epoch: 1
Epoch [2/20],Test AUROC: 0.7278
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]                                                                 epoch_loss: 0.587369441986084
Epoch [3/20], Loss: 0.5874
Best test AUROC: 0.7773, at epoch: 2
Epoch [3/20],Test AUROC: 0.7773
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]                                                                 epoch_loss: 0.5314977169036865
Epoch [4/20], Loss: 0.5315
Best test AUROC: 0.8105, at epoch: 3
Epoch [4/20],Test AUROC: 0.8105
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                 epoch_loss: 0.47831642627716064
Epoch [5/20], Loss: 0.4783
Epoch [5/20],Test AUROC: 0.7987
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                 epoch_loss: 0.4278440773487091
Epoch [6/20], Loss: 0.4278
Epoch [6/20],Test AUROC: 0.7939
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]                                                                 epoch_loss: 0.38900458812713623
Epoch [7/20], Loss: 0.3890
Epoch [7/20],Test AUROC: 0.7954
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]                                                                 epoch_loss: 0.3510435223579407
Epoch [8/20], Loss: 0.3510
Epoch [8/20],Test AUROC: 0.8019
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                 epoch_loss: 0.32064592838287354
Epoch [9/20], Loss: 0.3206
Best test AUROC: 0.8195, at epoch: 8
Epoch [9/20],Test AUROC: 0.8195
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]                                                                  epoch_loss: 0.29249340295791626
Epoch [10/20], Loss: 0.2925
Epoch [10/20],Test AUROC: 0.8140
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                  epoch_loss: 0.26252830028533936
Epoch [11/20], Loss: 0.2625
Epoch [11/20],Test AUROC: 0.8139
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                  epoch_loss: 0.24120250344276428
Epoch [12/20], Loss: 0.2412
Epoch [12/20],Test AUROC: 0.8170
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                  epoch_loss: 0.22052592039108276
Epoch [13/20], Loss: 0.2205
Best test AUROC: 0.8204, at epoch: 12
Epoch [13/20],Test AUROC: 0.8204
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]                                                                  epoch_loss: 0.20532190799713135
Epoch [14/20], Loss: 0.2053
Best test AUROC: 0.8215, at epoch: 13
Epoch [14/20],Test AUROC: 0.8215
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]                                                                  epoch_loss: 0.19060036540031433
Epoch [15/20], Loss: 0.1906
Epoch [15/20],Test AUROC: 0.8213
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]                                                                  epoch_loss: 0.1747613549232483
Epoch [16/20], Loss: 0.1748
Epoch [16/20],Test AUROC: 0.8205
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]                                                                  epoch_loss: 0.1620994210243225
Epoch [17/20], Loss: 0.1621
Epoch [17/20],Test AUROC: 0.8203
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]                                                                  epoch_loss: 0.15004879236221313
Epoch [18/20], Loss: 0.1500
Epoch [18/20],Test AUROC: 0.8192
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]                                                                  epoch_loss: 0.1394178420305252
Epoch [19/20], Loss: 0.1394
Epoch [19/20],Test AUROC: 0.8188
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]                                                                  epoch_loss: 0.12988531589508057
Epoch [20/20], Loss: 0.1299
Epoch [20/20],Test AUROC: 0.8187
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.09it/s] 50%|█████     | 2/4 [00:01<00:01,  1.03it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.08it/s]100%|██████████| 4/4 [00:03<00:00,  1.05it/s]100%|██████████| 4/4 [00:03<00:00,  1.05it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.09it/s]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]                                                                 epoch_loss: 0.0984798789024353
Epoch [1/20], Loss: 0.0985
Best test AUROC: 0.8281, at epoch: 20
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]                                                                 epoch_loss: 0.0816140502691269
Epoch [2/20], Loss: 0.0816
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.09it/s]Epoch 3/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]                                                                 epoch_loss: 0.07329218983650207
Epoch [3/20], Loss: 0.0733
Epoch 4/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 4/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                 epoch_loss: 0.06459760963916779
Epoch [4/20], Loss: 0.0646
Best test AUROC: 0.8344, at epoch: 23
Epoch 5/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.09it/s]Epoch 5/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                 epoch_loss: 0.05171377062797546
Epoch [5/20], Loss: 0.0517
Best test AUROC: 0.8476, at epoch: 24
Epoch 6/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 6/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                 epoch_loss: 0.04419490844011307
Epoch [6/20], Loss: 0.0442
Best test AUROC: 0.8485, at epoch: 25
Epoch 7/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 7/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]                                                                 epoch_loss: 0.0379703477025032
Epoch [7/20], Loss: 0.0380
Epoch 8/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.09it/s]Epoch 8/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]                                                                 epoch_loss: 0.03125941976904869
Epoch [8/20], Loss: 0.0313
Epoch 9/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.09it/s]Epoch 9/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                 epoch_loss: 0.025477614253759384
Epoch [9/20], Loss: 0.0255
Epoch 10/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 10/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.020939797908067704
Epoch [10/20], Loss: 0.0209
Epoch 11/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 11/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.01749851554632187
Epoch [11/20], Loss: 0.0175
Epoch 12/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 12/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.014379937574267388
Epoch [12/20], Loss: 0.0144
Best test AUROC: 0.8487, at epoch: 31
Epoch 13/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 13/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.011839498579502106
Epoch [13/20], Loss: 0.0118
Best test AUROC: 0.8542, at epoch: 32
Epoch 14/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 14/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.009794112481176852
Epoch [14/20], Loss: 0.0098
Epoch 15/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 15/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.008148355223238469
Epoch [15/20], Loss: 0.0081
Best test AUROC: 0.8546, at epoch: 34
Epoch 16/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 16/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.006837177276611328
Epoch [16/20], Loss: 0.0068
Epoch 17/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 17/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.005764352343976498
Epoch [17/20], Loss: 0.0058
Epoch 18/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 18/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.004845863115042448
Epoch [18/20], Loss: 0.0048
Epoch 19/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 19/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.004066148307174444
Epoch [19/20], Loss: 0.0041
Epoch 20/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  50%|█████     | 1/2 [00:00<00:00,  1.08it/s]Epoch 20/20 Batches: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]                                                                  epoch_loss: 0.0034157870337367057
Epoch [20/20], Loss: 0.0034
best_test_auroc: 0.8545806451612904
