Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   0%|          | 86/17944 [00:00<00:21, 848.30 examples/s]Map:   1%|          | 211/17944 [00:00<00:16, 1078.11 examples/s]Map:   2%|▏         | 338/17944 [00:00<00:15, 1158.87 examples/s]Map:   3%|▎         | 466/17944 [00:00<00:14, 1203.20 examples/s]Map:   3%|▎         | 595/17944 [00:00<00:14, 1229.18 examples/s]Map:   4%|▍         | 724/17944 [00:00<00:13, 1246.40 examples/s]Map:   5%|▍         | 851/17944 [00:00<00:13, 1253.69 examples/s]Map:   6%|▌         | 1029/17944 [00:00<00:13, 1222.59 examples/s]Map:   6%|▋         | 1158/17944 [00:00<00:13, 1240.13 examples/s]Map:   7%|▋         | 1287/17944 [00:01<00:13, 1252.59 examples/s]Map:   8%|▊         | 1416/17944 [00:01<00:13, 1260.19 examples/s]Map:   9%|▊         | 1543/17944 [00:01<00:13, 1260.99 examples/s]Map:   9%|▉         | 1672/17944 [00:01<00:12, 1265.56 examples/s]Map:  10%|█         | 1802/17944 [00:01<00:12, 1272.92 examples/s]Map:  11%|█         | 1932/17944 [00:01<00:12, 1277.63 examples/s]Map:  11%|█▏        | 2062/17944 [00:01<00:12, 1281.02 examples/s]Map:  12%|█▏        | 2242/17944 [00:01<00:12, 1245.24 examples/s]Map:  13%|█▎        | 2372/17944 [00:01<00:12, 1257.18 examples/s]Map:  14%|█▍        | 2502/17944 [00:02<00:12, 1264.67 examples/s]Map:  15%|█▍        | 2631/17944 [00:02<00:12, 1271.00 examples/s]Map:  16%|█▌        | 2817/17944 [00:02<00:12, 1255.34 examples/s]Map:  16%|█▋        | 2945/17944 [00:02<00:11, 1258.65 examples/s]Map:  17%|█▋        | 3074/17944 [00:02<00:11, 1265.26 examples/s]Map:  18%|█▊        | 3203/17944 [00:02<00:11, 1269.70 examples/s]Map:  19%|█▉        | 3370/17944 [00:02<00:12, 1206.48 examples/s]Map:  20%|█▉        | 3500/17944 [00:02<00:11, 1227.41 examples/s]Map:  20%|██        | 3629/17944 [00:02<00:11, 1242.27 examples/s]Map:  21%|██        | 3759/17944 [00:03<00:11, 1254.20 examples/s]Map:  22%|██▏       | 3887/17944 [00:03<00:11, 1257.25 examples/s]Map:  22%|██▏       | 4016/17944 [00:03<00:11, 1263.99 examples/s]Map:  23%|██▎       | 4145/17944 [00:03<00:10, 1269.93 examples/s]Map:  24%|██▍       | 4274/17944 [00:03<00:10, 1273.51 examples/s]Map:  25%|██▍       | 4454/17944 [00:03<00:10, 1238.18 examples/s]Map:  26%|██▌       | 4584/17944 [00:03<00:10, 1250.39 examples/s]Map:  26%|██▋       | 4713/17944 [00:03<00:10, 1259.68 examples/s]Map:  27%|██▋       | 4843/17944 [00:03<00:10, 1267.79 examples/s]Map:  28%|██▊       | 4972/17944 [00:03<00:10, 1270.91 examples/s]Map:  28%|██▊       | 5100/17944 [00:04<00:10, 1268.94 examples/s]Map:  29%|██▉       | 5289/17944 [00:04<00:10, 1261.13 examples/s]Map:  30%|███       | 5461/17944 [00:04<00:10, 1215.50 examples/s]Map:  31%|███       | 5585/17944 [00:04<00:10, 1218.70 examples/s]Map:  32%|███▏      | 5751/17944 [00:04<00:10, 1174.21 examples/s]Map:  33%|███▎      | 5910/17944 [00:04<00:11, 1018.87 examples/s]Map:  34%|███▎      | 6043/17944 [00:04<00:12, 978.41 examples/s] Map:  34%|███▍      | 6166/17944 [00:05<00:12, 927.80 examples/s]Map:  35%|███▌      | 6290/17944 [00:05<00:13, 891.92 examples/s]Map:  36%|███▌      | 6418/17944 [00:05<00:13, 876.90 examples/s]Map:  36%|███▋      | 6508/17944 [00:05<00:12, 880.38 examples/s]Map:  37%|███▋      | 6628/17944 [00:05<00:13, 850.41 examples/s]Map:  37%|███▋      | 6727/17944 [00:05<00:12, 881.17 examples/s]Map:  38%|███▊      | 6837/17944 [00:05<00:13, 829.07 examples/s]Map:  39%|███▊      | 6941/17944 [00:06<00:12, 877.05 examples/s]Map:  39%|███▉      | 7051/17944 [00:06<00:13, 825.55 examples/s]Map:  40%|███▉      | 7147/17944 [00:06<00:12, 856.65 examples/s]Map:  41%|████      | 7276/17944 [00:06<00:11, 967.23 examples/s]Map:  41%|████▏     | 7405/17944 [00:06<00:10, 1052.34 examples/s]Map:  42%|████▏     | 7530/17944 [00:06<00:09, 1104.99 examples/s]Map:  43%|████▎     | 7670/17944 [00:06<00:09, 1036.40 examples/s]Map:  43%|████▎     | 7779/17944 [00:06<00:09, 1047.94 examples/s]Map:  44%|████▍     | 7909/17944 [00:06<00:09, 1114.23 examples/s]Map:  45%|████▍     | 8038/17944 [00:07<00:08, 1161.14 examples/s]Map:  46%|████▌     | 8214/17944 [00:07<00:08, 1165.11 examples/s]Map:  47%|████▋     | 8344/17944 [00:07<00:08, 1199.07 examples/s]Map:  47%|████▋     | 8474/17944 [00:07<00:07, 1224.10 examples/s]Map:  48%|████▊     | 8604/17944 [00:07<00:07, 1244.01 examples/s]Map:  49%|████▊     | 8734/17944 [00:07<00:07, 1258.10 examples/s]Map:  49%|████▉     | 8863/17944 [00:07<00:07, 1263.70 examples/s]Map:  50%|█████     | 8993/17944 [00:07<00:07, 1273.04 examples/s]Map:  51%|█████     | 9123/17944 [00:07<00:06, 1278.14 examples/s]Map:  52%|█████▏    | 9304/17944 [00:08<00:06, 1243.39 examples/s]Map:  53%|█████▎    | 9434/17944 [00:08<00:06, 1256.72 examples/s]Map:  53%|█████▎    | 9564/17944 [00:08<00:06, 1265.55 examples/s]Map:  54%|█████▍    | 9694/17944 [00:08<00:06, 1272.94 examples/s]Map:  55%|█████▍    | 9824/17944 [00:08<00:06, 1278.01 examples/s]Map:  56%|█████▌    | 9978/17944 [00:08<00:05, 1352.09 examples/s]Map:  66%|██████▋   | 11932/17944 [00:08<00:00, 6679.14 examples/s]Map:  78%|███████▊  | 13928/17944 [00:08<00:00, 10595.53 examples/s]Map:  88%|████████▊ | 15860/17944 [00:08<00:00, 13179.89 examples/s]Map: 100%|██████████| 17944/17944 [00:09<00:00, 13551.49 examples/s]Map: 100%|██████████| 17944/17944 [00:09<00:00, 1947.00 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  1%|▏         | 149/9960 [00:00<00:06, 1480.74it/s]  3%|▎         | 313/9960 [00:00<00:06, 1571.58it/s]  5%|▍         | 480/9960 [00:00<00:05, 1613.29it/s]  6%|▋         | 645/9960 [00:00<00:05, 1627.25it/s]  8%|▊         | 811/9960 [00:00<00:05, 1635.78it/s] 10%|▉         | 977/9960 [00:00<00:05, 1643.30it/s] 11%|█▏        | 1143/9960 [00:00<00:05, 1648.60it/s] 13%|█▎        | 1313/9960 [00:00<00:05, 1663.04it/s] 15%|█▍        | 1481/9960 [00:00<00:05, 1666.77it/s] 17%|█▋        | 1648/9960 [00:01<00:04, 1664.37it/s] 18%|█▊        | 1817/9960 [00:01<00:04, 1671.77it/s] 20%|█▉        | 1985/9960 [00:01<00:04, 1670.24it/s] 22%|██▏       | 2155/9960 [00:01<00:04, 1676.80it/s] 23%|██▎       | 2323/9960 [00:01<00:04, 1670.01it/s] 25%|██▌       | 2491/9960 [00:01<00:04, 1665.48it/s] 27%|██▋       | 2658/9960 [00:01<00:04, 1651.01it/s] 28%|██▊       | 2825/9960 [00:01<00:04, 1654.13it/s] 30%|███       | 2991/9960 [00:01<00:04, 1643.79it/s] 32%|███▏      | 3156/9960 [00:01<00:04, 1636.86it/s] 33%|███▎      | 3322/9960 [00:02<00:04, 1642.85it/s] 35%|███▌      | 3490/9960 [00:02<00:03, 1652.66it/s] 37%|███▋      | 3656/9960 [00:02<00:03, 1642.90it/s] 38%|███▊      | 3821/9960 [00:02<00:03, 1631.17it/s] 40%|████      | 3985/9960 [00:02<00:03, 1608.81it/s] 42%|████▏     | 4146/9960 [00:02<00:03, 1595.21it/s] 43%|████▎     | 4308/9960 [00:02<00:03, 1600.92it/s] 45%|████▍     | 4469/9960 [00:02<00:03, 1582.05it/s] 46%|████▋     | 4629/9960 [00:02<00:03, 1587.11it/s] 48%|████▊     | 4793/9960 [00:02<00:03, 1601.50it/s] 50%|████▉     | 4966/9960 [00:03<00:03, 1637.32it/s] 52%|█████▏    | 5136/9960 [00:03<00:02, 1655.07it/s] 53%|█████▎    | 5305/9960 [00:03<00:02, 1665.15it/s] 55%|█████▍    | 5475/9960 [00:03<00:02, 1673.67it/s] 57%|█████▋    | 5644/9960 [00:03<00:02, 1676.10it/s] 58%|█████▊    | 5813/9960 [00:03<00:02, 1677.97it/s] 60%|██████    | 5982/9960 [00:03<00:02, 1680.54it/s] 62%|██████▏   | 6151/9960 [00:03<00:02, 1682.97it/s] 63%|██████▎   | 6322/9960 [00:03<00:02, 1689.84it/s] 65%|██████▌   | 6491/9960 [00:03<00:02, 1683.37it/s] 67%|██████▋   | 6660/9960 [00:04<00:01, 1672.21it/s] 69%|██████▊   | 6829/9960 [00:04<00:01, 1676.13it/s] 70%|███████   | 6997/9960 [00:04<00:01, 1652.76it/s] 72%|███████▏  | 7163/9960 [00:04<00:01, 1641.54it/s] 74%|███████▎  | 7328/9960 [00:04<00:01, 1635.45it/s] 75%|███████▌  | 7492/9960 [00:04<00:01, 1609.87it/s] 77%|███████▋  | 7654/9960 [00:04<00:01, 1591.13it/s] 78%|███████▊  | 7815/9960 [00:04<00:01, 1593.97it/s] 80%|████████  | 7975/9960 [00:04<00:01, 1470.94it/s] 82%|████████▏ | 8124/9960 [00:05<00:01, 1334.46it/s] 83%|████████▎ | 8261/9960 [00:05<00:01, 1308.93it/s] 84%|████████▍ | 8394/9960 [00:05<00:01, 1240.34it/s] 86%|████████▌ | 8520/9960 [00:05<00:01, 1222.36it/s] 87%|████████▋ | 8654/9960 [00:05<00:01, 1254.20it/s] 88%|████████▊ | 8781/9960 [00:05<00:00, 1196.56it/s] 89%|████████▉ | 8909/9960 [00:05<00:00, 1219.24it/s] 91%|█████████ | 9043/9960 [00:05<00:00, 1251.76it/s] 92%|█████████▏| 9170/9960 [00:05<00:00, 1204.02it/s] 93%|█████████▎| 9304/9960 [00:06<00:00, 1242.11it/s] 95%|█████████▍| 9435/9960 [00:06<00:00, 1260.59it/s] 96%|█████████▌| 9562/9960 [00:06<00:00, 1206.47it/s] 97%|█████████▋| 9689/9960 [00:06<00:00, 1224.22it/s] 99%|█████████▊| 9813/9960 [00:06<00:00, 1186.60it/s]100%|█████████▉| 9933/9960 [00:06<00:00, 1136.76it/s]100%|██████████| 9960/9960 [00:06<00:00, 1516.28it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]                                                                 epoch_loss: 0.6985028982162476
Epoch [1/20], Loss: 0.6985
Best test AUROC: 0.7514, at epoch: 0
Epoch [1/20],Test AUROC: 0.7514
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.6483756303787231
Epoch [2/20], Loss: 0.6484
Best test AUROC: 0.7957, at epoch: 1
Epoch [2/20],Test AUROC: 0.7957
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.49969595670700073
Epoch [3/20], Loss: 0.4997
Best test AUROC: 0.7990, at epoch: 2
Epoch [3/20],Test AUROC: 0.7990
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.35602879524230957
Epoch [4/20], Loss: 0.3560
Best test AUROC: 0.8020, at epoch: 3
Epoch [4/20],Test AUROC: 0.8020
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.22838467359542847
Epoch [5/20], Loss: 0.2284
Best test AUROC: 0.8043, at epoch: 4
Epoch [5/20],Test AUROC: 0.8043
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.13740694522857666
Epoch [6/20], Loss: 0.1374
Best test AUROC: 0.8053, at epoch: 5
Epoch [6/20],Test AUROC: 0.8053
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.0795900970697403
Epoch [7/20], Loss: 0.0796
Epoch [7/20],Test AUROC: 0.8052
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.04320882260799408
Epoch [8/20], Loss: 0.0432
Epoch [8/20],Test AUROC: 0.8040
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.022212142124772072
Epoch [9/20], Loss: 0.0222
Epoch [9/20],Test AUROC: 0.8025
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.011589834466576576
Epoch [10/20], Loss: 0.0116
Epoch [10/20],Test AUROC: 0.8008
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0063679516315460205
Epoch [11/20], Loss: 0.0064
Epoch [11/20],Test AUROC: 0.7992
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.003713046433404088
Epoch [12/20], Loss: 0.0037
Epoch [12/20],Test AUROC: 0.7978
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.0022902637720108032
Epoch [13/20], Loss: 0.0023
Epoch [13/20],Test AUROC: 0.7967
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]                                                                  epoch_loss: 0.0014834603061899543
Epoch [14/20], Loss: 0.0015
Epoch [14/20],Test AUROC: 0.7960
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.0010016255546361208
Epoch [15/20], Loss: 0.0010
Epoch [15/20],Test AUROC: 0.7955
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.0006999208708293736
Epoch [16/20], Loss: 0.0007
Epoch [16/20],Test AUROC: 0.7952
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0005040853284299374
Epoch [17/20], Loss: 0.0005
Epoch [17/20],Test AUROC: 0.7950
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.00037209989386610687
Epoch [18/20], Loss: 0.0004
Epoch [18/20],Test AUROC: 0.7949
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.0002804527466651052
Epoch [19/20], Loss: 0.0003
Epoch [19/20],Test AUROC: 0.7948
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.00021551935060415417
Epoch [20/20], Loss: 0.0002
Epoch [20/20],Test AUROC: 0.7947
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.08it/s]  2%|▏         | 2/115 [00:01<00:57,  1.95it/s]  3%|▎         | 3/115 [00:01<00:48,  2.31it/s]  3%|▎         | 4/115 [00:01<00:52,  2.12it/s]  4%|▍         | 5/115 [00:02<00:53,  2.07it/s]  5%|▌         | 6/115 [00:02<00:49,  2.19it/s]  6%|▌         | 7/115 [00:03<00:45,  2.35it/s]  7%|▋         | 8/115 [00:03<00:45,  2.35it/s]  8%|▊         | 9/115 [00:04<00:47,  2.23it/s]  9%|▊         | 10/115 [00:04<00:49,  2.11it/s] 10%|▉         | 11/115 [00:04<00:44,  2.33it/s] 10%|█         | 12/115 [00:05<00:48,  2.12it/s] 11%|█▏        | 13/115 [00:06<00:48,  2.09it/s] 12%|█▏        | 14/115 [00:06<00:49,  2.05it/s] 13%|█▎        | 15/115 [00:06<00:44,  2.25it/s] 14%|█▍        | 16/115 [00:07<00:48,  2.05it/s] 15%|█▍        | 17/115 [00:08<00:50,  1.96it/s] 16%|█▌        | 18/115 [00:08<00:51,  1.88it/s] 17%|█▋        | 19/115 [00:08<00:45,  2.11it/s] 17%|█▋        | 20/115 [00:09<00:43,  2.18it/s] 18%|█▊        | 21/115 [00:09<00:45,  2.08it/s] 19%|█▉        | 22/115 [00:10<00:45,  2.05it/s] 20%|██        | 23/115 [00:10<00:40,  2.27it/s] 21%|██        | 24/115 [00:11<00:39,  2.33it/s] 22%|██▏       | 25/115 [00:11<00:36,  2.50it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.64it/s] 23%|██▎       | 27/115 [00:12<00:37,  2.35it/s] 24%|██▍       | 28/115 [00:12<00:40,  2.16it/s] 25%|██▌       | 29/115 [00:13<00:44,  1.93it/s] 26%|██▌       | 30/115 [00:14<00:44,  1.91it/s] 27%|██▋       | 31/115 [00:14<00:40,  2.07it/s] 28%|██▊       | 32/115 [00:14<00:40,  2.06it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.91it/s] 30%|██▉       | 34/115 [00:16<00:40,  1.98it/s] 30%|███       | 35/115 [00:16<00:39,  2.04it/s] 31%|███▏      | 36/115 [00:17<00:39,  1.98it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.91it/s] 33%|███▎      | 38/115 [00:18<00:39,  1.96it/s] 34%|███▍      | 39/115 [00:18<00:36,  2.10it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.17it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.96it/s] 37%|███▋      | 42/115 [00:19<00:36,  1.98it/s] 37%|███▋      | 43/115 [00:20<00:41,  1.72it/s] 38%|███▊      | 44/115 [00:21<00:46,  1.53it/s] 39%|███▉      | 45/115 [00:22<00:43,  1.60it/s] 40%|████      | 46/115 [00:22<00:42,  1.62it/s] 41%|████      | 47/115 [00:23<00:39,  1.72it/s] 42%|████▏     | 48/115 [00:24<00:51,  1.30it/s] 43%|████▎     | 49/115 [00:25<00:48,  1.36it/s] 43%|████▎     | 50/115 [00:25<00:44,  1.47it/s] 44%|████▍     | 51/115 [00:26<00:40,  1.59it/s] 45%|████▌     | 52/115 [00:26<00:40,  1.56it/s] 46%|████▌     | 53/115 [00:27<00:39,  1.58it/s] 47%|████▋     | 54/115 [00:28<00:37,  1.63it/s] 48%|████▊     | 55/115 [00:28<00:31,  1.91it/s] 49%|████▊     | 56/115 [00:28<00:29,  2.02it/s] 50%|████▉     | 57/115 [00:29<00:25,  2.30it/s] 50%|█████     | 58/115 [00:29<00:23,  2.43it/s] 51%|█████▏    | 59/115 [00:29<00:21,  2.65it/s] 52%|█████▏    | 60/115 [00:30<00:23,  2.36it/s] 53%|█████▎    | 61/115 [00:30<00:23,  2.31it/s] 54%|█████▍    | 62/115 [00:31<00:24,  2.16it/s] 55%|█████▍    | 63/115 [00:31<00:26,  1.96it/s] 56%|█████▌    | 64/115 [00:32<00:25,  2.01it/s] 57%|█████▋    | 65/115 [00:32<00:24,  2.08it/s] 57%|█████▋    | 66/115 [00:33<00:24,  2.00it/s] 58%|█████▊    | 67/115 [00:33<00:22,  2.18it/s] 59%|█████▉    | 68/115 [00:34<00:20,  2.27it/s] 60%|██████    | 69/115 [00:34<00:20,  2.19it/s] 61%|██████    | 70/115 [00:35<00:21,  2.13it/s] 62%|██████▏   | 71/115 [00:35<00:20,  2.15it/s] 63%|██████▎   | 72/115 [00:36<00:20,  2.10it/s] 63%|██████▎   | 73/115 [00:36<00:18,  2.26it/s] 64%|██████▍   | 74/115 [00:36<00:17,  2.35it/s] 65%|██████▌   | 75/115 [00:37<00:17,  2.31it/s] 66%|██████▌   | 76/115 [00:37<00:18,  2.14it/s] 67%|██████▋   | 77/115 [00:38<00:18,  2.04it/s] 68%|██████▊   | 78/115 [00:38<00:16,  2.19it/s] 69%|██████▊   | 79/115 [00:39<00:17,  2.09it/s] 70%|██████▉   | 80/115 [00:39<00:15,  2.24it/s] 70%|███████   | 81/115 [00:39<00:14,  2.30it/s] 71%|███████▏  | 82/115 [00:40<00:14,  2.31it/s] 72%|███████▏  | 83/115 [00:40<00:13,  2.38it/s] 73%|███████▎  | 84/115 [00:41<00:13,  2.24it/s] 74%|███████▍  | 85/115 [00:41<00:13,  2.19it/s] 75%|███████▍  | 86/115 [00:42<00:13,  2.07it/s] 76%|███████▌  | 87/115 [00:43<00:15,  1.85it/s] 77%|███████▋  | 88/115 [00:43<00:14,  1.90it/s] 77%|███████▋  | 89/115 [00:43<00:11,  2.18it/s] 78%|███████▊  | 90/115 [00:45<00:17,  1.45it/s] 79%|███████▉  | 91/115 [00:45<00:16,  1.45it/s] 80%|████████  | 92/115 [00:46<00:15,  1.49it/s] 81%|████████  | 93/115 [00:46<00:14,  1.57it/s] 82%|████████▏ | 94/115 [00:47<00:12,  1.72it/s] 83%|████████▎ | 95/115 [00:47<00:10,  1.82it/s] 83%|████████▎ | 96/115 [00:48<00:10,  1.74it/s] 84%|████████▍ | 97/115 [00:48<00:09,  1.83it/s] 85%|████████▌ | 98/115 [00:49<00:08,  2.01it/s] 86%|████████▌ | 99/115 [00:49<00:07,  2.10it/s] 87%|████████▋ | 100/115 [00:50<00:06,  2.27it/s] 88%|████████▊ | 101/115 [00:50<00:06,  2.19it/s] 89%|████████▊ | 102/115 [00:51<00:06,  2.14it/s] 90%|████████▉ | 103/115 [00:51<00:05,  2.35it/s] 90%|█████████ | 104/115 [00:51<00:04,  2.27it/s] 91%|█████████▏| 105/115 [00:52<00:03,  2.58it/s] 92%|█████████▏| 106/115 [00:52<00:03,  2.39it/s] 93%|█████████▎| 107/115 [00:53<00:03,  2.46it/s] 94%|█████████▍| 108/115 [00:53<00:02,  2.66it/s] 95%|█████████▍| 109/115 [00:53<00:02,  2.79it/s] 96%|█████████▌| 110/115 [00:54<00:02,  1.88it/s] 97%|█████████▋| 111/115 [00:55<00:02,  1.66it/s] 97%|█████████▋| 112/115 [00:59<00:04,  1.54s/it] 98%|█████████▊| 113/115 [00:59<00:02,  1.20s/it] 99%|█████████▉| 114/115 [00:59<00:00,  1.02it/s]100%|██████████| 115/115 [01:00<00:00,  1.92it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.57it/s]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 7.836390917267029e-05
Epoch [1/20], Loss: 0.0001
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 5.7461464166408405e-05
Epoch [2/20], Loss: 0.0001
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 4.253975384926889e-05
Epoch [3/20], Loss: 0.0000
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.14it/s]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 3.18154961860273e-05
Epoch [4/20], Loss: 0.0000
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 2.3999045273133863e-05
Epoch [5/20], Loss: 0.0000
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 1.8282099820983905e-05
Epoch [6/20], Loss: 0.0000
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.14it/s]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 1.4039933375897817e-05
Epoch [7/20], Loss: 0.0000
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 1.0892494628933491e-05
Epoch [8/20], Loss: 0.0000
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.57it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                 epoch_loss: 8.528366682488317e-06
Epoch [9/20], Loss: 0.0000
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 6.7376645347394515e-06
Epoch [10/20], Loss: 0.0000
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 5.359255131528092e-06
Epoch [11/20], Loss: 0.0000
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 4.3077578387359e-06
Epoch [12/20], Loss: 0.0000
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 3.4925161192707796e-06
Epoch [13/20], Loss: 0.0000
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 2.846162033165456e-06
Epoch [14/20], Loss: 0.0000
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.57it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 2.3413740185181573e-06
Epoch [15/20], Loss: 0.0000
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.57it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 1.943381334967853e-06
Epoch [16/20], Loss: 0.0000
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 1.6248633869508922e-06
Epoch [17/20], Loss: 0.0000
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 1.3616055033101777e-06
Epoch [18/20], Loss: 0.0000
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]                                                                  epoch_loss: 1.1554698554997838e-06
Epoch [19/20], Loss: 0.0000
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 9.92796723645976e-07
Epoch [20/20], Loss: 0.0000
best_test_auroc: 0.8052859532844844
