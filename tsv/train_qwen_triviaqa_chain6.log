Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   1%|          | 120/17944 [00:00<00:15, 1176.07 examples/s]Map:   1%|▏         | 246/17944 [00:00<00:14, 1218.34 examples/s]Map:   2%|▏         | 375/17944 [00:00<00:14, 1245.01 examples/s]Map:   3%|▎         | 504/17944 [00:00<00:13, 1258.29 examples/s]Map:   4%|▎         | 633/17944 [00:00<00:13, 1266.20 examples/s]Map:   4%|▍         | 762/17944 [00:00<00:13, 1270.36 examples/s]Map:   5%|▌         | 939/17944 [00:00<00:13, 1229.12 examples/s]Map:   6%|▌         | 1064/17944 [00:00<00:13, 1234.17 examples/s]Map:   7%|▋         | 1194/17944 [00:00<00:13, 1250.86 examples/s]Map:   7%|▋         | 1324/17944 [00:01<00:13, 1262.05 examples/s]Map:   8%|▊         | 1454/17944 [00:01<00:12, 1271.51 examples/s]Map:   9%|▉         | 1584/17944 [00:01<00:12, 1277.75 examples/s]Map:  10%|▉         | 1713/17944 [00:01<00:12, 1276.88 examples/s]Map:  11%|█         | 1905/17944 [00:01<00:12, 1274.61 examples/s]Map:  12%|█▏        | 2086/17944 [00:01<00:12, 1245.03 examples/s]Map:  12%|█▏        | 2216/17944 [00:01<00:12, 1256.77 examples/s]Map:  13%|█▎        | 2346/17944 [00:01<00:12, 1266.21 examples/s]Map:  14%|█▍        | 2475/17944 [00:01<00:12, 1272.02 examples/s]Map:  15%|█▍        | 2605/17944 [00:02<00:12, 1276.38 examples/s]Map:  15%|█▌        | 2735/17944 [00:02<00:11, 1280.10 examples/s]Map:  16%|█▌        | 2864/17944 [00:02<00:11, 1281.47 examples/s]Map:  17%|█▋        | 2994/17944 [00:02<00:11, 1283.68 examples/s]Map:  18%|█▊        | 3169/17944 [00:02<00:11, 1236.38 examples/s]Map:  18%|█▊        | 3299/17944 [00:02<00:11, 1250.76 examples/s]Map:  19%|█▉        | 3429/17944 [00:02<00:11, 1261.67 examples/s]Map:  20%|█▉        | 3557/17944 [00:02<00:11, 1264.69 examples/s]Map:  21%|██        | 3685/17944 [00:02<00:11, 1267.14 examples/s]Map:  21%|██▏       | 3815/17944 [00:03<00:11, 1273.89 examples/s]Map:  22%|██▏       | 3945/17944 [00:03<00:10, 1278.55 examples/s]Map:  23%|██▎       | 4074/17944 [00:03<00:10, 1278.27 examples/s]Map:  23%|██▎       | 4204/17944 [00:03<00:10, 1281.03 examples/s]Map:  24%|██▍       | 4386/17944 [00:03<00:10, 1248.82 examples/s]Map:  25%|██▌       | 4515/17944 [00:03<00:10, 1258.08 examples/s]Map:  26%|██▌       | 4644/17944 [00:03<00:10, 1263.21 examples/s]Map:  27%|██▋       | 4771/17944 [00:03<00:10, 1263.18 examples/s]Map:  27%|██▋       | 4902/17944 [00:03<00:10, 1272.00 examples/s]Map:  28%|██▊       | 5094/17944 [00:04<00:10, 1269.83 examples/s]Map:  29%|██▉       | 5224/17944 [00:04<00:09, 1274.96 examples/s]Map:  30%|██▉       | 5354/17944 [00:04<00:09, 1279.18 examples/s]Map:  31%|███       | 5533/17944 [00:04<00:09, 1242.35 examples/s]Map:  32%|███▏      | 5663/17944 [00:04<00:09, 1255.81 examples/s]Map:  32%|███▏      | 5790/17944 [00:04<00:09, 1256.85 examples/s]Map:  33%|███▎      | 5919/17944 [00:04<00:09, 1265.35 examples/s]Map:  34%|███▎      | 6049/17944 [00:04<00:09, 1273.17 examples/s]Map:  34%|███▍      | 6177/17944 [00:04<00:09, 1273.60 examples/s]Map:  35%|███▌      | 6307/17944 [00:04<00:09, 1279.48 examples/s]Map:  36%|███▌      | 6437/17944 [00:05<00:08, 1283.34 examples/s]Map:  37%|███▋      | 6567/17944 [00:05<00:08, 1285.12 examples/s]Map:  38%|███▊      | 6745/17944 [00:05<00:09, 1244.11 examples/s]Map:  38%|███▊      | 6875/17944 [00:05<00:08, 1256.06 examples/s]Map:  39%|███▉      | 7003/17944 [00:05<00:08, 1261.50 examples/s]Map:  40%|███▉      | 7133/17944 [00:05<00:08, 1269.05 examples/s]Map:  40%|████      | 7263/17944 [00:05<00:08, 1274.79 examples/s]Map:  41%|████      | 7393/17944 [00:05<00:08, 1279.92 examples/s]Map:  42%|████▏     | 7523/17944 [00:05<00:08, 1282.57 examples/s]Map:  43%|████▎     | 7653/17944 [00:06<00:08, 1283.93 examples/s]Map:  44%|████▎     | 7837/17944 [00:06<00:08, 1257.13 examples/s]Map:  45%|████▍     | 8026/17944 [00:06<00:07, 1255.06 examples/s]Map:  45%|████▌     | 8155/17944 [00:06<00:07, 1262.89 examples/s]Map:  46%|████▌     | 8285/17944 [00:06<00:07, 1269.76 examples/s]Map:  47%|████▋     | 8415/17944 [00:06<00:07, 1275.60 examples/s]Map:  48%|████▊     | 8545/17944 [00:06<00:07, 1280.42 examples/s]Map:  48%|████▊     | 8675/17944 [00:06<00:07, 1283.58 examples/s]Map:  49%|████▉     | 8805/17944 [00:06<00:07, 1286.48 examples/s]Map:  50%|████▉     | 8935/17944 [00:07<00:07, 1285.91 examples/s]Map:  51%|█████     | 9116/17944 [00:07<00:07, 1251.02 examples/s]Map:  52%|█████▏    | 9247/17944 [00:07<00:06, 1262.61 examples/s]Map:  52%|█████▏    | 9377/17944 [00:07<00:06, 1270.50 examples/s]Map:  53%|█████▎    | 9569/17944 [00:07<00:06, 1271.10 examples/s]Map:  54%|█████▍    | 9698/17944 [00:07<00:06, 1275.27 examples/s]Map:  55%|█████▍    | 9828/17944 [00:07<00:06, 1279.87 examples/s]Map:  56%|█████▌    | 10050/17944 [00:07<00:05, 1539.13 examples/s]Map:  67%|██████▋   | 11998/17944 [00:07<00:00, 6642.64 examples/s]Map:  78%|███████▊  | 13970/17944 [00:08<00:00, 10419.29 examples/s]Map:  89%|████████▊ | 15891/17944 [00:08<00:00, 12987.15 examples/s]Map:  99%|█████████▉| 17839/17944 [00:08<00:00, 14892.56 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2121.59 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.49s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:10<00:03,  3.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.44s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  2%|▏         | 156/9960 [00:00<00:06, 1551.38it/s]  3%|▎         | 323/9960 [00:00<00:05, 1618.66it/s]  5%|▍         | 495/9960 [00:00<00:05, 1660.77it/s]  7%|▋         | 664/9960 [00:00<00:05, 1671.42it/s]  8%|▊         | 833/9960 [00:00<00:05, 1676.51it/s] 10%|█         | 1003/9960 [00:00<00:05, 1683.71it/s] 12%|█▏        | 1175/9960 [00:00<00:05, 1692.63it/s] 14%|█▎        | 1346/9960 [00:00<00:05, 1697.07it/s] 15%|█▌        | 1516/9960 [00:00<00:05, 1666.21it/s] 17%|█▋        | 1683/9960 [00:01<00:04, 1661.90it/s] 19%|█▊        | 1853/9960 [00:01<00:04, 1671.48it/s] 20%|██        | 2026/9960 [00:01<00:04, 1687.94it/s] 22%|██▏       | 2198/9960 [00:01<00:04, 1696.50it/s] 24%|██▍       | 2368/9960 [00:01<00:04, 1658.61it/s] 25%|██▌       | 2535/9960 [00:01<00:04, 1649.35it/s] 27%|██▋       | 2701/9960 [00:01<00:06, 1097.19it/s] 29%|██▊       | 2847/9960 [00:01<00:06, 1175.87it/s] 30%|███       | 3014/9960 [00:01<00:05, 1291.83it/s] 32%|███▏      | 3180/9960 [00:02<00:04, 1384.19it/s] 34%|███▎      | 3351/9960 [00:02<00:04, 1468.62it/s] 35%|███▌      | 3516/9960 [00:02<00:04, 1517.68it/s] 37%|███▋      | 3682/9960 [00:02<00:04, 1556.17it/s] 39%|███▊      | 3844/9960 [00:02<00:03, 1573.44it/s] 40%|████      | 4006/9960 [00:02<00:03, 1573.85it/s] 42%|████▏     | 4167/9960 [00:02<00:03, 1583.89it/s] 43%|████▎     | 4330/9960 [00:02<00:03, 1596.12it/s] 45%|████▌     | 4496/9960 [00:02<00:03, 1614.17it/s] 47%|████▋     | 4659/9960 [00:02<00:03, 1612.77it/s] 49%|████▊     | 4831/9960 [00:03<00:03, 1644.46it/s] 50%|█████     | 5008/9960 [00:03<00:02, 1680.71it/s] 52%|█████▏    | 5181/9960 [00:03<00:02, 1694.60it/s] 54%|█████▍    | 5355/9960 [00:03<00:02, 1705.90it/s] 56%|█████▌    | 5529/9960 [00:03<00:02, 1715.41it/s] 57%|█████▋    | 5703/9960 [00:03<00:02, 1719.94it/s] 59%|█████▉    | 5876/9960 [00:03<00:02, 1719.69it/s] 61%|██████    | 6049/9960 [00:03<00:02, 1718.25it/s] 62%|██████▏   | 6223/9960 [00:03<00:02, 1723.08it/s] 64%|██████▍   | 6398/9960 [00:04<00:02, 1728.63it/s] 66%|██████▌   | 6571/9960 [00:05<00:07, 425.03it/s]  68%|██████▊   | 6744/9960 [00:05<00:05, 548.73it/s] 69%|██████▉   | 6914/9960 [00:05<00:04, 686.17it/s] 71%|███████   | 7086/9960 [00:05<00:03, 836.83it/s] 73%|███████▎  | 7258/9960 [00:05<00:02, 988.56it/s] 75%|███████▍  | 7428/9960 [00:05<00:02, 1127.76it/s] 76%|███████▌  | 7591/9960 [00:05<00:01, 1227.32it/s] 78%|███████▊  | 7764/9960 [00:05<00:01, 1344.66it/s] 80%|███████▉  | 7932/9960 [00:05<00:01, 1429.29it/s] 81%|████████▏ | 8104/9960 [00:06<00:01, 1504.71it/s] 83%|████████▎ | 8276/9960 [00:06<00:01, 1561.86it/s] 85%|████████▍ | 8447/9960 [00:06<00:00, 1600.80it/s] 87%|████████▋ | 8618/9960 [00:06<00:00, 1629.53it/s] 88%|████████▊ | 8789/9960 [00:06<00:00, 1651.63it/s] 90%|█████████ | 8965/9960 [00:06<00:00, 1683.31it/s] 92%|█████████▏| 9140/9960 [00:06<00:00, 1702.77it/s] 94%|█████████▎| 9315/9960 [00:06<00:00, 1716.75it/s] 95%|█████████▌| 9491/9960 [00:06<00:00, 1728.18it/s] 97%|█████████▋| 9665/9960 [00:06<00:00, 1710.49it/s] 99%|█████████▉| 9837/9960 [00:07<00:00, 1689.70it/s]100%|██████████| 9960/9960 [00:07<00:00, 1398.65it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]                                                                 epoch_loss: 0.713432788848877
Epoch [1/20], Loss: 0.7134
Best test AUROC: 0.5729, at epoch: 0
Epoch [1/20],Test AUROC: 0.5729
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]                                                                 epoch_loss: 0.6826717853546143
Epoch [2/20], Loss: 0.6827
Best test AUROC: 0.6650, at epoch: 1
Epoch [2/20],Test AUROC: 0.6650
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]                                                                 epoch_loss: 0.6611248254776001
Epoch [3/20], Loss: 0.6611
Best test AUROC: 0.7151, at epoch: 2
Epoch [3/20],Test AUROC: 0.7151
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.6404581665992737
Epoch [4/20], Loss: 0.6405
Best test AUROC: 0.7510, at epoch: 3
Epoch [4/20],Test AUROC: 0.7510
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.6184016466140747
Epoch [5/20], Loss: 0.6184
Best test AUROC: 0.7727, at epoch: 4
Epoch [5/20],Test AUROC: 0.7727
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.5949146151542664
Epoch [6/20], Loss: 0.5949
Best test AUROC: 0.7894, at epoch: 5
Epoch [6/20],Test AUROC: 0.7894
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.5724685788154602
Epoch [7/20], Loss: 0.5725
Best test AUROC: 0.7968, at epoch: 6
Epoch [7/20],Test AUROC: 0.7968
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.5440737009048462
Epoch [8/20], Loss: 0.5441
Best test AUROC: 0.8004, at epoch: 7
Epoch [8/20],Test AUROC: 0.8004
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.5135471224784851
Epoch [9/20], Loss: 0.5135
Epoch [9/20],Test AUROC: 0.7987
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.48731857538223267
Epoch [10/20], Loss: 0.4873
Best test AUROC: 0.8091, at epoch: 9
Epoch [10/20],Test AUROC: 0.8091
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.4507220387458801
Epoch [11/20], Loss: 0.4507
Best test AUROC: 0.8145, at epoch: 10
Epoch [11/20],Test AUROC: 0.8145
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.41391780972480774
Epoch [12/20], Loss: 0.4139
Epoch [12/20],Test AUROC: 0.8104
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.3744657039642334
Epoch [13/20], Loss: 0.3745
Epoch [13/20],Test AUROC: 0.8117
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.3427194058895111
Epoch [14/20], Loss: 0.3427
Epoch [14/20],Test AUROC: 0.8079
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.31335315108299255
Epoch [15/20], Loss: 0.3134
Epoch [15/20],Test AUROC: 0.8142
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.2810124158859253
Epoch [16/20], Loss: 0.2810
Best test AUROC: 0.8164, at epoch: 15
Epoch [16/20],Test AUROC: 0.8164
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.2530208230018616
Epoch [17/20], Loss: 0.2530
Epoch [17/20],Test AUROC: 0.8113
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.2336978018283844
Epoch [18/20], Loss: 0.2337
Epoch [18/20],Test AUROC: 0.8090
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.212243914604187
Epoch [19/20], Loss: 0.2122
Epoch [19/20],Test AUROC: 0.8033
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.194350928068161
Epoch [20/20], Loss: 0.1944
Epoch [20/20],Test AUROC: 0.8017
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.11it/s]  2%|▏         | 2/115 [00:00<00:56,  1.98it/s]  3%|▎         | 3/115 [00:01<00:47,  2.35it/s]  3%|▎         | 4/115 [00:01<00:51,  2.15it/s]  4%|▍         | 5/115 [00:02<00:52,  2.10it/s]  5%|▌         | 6/115 [00:02<00:49,  2.22it/s]  6%|▌         | 7/115 [00:03<00:45,  2.39it/s]  7%|▋         | 8/115 [00:03<00:44,  2.39it/s]  8%|▊         | 9/115 [00:04<00:46,  2.26it/s]  9%|▊         | 10/115 [00:04<00:49,  2.14it/s] 10%|▉         | 11/115 [00:04<00:44,  2.36it/s] 10%|█         | 12/115 [00:05<00:47,  2.15it/s] 11%|█▏        | 13/115 [00:05<00:48,  2.12it/s] 12%|█▏        | 14/115 [00:06<00:48,  2.08it/s] 13%|█▎        | 15/115 [00:06<00:43,  2.29it/s] 14%|█▍        | 16/115 [00:07<00:47,  2.08it/s] 15%|█▍        | 17/115 [00:07<00:49,  1.99it/s] 16%|█▌        | 18/115 [00:08<00:50,  1.91it/s] 17%|█▋        | 19/115 [00:08<00:44,  2.15it/s] 17%|█▋        | 20/115 [00:09<00:42,  2.22it/s] 18%|█▊        | 21/115 [00:09<00:44,  2.11it/s] 19%|█▉        | 22/115 [00:10<00:44,  2.09it/s] 20%|██        | 23/115 [00:10<00:39,  2.31it/s] 21%|██        | 24/115 [00:10<00:38,  2.36it/s] 22%|██▏       | 25/115 [00:11<00:35,  2.54it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.68it/s] 23%|██▎       | 27/115 [00:12<00:36,  2.39it/s] 24%|██▍       | 28/115 [00:12<00:39,  2.19it/s] 25%|██▌       | 29/115 [00:13<00:43,  1.96it/s] 26%|██▌       | 30/115 [00:13<00:43,  1.94it/s] 27%|██▋       | 31/115 [00:14<00:39,  2.11it/s] 28%|██▊       | 32/115 [00:14<00:39,  2.09it/s] 29%|██▊       | 33/115 [00:15<00:41,  1.95it/s] 30%|██▉       | 34/115 [00:15<00:40,  2.01it/s] 30%|███       | 35/115 [00:16<00:38,  2.08it/s] 31%|███▏      | 36/115 [00:16<00:39,  2.01it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.94it/s] 33%|███▎      | 38/115 [00:17<00:38,  1.99it/s] 34%|███▍      | 39/115 [00:18<00:35,  2.13it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.20it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.99it/s] 37%|███▋      | 42/115 [00:19<00:36,  2.01it/s] 37%|███▋      | 43/115 [00:20<00:41,  1.75it/s] 38%|███▊      | 44/115 [00:23<01:30,  1.27s/it] 39%|███▉      | 45/115 [00:23<01:13,  1.06s/it] 40%|████      | 46/115 [00:24<01:03,  1.09it/s] 41%|████      | 47/115 [00:26<01:26,  1.28s/it] 42%|████▏     | 48/115 [00:27<01:16,  1.15s/it] 43%|████▎     | 49/115 [00:28<01:05,  1.01it/s] 43%|████▎     | 50/115 [00:28<00:55,  1.16it/s] 44%|████▍     | 51/115 [00:29<00:48,  1.33it/s] 45%|████▌     | 52/115 [00:30<00:59,  1.06it/s] 46%|████▌     | 53/115 [00:31<00:52,  1.19it/s] 47%|████▋     | 54/115 [00:31<00:45,  1.33it/s] 48%|████▊     | 55/115 [00:31<00:37,  1.61it/s] 49%|████▊     | 56/115 [00:33<00:53,  1.11it/s] 50%|████▉     | 57/115 [00:33<00:41,  1.39it/s] 50%|█████     | 58/115 [00:34<00:34,  1.64it/s] 51%|█████▏    | 59/115 [00:34<00:28,  1.94it/s] 52%|█████▏    | 60/115 [00:34<00:28,  1.93it/s] 53%|█████▎    | 61/115 [00:36<00:44,  1.21it/s] 54%|█████▍    | 62/115 [00:37<00:38,  1.36it/s] 55%|█████▍    | 63/115 [00:37<00:36,  1.44it/s] 56%|█████▌    | 64/115 [00:38<00:31,  1.60it/s] 57%|█████▋    | 65/115 [00:38<00:28,  1.75it/s] 57%|█████▋    | 66/115 [00:39<00:27,  1.79it/s] 58%|█████▊    | 67/115 [00:39<00:23,  2.00it/s] 59%|█████▉    | 68/115 [00:40<00:32,  1.44it/s] 60%|██████    | 69/115 [00:41<00:28,  1.59it/s] 61%|██████    | 70/115 [00:41<00:26,  1.70it/s] 62%|██████▏   | 71/115 [00:42<00:24,  1.83it/s] 63%|██████▎   | 72/115 [00:42<00:22,  1.89it/s] 63%|██████▎   | 73/115 [00:42<00:20,  2.09it/s] 64%|██████▍   | 74/115 [00:43<00:18,  2.23it/s] 65%|██████▌   | 75/115 [00:44<00:23,  1.70it/s] 66%|██████▌   | 76/115 [00:44<00:22,  1.75it/s] 67%|██████▋   | 77/115 [00:45<00:21,  1.79it/s] 68%|██████▊   | 78/115 [00:45<00:18,  1.99it/s] 69%|██████▊   | 79/115 [00:46<00:18,  1.96it/s] 70%|██████▉   | 80/115 [00:47<00:27,  1.26it/s] 70%|███████   | 81/115 [00:47<00:23,  1.48it/s] 71%|███████▏  | 82/115 [00:48<00:19,  1.67it/s] 72%|███████▏  | 83/115 [00:48<00:17,  1.87it/s] 73%|███████▎  | 84/115 [00:49<00:16,  1.91it/s] 74%|███████▍  | 85/115 [00:49<00:15,  1.98it/s] 75%|███████▍  | 86/115 [00:50<00:14,  1.95it/s] 76%|███████▌  | 87/115 [00:50<00:15,  1.79it/s] 77%|███████▋  | 88/115 [00:51<00:14,  1.87it/s] 77%|███████▋  | 89/115 [00:51<00:12,  2.16it/s] 78%|███████▊  | 90/115 [00:52<00:11,  2.19it/s] 79%|███████▉  | 91/115 [00:52<00:12,  1.91it/s] 80%|████████  | 92/115 [00:53<00:12,  1.81it/s] 81%|████████  | 93/115 [00:53<00:12,  1.82it/s] 82%|████████▏ | 94/115 [00:54<00:12,  1.71it/s] 83%|████████▎ | 95/115 [00:55<00:11,  1.82it/s] 83%|████████▎ | 96/115 [00:55<00:10,  1.75it/s] 84%|████████▍ | 97/115 [00:56<00:09,  1.85it/s] 85%|████████▌ | 98/115 [00:56<00:08,  2.03it/s] 86%|████████▌ | 99/115 [00:57<00:11,  1.35it/s] 87%|████████▋ | 100/115 [00:58<00:09,  1.60it/s] 88%|████████▊ | 101/115 [00:58<00:08,  1.72it/s] 89%|████████▊ | 102/115 [00:59<00:07,  1.81it/s] 90%|████████▉ | 103/115 [00:59<00:05,  2.07it/s] 90%|█████████ | 104/115 [01:00<00:05,  2.09it/s] 91%|█████████▏| 105/115 [01:00<00:04,  2.42it/s] 92%|█████████▏| 106/115 [01:01<00:06,  1.40it/s] 93%|█████████▎| 107/115 [01:02<00:04,  1.64it/s] 94%|█████████▍| 108/115 [01:02<00:03,  1.93it/s] 95%|█████████▍| 109/115 [01:02<00:02,  2.19it/s] 96%|█████████▌| 110/115 [01:04<00:04,  1.15it/s] 97%|█████████▋| 111/115 [01:05<00:03,  1.20it/s] 97%|█████████▋| 112/115 [01:06<00:02,  1.02it/s] 98%|█████████▊| 113/115 [01:07<00:02,  1.03s/it] 99%|█████████▉| 114/115 [01:08<00:00,  1.02it/s]100%|██████████| 115/115 [01:08<00:00,  1.68it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.23it/s]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:02<00:01,  1.15s/it]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]                                                                 epoch_loss: 0.14358036716779074
Epoch [1/20], Loss: 0.1436
Best test AUROC: 0.8169, at epoch: 20
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                 epoch_loss: 0.14766264458497366
Epoch [2/20], Loss: 0.1477
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.15565094351768494
Epoch [3/20], Loss: 0.1557
Best test AUROC: 0.8237, at epoch: 22
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.1334063857793808
Epoch [4/20], Loss: 0.1334
Best test AUROC: 0.8281, at epoch: 23
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.51it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.10258255898952484
Epoch [5/20], Loss: 0.1026
Best test AUROC: 0.8309, at epoch: 24
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.07320842395226161
Epoch [6/20], Loss: 0.0732
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.05563968295852343
Epoch [7/20], Loss: 0.0556
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.045441090439756714
Epoch [8/20], Loss: 0.0454
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                 epoch_loss: 0.03766003499428431
Epoch [9/20], Loss: 0.0377
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.03016899774471919
Epoch [10/20], Loss: 0.0302
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.024056609719991684
Epoch [11/20], Loss: 0.0241
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.019350973889231682
Epoch [12/20], Loss: 0.0194
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 0.015806301186482113
Epoch [13/20], Loss: 0.0158
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.012892377252380053
Epoch [14/20], Loss: 0.0129
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 0.010613144841045141
Epoch [15/20], Loss: 0.0106
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 0.008762134937569499
Epoch [16/20], Loss: 0.0088
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.54it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.007252495968714356
Epoch [17/20], Loss: 0.0073
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.23it/s]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 0.006050469198574622
Epoch [18/20], Loss: 0.0061
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.005081569077447057
Epoch [19/20], Loss: 0.0051
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.22it/s]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]                                                                  epoch_loss: 0.004281863997069498
Epoch [20/20], Loss: 0.0043
best_test_auroc: 0.830948203331604
