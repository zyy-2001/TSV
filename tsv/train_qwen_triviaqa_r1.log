Map:   0%|          | 0/17944 [00:00<?, ? examples/s]Map:   0%|          | 87/17944 [00:00<00:20, 854.70 examples/s]Map:   1%|          | 213/17944 [00:00<00:16, 1082.59 examples/s]Map:   2%|▏         | 342/17944 [00:00<00:15, 1171.21 examples/s]Map:   3%|▎         | 472/17944 [00:00<00:14, 1215.16 examples/s]Map:   3%|▎         | 601/17944 [00:00<00:13, 1240.00 examples/s]Map:   4%|▍         | 731/17944 [00:00<00:13, 1256.24 examples/s]Map:   5%|▍         | 861/17944 [00:00<00:13, 1266.59 examples/s]Map:   6%|▌         | 990/17944 [00:00<00:13, 1271.24 examples/s]Map:   6%|▌         | 1118/17944 [00:00<00:13, 1273.41 examples/s]Map:   7%|▋         | 1247/17944 [00:01<00:13, 1276.67 examples/s]Map:   8%|▊         | 1377/17944 [00:01<00:12, 1281.98 examples/s]Map:   8%|▊         | 1507/17944 [00:01<00:12, 1286.25 examples/s]Map:   9%|▉         | 1637/17944 [00:01<00:12, 1288.66 examples/s]Map:  10%|▉         | 1767/17944 [00:01<00:12, 1290.25 examples/s]Map:  11%|█         | 1897/17944 [00:01<00:12, 1290.35 examples/s]Map:  11%|█▏        | 2027/17944 [00:01<00:12, 1291.67 examples/s]Map:  12%|█▏        | 2158/17944 [00:01<00:12, 1293.43 examples/s]Map:  13%|█▎        | 2347/17944 [00:01<00:12, 1274.14 examples/s]Map:  14%|█▍        | 2477/17944 [00:01<00:12, 1279.52 examples/s]Map:  15%|█▍        | 2608/17944 [00:02<00:11, 1284.78 examples/s]Map:  15%|█▌        | 2738/17944 [00:02<00:11, 1287.84 examples/s]Map:  16%|█▋        | 2930/17944 [00:02<00:11, 1280.16 examples/s]Map:  17%|█▋        | 3060/17944 [00:02<00:11, 1282.10 examples/s]Map:  18%|█▊        | 3190/17944 [00:02<00:11, 1285.32 examples/s]Map:  19%|█▊        | 3320/17944 [00:02<00:11, 1287.77 examples/s]Map:  19%|█▉        | 3450/17944 [00:02<00:11, 1288.72 examples/s]Map:  20%|██        | 3643/17944 [00:02<00:11, 1284.26 examples/s]Map:  21%|██▏       | 3834/17944 [00:03<00:11, 1276.90 examples/s]Map:  22%|██▏       | 3964/17944 [00:03<00:10, 1281.56 examples/s]Map:  23%|██▎       | 4157/17944 [00:03<00:10, 1282.19 examples/s]Map:  24%|██▍       | 4288/17944 [00:03<00:10, 1285.35 examples/s]Map:  25%|██▍       | 4419/17944 [00:03<00:10, 1288.76 examples/s]Map:  26%|██▌       | 4611/17944 [00:03<00:10, 1281.55 examples/s]Map:  26%|██▋       | 4742/17944 [00:03<00:10, 1286.04 examples/s]Map:  27%|██▋       | 4874/17944 [00:03<00:10, 1290.40 examples/s]Map:  28%|██▊       | 5068/17944 [00:03<00:09, 1290.41 examples/s]Map:  29%|██▉       | 5262/17944 [00:04<00:09, 1290.67 examples/s]Map:  30%|███       | 5392/17944 [00:04<00:09, 1291.67 examples/s]Map:  31%|███       | 5523/17944 [00:04<00:09, 1293.86 examples/s]Map:  32%|███▏      | 5653/17944 [00:04<00:09, 1294.13 examples/s]Map:  33%|███▎      | 5844/17944 [00:04<00:09, 1284.11 examples/s]Map:  33%|███▎      | 5974/17944 [00:04<00:09, 1285.74 examples/s]Map:  34%|███▍      | 6105/17944 [00:04<00:09, 1288.46 examples/s]Map:  35%|███▍      | 6235/17944 [00:04<00:09, 1290.92 examples/s]Map:  35%|███▌      | 6366/17944 [00:04<00:08, 1293.02 examples/s]Map:  36%|███▌      | 6497/17944 [00:05<00:08, 1293.66 examples/s]Map:  37%|███▋      | 6627/17944 [00:05<00:08, 1289.52 examples/s]Map:  38%|███▊      | 6756/17944 [00:05<00:08, 1285.48 examples/s]Map:  38%|███▊      | 6886/17944 [00:05<00:08, 1286.08 examples/s]Map:  39%|███▉      | 7015/17944 [00:05<00:08, 1286.74 examples/s]Map:  40%|███▉      | 7145/17944 [00:05<00:08, 1289.32 examples/s]Map:  41%|████      | 7275/17944 [00:05<00:08, 1290.34 examples/s]Map:  41%|████▏     | 7405/17944 [00:05<00:08, 1292.62 examples/s]Map:  42%|████▏     | 7535/17944 [00:05<00:08, 1292.46 examples/s]Map:  43%|████▎     | 7665/17944 [00:05<00:07, 1293.59 examples/s]Map:  44%|████▍     | 7857/17944 [00:06<00:07, 1286.29 examples/s]Map:  45%|████▍     | 7988/17944 [00:06<00:07, 1287.73 examples/s]Map:  45%|████▌     | 8118/17944 [00:06<00:07, 1285.73 examples/s]Map:  46%|████▌     | 8248/17944 [00:06<00:07, 1287.66 examples/s]Map:  47%|████▋     | 8379/17944 [00:06<00:07, 1289.79 examples/s]Map:  47%|████▋     | 8509/17944 [00:06<00:07, 1292.12 examples/s]Map:  48%|████▊     | 8640/17944 [00:06<00:07, 1293.40 examples/s]Map:  49%|████▉     | 8771/17944 [00:06<00:07, 1295.20 examples/s]Map:  50%|████▉     | 8901/17944 [00:06<00:06, 1295.86 examples/s]Map:  51%|█████     | 9093/17944 [00:07<00:06, 1287.89 examples/s]Map:  52%|█████▏    | 9287/17944 [00:07<00:06, 1286.80 examples/s]Map:  53%|█████▎    | 9474/17944 [00:07<00:06, 1271.06 examples/s]Map:  54%|█████▎    | 9604/17944 [00:07<00:06, 1276.98 examples/s]Map:  54%|█████▍    | 9734/17944 [00:07<00:06, 1281.06 examples/s]Map:  55%|█████▍    | 9864/17944 [00:07<00:06, 1285.40 examples/s]Map:  59%|█████▉    | 10592/17944 [00:07<00:02, 2941.63 examples/s]Map:  70%|███████   | 12582/17944 [00:07<00:00, 7743.50 examples/s]Map:  81%|████████  | 14516/17944 [00:08<00:00, 11081.19 examples/s]Map:  92%|█████████▏| 16471/17944 [00:08<00:00, 13547.31 examples/s]Map: 100%|██████████| 17944/17944 [00:08<00:00, 2144.08 examples/s] 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]
  0%|          | 0/9960 [00:00<?, ?it/s]  1%|▏         | 148/9960 [00:00<00:06, 1478.76it/s]  3%|▎         | 306/9960 [00:00<00:06, 1533.13it/s]  5%|▍         | 470/9960 [00:00<00:06, 1580.72it/s]  6%|▋         | 634/9960 [00:00<00:05, 1603.10it/s]  8%|▊         | 796/9960 [00:00<00:05, 1608.41it/s] 10%|▉         | 961/9960 [00:00<00:05, 1621.19it/s] 11%|█▏        | 1126/9960 [00:00<00:05, 1629.10it/s] 13%|█▎        | 1292/9960 [00:00<00:05, 1636.95it/s] 15%|█▍        | 1456/9960 [00:00<00:05, 1637.37it/s] 16%|█▋        | 1620/9960 [00:01<00:05, 1634.39it/s] 18%|█▊        | 1784/9960 [00:01<00:05, 1631.57it/s] 20%|█▉        | 1949/9960 [00:01<00:04, 1634.93it/s] 21%|██▏       | 2118/9960 [00:01<00:04, 1650.55it/s] 23%|██▎       | 2284/9960 [00:01<00:04, 1652.14it/s] 25%|██▍       | 2450/9960 [00:01<00:04, 1647.94it/s] 26%|██▋       | 2615/9960 [00:01<00:04, 1633.70it/s] 28%|██▊       | 2779/9960 [00:01<00:04, 1622.82it/s] 30%|██▉       | 2942/9960 [00:01<00:04, 1620.42it/s] 31%|███       | 3105/9960 [00:01<00:04, 1616.96it/s] 33%|███▎      | 3268/9960 [00:02<00:04, 1618.34it/s] 34%|███▍      | 3433/9960 [00:02<00:04, 1627.24it/s] 36%|███▌      | 3596/9960 [00:02<00:04, 1585.27it/s] 38%|███▊      | 3755/9960 [00:02<00:03, 1569.11it/s] 39%|███▉      | 3913/9960 [00:02<00:03, 1569.27it/s] 41%|████      | 4071/9960 [00:02<00:03, 1555.78it/s] 42%|████▏     | 4227/9960 [00:02<00:03, 1547.52it/s] 44%|████▍     | 4387/9960 [00:02<00:03, 1561.45it/s] 46%|████▌     | 4548/9960 [00:02<00:03, 1573.34it/s] 47%|████▋     | 4707/9960 [00:02<00:03, 1577.04it/s] 49%|████▉     | 4876/9960 [00:03<00:03, 1609.30it/s] 51%|█████     | 5047/9960 [00:03<00:03, 1636.93it/s] 52%|█████▏    | 5214/9960 [00:03<00:02, 1646.66it/s] 54%|█████▍    | 5380/9960 [00:03<00:02, 1649.86it/s] 56%|█████▌    | 5548/9960 [00:03<00:02, 1658.82it/s] 57%|█████▋    | 5715/9960 [00:03<00:02, 1660.78it/s] 59%|█████▉    | 5882/9960 [00:03<00:02, 1662.90it/s] 61%|██████    | 6049/9960 [00:03<00:02, 1661.58it/s] 62%|██████▏   | 6217/9960 [00:03<00:02, 1665.82it/s] 64%|██████▍   | 6384/9960 [00:03<00:02, 1660.89it/s] 66%|██████▌   | 6551/9960 [00:04<00:02, 1655.70it/s] 67%|██████▋   | 6717/9960 [00:04<00:01, 1654.14it/s] 69%|██████▉   | 6883/9960 [00:04<00:01, 1654.34it/s] 71%|███████   | 7051/9960 [00:04<00:01, 1658.89it/s] 72%|███████▏  | 7217/9960 [00:04<00:01, 1653.86it/s] 74%|███████▍  | 7383/9960 [00:04<00:01, 1643.92it/s] 76%|███████▌  | 7548/9960 [00:04<00:01, 1613.18it/s] 77%|███████▋  | 7713/9960 [00:04<00:01, 1621.91it/s] 79%|███████▉  | 7880/9960 [00:04<00:01, 1633.73it/s] 81%|████████  | 8044/9960 [00:04<00:01, 1633.35it/s] 82%|████████▏ | 8210/9960 [00:05<00:01, 1639.50it/s] 84%|████████▍ | 8375/9960 [00:05<00:00, 1641.88it/s] 86%|████████▌ | 8540/9960 [00:05<00:00, 1644.27it/s] 87%|████████▋ | 8706/9960 [00:05<00:00, 1646.52it/s] 89%|████████▉ | 8874/9960 [00:05<00:00, 1655.14it/s] 91%|█████████ | 9043/9960 [00:05<00:00, 1665.00it/s] 92%|█████████▏| 9211/9960 [00:05<00:00, 1669.06it/s] 94%|█████████▍| 9378/9960 [00:05<00:00, 1666.33it/s] 96%|█████████▌| 9548/9960 [00:05<00:00, 1676.16it/s] 98%|█████████▊| 9716/9960 [00:05<00:00, 1641.37it/s] 99%|█████████▉| 9881/9960 [00:06<00:00, 1616.38it/s]100%|██████████| 9960/9960 [00:06<00:00, 1628.13it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]                                                                 epoch_loss: 0.6987965703010559
Epoch [1/20], Loss: 0.6988
Best test AUROC: 0.5042, at epoch: 0
Epoch [1/20],Test AUROC: 0.5042
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.6714199781417847
Epoch [2/20], Loss: 0.6714
Epoch [2/20],Test AUROC: 0.4997
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                 epoch_loss: 0.6748056411743164
Epoch [3/20], Loss: 0.6748
Epoch [3/20],Test AUROC: 0.4220
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.6458474397659302
Epoch [4/20], Loss: 0.6458
Epoch [4/20],Test AUROC: 0.4832
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.6139179468154907
Epoch [5/20], Loss: 0.6139
Best test AUROC: 0.5114, at epoch: 4
Epoch [5/20],Test AUROC: 0.5114
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.5869797468185425
Epoch [6/20], Loss: 0.5870
Best test AUROC: 0.6277, at epoch: 5
Epoch [6/20],Test AUROC: 0.6277
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.519202470779419
Epoch [7/20], Loss: 0.5192
Best test AUROC: 0.6294, at epoch: 6
Epoch [7/20],Test AUROC: 0.6294
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.4973849952220917
Epoch [8/20], Loss: 0.4974
Best test AUROC: 0.7356, at epoch: 7
Epoch [8/20],Test AUROC: 0.7356
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                 epoch_loss: 0.3944176733493805
Epoch [9/20], Loss: 0.3944
Best test AUROC: 0.7706, at epoch: 8
Epoch [9/20],Test AUROC: 0.7706
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.3288698196411133
Epoch [10/20], Loss: 0.3289
Best test AUROC: 0.7832, at epoch: 9
Epoch [10/20],Test AUROC: 0.7832
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]                                                                  epoch_loss: 0.2751805782318115
Epoch [11/20], Loss: 0.2752
Best test AUROC: 0.7860, at epoch: 10
Epoch [11/20],Test AUROC: 0.7860
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.24141696095466614
Epoch [12/20], Loss: 0.2414
Best test AUROC: 0.7865, at epoch: 11
Epoch [12/20],Test AUROC: 0.7865
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.21942776441574097
Epoch [13/20], Loss: 0.2194
Best test AUROC: 0.7875, at epoch: 12
Epoch [13/20],Test AUROC: 0.7875
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.20508554577827454
Epoch [14/20], Loss: 0.2051
Best test AUROC: 0.7881, at epoch: 13
Epoch [14/20],Test AUROC: 0.7881
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.19597399234771729
Epoch [15/20], Loss: 0.1960
Epoch [15/20],Test AUROC: 0.7874
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.19097594916820526
Epoch [16/20], Loss: 0.1910
Epoch [16/20],Test AUROC: 0.7872
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.1893884390592575
Epoch [17/20], Loss: 0.1894
Epoch [17/20],Test AUROC: 0.7873
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.19036975502967834
Epoch [18/20], Loss: 0.1904
Epoch [18/20],Test AUROC: 0.7871
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]                                                                  epoch_loss: 0.19322127103805542
Epoch [19/20], Loss: 0.1932
Epoch [19/20],Test AUROC: 0.7875
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]                                                                  epoch_loss: 0.19743451476097107
Epoch [20/20], Loss: 0.1974
Epoch [20/20],Test AUROC: 0.7870
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:00<00:54,  2.10it/s]  2%|▏         | 2/115 [00:01<00:57,  1.98it/s]  3%|▎         | 3/115 [00:01<00:47,  2.34it/s]  3%|▎         | 4/115 [00:01<00:51,  2.14it/s]  4%|▍         | 5/115 [00:02<00:52,  2.09it/s]  5%|▌         | 6/115 [00:02<00:49,  2.21it/s]  6%|▌         | 7/115 [00:03<00:45,  2.38it/s]  7%|▋         | 8/115 [00:03<00:44,  2.38it/s]  8%|▊         | 9/115 [00:04<00:47,  2.25it/s]  9%|▊         | 10/115 [00:04<00:49,  2.14it/s] 10%|▉         | 11/115 [00:04<00:44,  2.35it/s] 10%|█         | 12/115 [00:05<00:48,  2.14it/s] 11%|█▏        | 13/115 [00:05<00:48,  2.11it/s] 12%|█▏        | 14/115 [00:06<00:48,  2.07it/s] 13%|█▎        | 15/115 [00:06<00:43,  2.28it/s] 14%|█▍        | 16/115 [00:07<00:47,  2.07it/s] 15%|█▍        | 17/115 [00:07<00:49,  1.98it/s] 16%|█▌        | 18/115 [00:08<00:51,  1.90it/s] 17%|█▋        | 19/115 [00:08<00:44,  2.13it/s] 17%|█▋        | 20/115 [00:09<00:43,  2.20it/s] 18%|█▊        | 21/115 [00:09<00:44,  2.10it/s] 19%|█▉        | 22/115 [00:10<00:44,  2.08it/s] 20%|██        | 23/115 [00:10<00:40,  2.30it/s] 21%|██        | 24/115 [00:11<00:38,  2.35it/s] 22%|██▏       | 25/115 [00:11<00:35,  2.52it/s] 23%|██▎       | 26/115 [00:11<00:33,  2.66it/s] 23%|██▎       | 27/115 [00:12<00:37,  2.37it/s] 24%|██▍       | 28/115 [00:12<00:39,  2.19it/s] 25%|██▌       | 29/115 [00:13<00:44,  1.95it/s] 26%|██▌       | 30/115 [00:13<00:44,  1.93it/s] 27%|██▋       | 31/115 [00:14<00:40,  2.09it/s] 28%|██▊       | 32/115 [00:14<00:39,  2.08it/s] 29%|██▊       | 33/115 [00:15<00:42,  1.94it/s] 30%|██▉       | 34/115 [00:15<00:40,  2.00it/s] 30%|███       | 35/115 [00:16<00:38,  2.07it/s] 31%|███▏      | 36/115 [00:16<00:39,  2.00it/s] 32%|███▏      | 37/115 [00:17<00:40,  1.93it/s] 33%|███▎      | 38/115 [00:17<00:38,  1.98it/s] 34%|███▍      | 39/115 [00:18<00:35,  2.12it/s] 35%|███▍      | 40/115 [00:18<00:34,  2.19it/s] 36%|███▌      | 41/115 [00:19<00:37,  1.98it/s] 37%|███▋      | 42/115 [00:19<00:36,  2.00it/s] 37%|███▋      | 43/115 [00:20<00:41,  1.74it/s] 38%|███▊      | 44/115 [00:21<00:54,  1.30it/s] 39%|███▉      | 45/115 [00:22<00:49,  1.42it/s] 40%|████      | 46/115 [00:22<00:46,  1.49it/s] 41%|████      | 47/115 [00:23<00:41,  1.62it/s] 42%|████▏     | 48/115 [00:24<00:45,  1.46it/s] 43%|████▎     | 49/115 [00:24<00:44,  1.49it/s] 43%|████▎     | 50/115 [00:25<00:41,  1.57it/s] 44%|████▍     | 51/115 [00:25<00:38,  1.67it/s] 45%|████▌     | 52/115 [00:26<00:38,  1.63it/s] 46%|████▌     | 53/115 [00:27<00:38,  1.63it/s] 47%|████▋     | 54/115 [00:27<00:36,  1.68it/s] 48%|████▊     | 55/115 [00:28<00:30,  1.95it/s] 49%|████▊     | 56/115 [00:28<00:28,  2.06it/s] 50%|████▉     | 57/115 [00:28<00:24,  2.35it/s] 50%|█████     | 58/115 [00:29<00:23,  2.47it/s] 51%|█████▏    | 59/115 [00:29<00:20,  2.69it/s] 52%|█████▏    | 60/115 [00:29<00:23,  2.39it/s] 53%|█████▎    | 61/115 [00:30<00:23,  2.34it/s] 54%|█████▍    | 62/115 [00:30<00:24,  2.19it/s] 55%|█████▍    | 63/115 [00:31<00:26,  1.98it/s] 56%|█████▌    | 64/115 [00:32<00:25,  2.04it/s] 57%|█████▋    | 65/115 [00:32<00:23,  2.10it/s] 57%|█████▋    | 66/115 [00:32<00:24,  2.02it/s] 58%|█████▊    | 67/115 [00:33<00:21,  2.20it/s] 59%|█████▉    | 68/115 [00:33<00:20,  2.29it/s] 60%|██████    | 69/115 [00:34<00:20,  2.21it/s] 61%|██████    | 70/115 [00:34<00:20,  2.15it/s] 62%|██████▏   | 71/115 [00:35<00:20,  2.17it/s] 63%|██████▎   | 72/115 [00:35<00:20,  2.12it/s] 63%|██████▎   | 73/115 [00:36<00:18,  2.28it/s] 64%|██████▍   | 74/115 [00:36<00:17,  2.37it/s] 65%|██████▌   | 75/115 [00:36<00:17,  2.33it/s] 66%|██████▌   | 76/115 [00:37<00:18,  2.16it/s] 67%|██████▋   | 77/115 [00:37<00:18,  2.06it/s] 68%|██████▊   | 78/115 [00:38<00:16,  2.21it/s] 69%|██████▊   | 79/115 [00:38<00:17,  2.11it/s] 70%|██████▉   | 80/115 [00:39<00:15,  2.27it/s] 70%|███████   | 81/115 [00:39<00:14,  2.33it/s] 71%|███████▏  | 82/115 [00:40<00:14,  2.34it/s] 72%|███████▏  | 83/115 [00:40<00:13,  2.42it/s] 73%|███████▎  | 84/115 [00:40<00:13,  2.27it/s] 74%|███████▍  | 85/115 [00:41<00:13,  2.22it/s] 75%|███████▍  | 86/115 [00:41<00:13,  2.10it/s] 76%|███████▌  | 87/115 [00:42<00:14,  1.88it/s] 77%|███████▋  | 88/115 [00:43<00:14,  1.92it/s] 77%|███████▋  | 89/115 [00:43<00:11,  2.20it/s] 78%|███████▊  | 90/115 [00:43<00:11,  2.22it/s] 79%|███████▉  | 91/115 [00:44<00:12,  1.91it/s] 80%|████████  | 92/115 [00:45<00:12,  1.81it/s] 81%|████████  | 93/115 [00:45<00:12,  1.81it/s] 82%|████████▏ | 94/115 [00:46<00:10,  1.92it/s] 83%|████████▎ | 95/115 [00:46<00:10,  1.98it/s] 83%|████████▎ | 96/115 [00:47<00:10,  1.85it/s] 84%|████████▍ | 97/115 [00:47<00:09,  1.92it/s] 85%|████████▌ | 98/115 [00:48<00:08,  2.09it/s] 86%|████████▌ | 99/115 [00:48<00:07,  2.17it/s] 87%|████████▋ | 100/115 [00:48<00:06,  2.33it/s] 88%|████████▊ | 101/115 [00:49<00:06,  2.24it/s] 89%|████████▊ | 102/115 [00:49<00:05,  2.18it/s] 90%|████████▉ | 103/115 [00:50<00:05,  2.39it/s] 90%|█████████ | 104/115 [00:50<00:04,  2.31it/s] 91%|█████████▏| 105/115 [00:50<00:03,  2.62it/s] 92%|█████████▏| 106/115 [00:51<00:03,  2.42it/s] 93%|█████████▎| 107/115 [00:51<00:03,  2.49it/s] 94%|█████████▍| 108/115 [00:52<00:02,  2.68it/s] 95%|█████████▍| 109/115 [00:52<00:02,  2.81it/s] 96%|█████████▌| 110/115 [00:53<00:02,  1.90it/s] 97%|█████████▋| 111/115 [00:54<00:02,  1.68it/s] 97%|█████████▋| 112/115 [00:55<00:02,  1.08it/s] 98%|█████████▊| 113/115 [00:56<00:01,  1.30it/s] 99%|█████████▉| 114/115 [00:56<00:00,  1.48it/s]100%|██████████| 115/115 [00:56<00:00,  2.03it/s]
tsv_main2.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main2.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 1/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 1/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                 epoch_loss: 0.08240911861260732
Epoch [1/20], Loss: 0.0824
Best test AUROC: 0.7883, at epoch: 20
Epoch 2/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]Epoch 2/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.48it/s]Epoch 2/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]                                                                 epoch_loss: 0.08330817054957151
Epoch [2/20], Loss: 0.0833
Best test AUROC: 0.7910, at epoch: 21
Epoch 3/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 3/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]Epoch 3/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 3/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]                                                                 epoch_loss: 0.086382486547033
Epoch [3/20], Loss: 0.0864
Best test AUROC: 0.7913, at epoch: 22
Epoch 4/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 4/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 4/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 4/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]                                                                 epoch_loss: 0.09086682088673115
Epoch [4/20], Loss: 0.0909
Best test AUROC: 0.7927, at epoch: 23
Epoch 5/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 5/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]Epoch 5/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.48it/s]Epoch 5/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]                                                                 epoch_loss: 0.09611943790999551
Epoch [5/20], Loss: 0.0961
Best test AUROC: 0.7928, at epoch: 24
Epoch 6/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 6/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 6/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 6/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]                                                                 epoch_loss: 0.10187164880335331
Epoch [6/20], Loss: 0.1019
Best test AUROC: 0.7931, at epoch: 25
Epoch 7/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 7/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 7/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 7/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                 epoch_loss: 0.10787320594924192
Epoch [7/20], Loss: 0.1079
Best test AUROC: 0.7940, at epoch: 26
Epoch 8/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 8/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 8/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 8/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                 epoch_loss: 0.11398129826799656
Epoch [8/20], Loss: 0.1140
Best test AUROC: 0.7943, at epoch: 27
Epoch 9/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 9/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]Epoch 9/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 9/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                 epoch_loss: 0.12007169291609898
Epoch [9/20], Loss: 0.1201
Epoch 10/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 10/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 10/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]Epoch 10/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                  epoch_loss: 0.12619410045833016
Epoch [10/20], Loss: 0.1262
Epoch 11/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 11/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.55it/s]Epoch 11/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.51it/s]Epoch 11/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.13220333229886214
Epoch [11/20], Loss: 0.1322
Best test AUROC: 0.7947, at epoch: 30
Epoch 12/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 12/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 12/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 12/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.13813924232090358
Epoch [12/20], Loss: 0.1381
Epoch 13/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 13/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 13/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 13/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                  epoch_loss: 0.14394770689007905
Epoch [13/20], Loss: 0.1439
Best test AUROC: 0.7950, at epoch: 32
Epoch 14/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 14/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 14/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 14/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.1496300736713844
Epoch [14/20], Loss: 0.1496
Epoch 15/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 15/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 15/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 15/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.15520106791397362
Epoch [15/20], Loss: 0.1552
Epoch 16/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 16/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 16/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 16/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.16063650126185772
Epoch [16/20], Loss: 0.1606
Epoch 17/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 17/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 17/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 17/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.16589327305700863
Epoch [17/20], Loss: 0.1659
Epoch 18/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 18/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 18/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 18/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]                                                                  epoch_loss: 0.17101025345800736
Epoch [18/20], Loss: 0.1710
Best test AUROC: 0.7956, at epoch: 37
Epoch 19/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 19/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Epoch 19/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 19/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.17600658915155995
Epoch [19/20], Loss: 0.1760
Epoch 20/20 Batches:   0%|          | 0/3 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 20/20 Batches:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Epoch 20/20 Batches:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Epoch 20/20 Batches: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]                                                                  epoch_loss: 0.18090155351728754
Epoch [20/20], Loss: 0.1809
best_test_auroc: 0.7956327346705605
