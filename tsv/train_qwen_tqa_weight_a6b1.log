Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]
  0%|          | 0/817 [00:00<?, ?it/s] 18%|█▊        | 151/817 [00:00<00:00, 1509.86it/s] 39%|███▉      | 320/817 [00:00<00:00, 1615.79it/s] 60%|█████▉    | 487/817 [00:00<00:00, 1638.08it/s] 80%|████████  | 655/817 [00:00<00:00, 1653.07it/s]100%|██████████| 817/817 [00:00<00:00, 1635.53it/s]
Epoch 1/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
Epoch 1/20 Batches: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]                                                                 epoch_loss: 0.7046865820884705
Epoch [1/20], Loss: 0.7047
Best test AUROC: 0.6748, at epoch: 0
Epoch [1/20],Test AUROC: 0.6748
Epoch 2/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]                                                                 epoch_loss: 0.6365846395492554
Epoch [2/20], Loss: 0.6366
Epoch [2/20],Test AUROC: 0.6695
Epoch 3/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                 epoch_loss: 0.5588000416755676
Epoch [3/20], Loss: 0.5588
Best test AUROC: 0.6889, at epoch: 2
Epoch [3/20],Test AUROC: 0.6889
Epoch 4/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                 epoch_loss: 0.48186397552490234
Epoch [4/20], Loss: 0.4819
Best test AUROC: 0.7124, at epoch: 3
Epoch [4/20],Test AUROC: 0.7124
Epoch 5/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                 epoch_loss: 0.4085945188999176
Epoch [5/20], Loss: 0.4086
Best test AUROC: 0.7321, at epoch: 4
Epoch [5/20],Test AUROC: 0.7321
Epoch 6/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                 epoch_loss: 0.3421710431575775
Epoch [6/20], Loss: 0.3422
Best test AUROC: 0.7705, at epoch: 5
Epoch [6/20],Test AUROC: 0.7705
Epoch 7/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                 epoch_loss: 0.2830171287059784
Epoch [7/20], Loss: 0.2830
Best test AUROC: 0.8036, at epoch: 6
Epoch [7/20],Test AUROC: 0.8036
Epoch 8/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]                                                                 epoch_loss: 0.23095020651817322
Epoch [8/20], Loss: 0.2310
Best test AUROC: 0.8192, at epoch: 7
Epoch [8/20],Test AUROC: 0.8192
Epoch 9/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                 epoch_loss: 0.18492895364761353
Epoch [9/20], Loss: 0.1849
Best test AUROC: 0.8213, at epoch: 8
Epoch [9/20],Test AUROC: 0.8213
Epoch 10/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]                                                                  epoch_loss: 0.1427631378173828
Epoch [10/20], Loss: 0.1428
Best test AUROC: 0.8241, at epoch: 9
Epoch [10/20],Test AUROC: 0.8241
Epoch 11/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                  epoch_loss: 0.10461919009685516
Epoch [11/20], Loss: 0.1046
Epoch [11/20],Test AUROC: 0.8235
Epoch 12/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]                                                                  epoch_loss: 0.0733775943517685
Epoch [12/20], Loss: 0.0734
Epoch [12/20],Test AUROC: 0.8237
Epoch 13/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.0501411110162735
Epoch [13/20], Loss: 0.0501
Best test AUROC: 0.8243, at epoch: 12
Epoch [13/20],Test AUROC: 0.8243
Epoch 14/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                  epoch_loss: 0.03385273367166519
Epoch [14/20], Loss: 0.0339
Best test AUROC: 0.8252, at epoch: 13
Epoch [14/20],Test AUROC: 0.8252
Epoch 15/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                  epoch_loss: 0.02262328565120697
Epoch [15/20], Loss: 0.0226
Best test AUROC: 0.8266, at epoch: 14
Epoch [15/20],Test AUROC: 0.8266
Epoch 16/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.014876103028655052
Epoch [16/20], Loss: 0.0149
Best test AUROC: 0.8281, at epoch: 15
Epoch [16/20],Test AUROC: 0.8281
Epoch 17/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                  epoch_loss: 0.00965429749339819
Epoch [17/20], Loss: 0.0097
Best test AUROC: 0.8290, at epoch: 16
Epoch [17/20],Test AUROC: 0.8290
Epoch 18/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]                                                                  epoch_loss: 0.006282715126872063
Epoch [18/20], Loss: 0.0063
Best test AUROC: 0.8306, at epoch: 17
Epoch [18/20],Test AUROC: 0.8306
Epoch 19/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]                                                                  epoch_loss: 0.004194398410618305
Epoch [19/20], Loss: 0.0042
Best test AUROC: 0.8330, at epoch: 18
Epoch [19/20],Test AUROC: 0.8330
Epoch 20/20 Batches:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20/20 Batches: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]                                                                  epoch_loss: 0.0029178690165281296
Epoch [20/20], Loss: 0.0029
Best test AUROC: 0.8334, at epoch: 19
Epoch [20/20],Test AUROC: 0.8334
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:02,  1.09it/s] 50%|█████     | 2/4 [00:01<00:01,  1.03it/s] 75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]100%|██████████| 4/4 [00:03<00:00,  1.05it/s]100%|██████████| 4/4 [00:03<00:00,  1.05it/s]
tsv_main3.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  exemplar_label = torch.tensor(exemplar_labels).cuda()
tsv_main3.py:182: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  augmented_labels = torch.concat((selected_labels, torch.tensor(exemplar_labels).clone().cuda()))
Epoch 1/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 1/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Epoch 1/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.04it/s]                                                                 epoch_loss: 0.0007382624782621861
Epoch [1/20], Loss: 0.0007
Best test AUROC: 0.8335, at epoch: 20
Epoch 2/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
Epoch 2/20 Batches:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Epoch 2/20 Batches: 100%|██████████| 2/2 [00:02<00:00,  1.08it/s]                                                                 epoch_loss: 0.0005762384505942463
Epoch [2/20], Loss: 0.0006
Best test AUROC: 0.8346, at epoch: 21
Epoch 3/20 Batches:   0%|          | 0/2 [00:00<?, ?it/s]/data/zyy/LLM/tsv/train_utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(labels, dtype=torch.long, device=device)
                                                         Traceback (most recent call last):
  File "tsv_main3.py", line 692, in <module>
    main()
  File "tsv_main3.py", line 688, in main
    train_model(model, optimizer, device, prompts, labels, args=args)
  File "tsv_main3.py", line 232, in train_model
    scaler.scale(loss).backward()
  File "/data/zyy/miniforge3/envs/tsv/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/data/zyy/miniforge3/envs/tsv/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/data/zyy/miniforge3/envs/tsv/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.46 GiB. GPU 
